{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab07e6c4",
   "metadata": {},
   "source": [
    "# Datengetriebene Analyse zur Optimierung von Airbnb-Investitionen in Z√ºrich f√ºr \"InvestZurich AG\"\n",
    "\n",
    "**Kontext:**\n",
    "Dieser Report wurden im Rahmen des MSc in Wirtschaftsinformatik (BFH-OST-HSLU-FFHS) im Zuge des BINA-Moduls (Business Intelligence & Business Analytics) im Fr√ºhlingssemester 2025 erstellt. Die Fallstudie wurde als Gruppenarbeit erarbeitet und stellt einen Teil des Modul-Kompetenznachweises dar.\n",
    "\n",
    "**Autoren:**\n",
    "- Bielmann Tobias (BFH)\n",
    "- H√∂sli Marc (BFH)\n",
    "- K√ºnzli Joel (BFH)\n",
    "- M√ºhlemann Robin (BFH)\n",
    "- Sinzig Basil (BFH)\n",
    "\n",
    "**Datum:**\n",
    "2. Juni 2025\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "Die vorliegende Fallstudie untersucht den Airbnb-Markt der Stadt Z√ºrich, zur Optimierung von Investitionsstrategien, f√ºr unsere hypothetische Investorenfirma \"InvestZurich AG\". In einem zunehmend wettbewerbsintensiven Umfeld f√ºr Kurzzeitvermietungen ist es f√ºr Investoren entscheidend, datengest√ºtzte Entscheidungen zu treffen, um die Rentabilit√§t zu maximieren und Risiken zu minimieren.\n",
    "Dieses Projekt zielt darauf ab, die Prinzipien des DDDM und die im Modul BINA erlernten Analysemethoden (inkl. Descriptive Statistics, Regression, Classification, Clustering, Time Series Analysis und Datenvisualisierung) anzuwenden, um InvestZurich AG bei der Beantwortung zentraler Fragen in Bezug auf Marktpotenzial, Preisgestaltung, Wettbewerbsanalyse, Rentabilit√§t und Risikomanagement in Z√ºrich zu unterst√ºtzen.\n",
    "\n",
    "Die Vorgehensweise folgt dem von CPA Canada entwickelten Framework \"From Data to Decisions\", das datenbasierte Entscheidungsprozesse in f√ºnf aufeinander aufbauenden Schritten strukturiert. In dieser Arbeit werden die Schritte 1 bis 4 adressiert:\n",
    "1. Defining objectives and information needs\n",
    "2. Collecting Data\n",
    "3. Analyzing Data\n",
    "4. Presenting Information\n",
    "\n",
    "Zu Beginn werden die strategischen Ziele der InvestZurich AG sowie die daraus abgeleiteten Informationsbed√ºrfnisse definiert. Dabei geht es darum, die relevanten Fragestellungen zu identifizieren, die f√ºr Investitionsentscheidungen von zentraler Bedeutung sind, beispielsweise zur Standortattraktivit√§t, zur Preisgestaltung oder zur erwarteten Auslastung. Nur wenn die Informationsbedarfe klar formuliert sind, kann die Analyse zielgerichtet erfolgen.\n",
    "\n",
    "Anschliessend liegt der Fokus auf die Erhebung, Auswahl und Aufbereitung geeigneter Datenquellen. Dazu z√§hlen strukturierte Airbnb-Daten ebenso wie erg√§nzende Informationen zu Wohungspreisen in der Stadt Z√ºrich. Die Daten werden bereinigt und so vorbereitet, dass eine valide und aussagekr√§ftige Analyse m√∂glich ist.\n",
    "\n",
    "Im dritten Schritt erfolgt die Auswertung mithilfe den im Modul BINA erlernten Analysemethoden. Ziel ist es, aus den Daten konkrete Muster, Zusammenh√§nge und Trends abzuleiten, die f√ºr die InvestZurich AG wirtschaftlich relevante Erkenntnisse liefern.\n",
    "\n",
    "Abschliessend werden die Analyseergebnisse zielgruppengerecht aufbereitet. Dabei stehen visuelle Elemente im Fokus, um zentrale Erkenntnisse klar und verst√§ndlich zu vermitteln. Auf dieser Grundlage werden konkrete, umsetzbare Handlungsmpfehlungen f√ºr die InvestZurich AG formuliert, die sie bei ihrer Entscheidungsfindung unterst√ºtzen sollen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241fc32",
   "metadata": {},
   "source": [
    "# Step 1: Defining Objectives and Information Needs\n",
    "\n",
    "Der erste Schritt des CPA-Frameworks \"From Data to Decisions\" besteht in der klaren Definition der strategischen Zielsetzungen sowie der daraus abgeleiteten Informationsbedarfe. Dieser Schritt bildet die Grundlage f√ºr alle folgenden Phasen der datengest√ºtzten Entscheidungsfindung. Eine pr√§zise Formulierung der gesch√§ftlichen Ziele sowie der damit verbundenen Informationsanforderungen ist entscheidend, um die Analyse strukturiert und zielgerichtet ausrichten zu k√∂nnen.\n",
    "\n",
    "Im Rahmen dieser Fallstudie steht die Optimierung von Investitionen im Airbnb-Markt der Stadt Z√ºrich im Fokus. F√ºr die fiktive Investorenfirma InvestZurich AG sollen auf Basis datengetriebener Analysen Entscheidungsgrundlagen erarbeitet werden, um Investitionsrisiken zu minimieren, Chancen systematisch zu identifizieren und die operative Performance der Vermietungsobjekte zu steigern. Die strategischen Ziele lassen sich in vier zentrale Themenfelder unterteilen.\n",
    "\n",
    "## Objective 1 ‚Äì Marktpotenzial und Standortanalyse\n",
    "**Strategisches Ziel:** Identifikation besonders attraktiver Standorte f√ºr Airbnb-Investitionen in der Stadt Z√ºrich.\n",
    "\n",
    "**Informationsbedarfe:**\n",
    "- Analyse der Nachfrage nach Kurzzeitvermietungen in den einzelnen Stadtquartieren.\n",
    "- Identifikation unterversorgter Wohnungstypen hinsichtlich Gr√∂sse oder Zimmeranzahl.\n",
    "- Vergleich von Auslastung und erzielbaren Preisen zwischen verschiedenen Quartieren.\n",
    "- Untersuchung relevanter sozio√∂konomischer und infrastruktureller Standortfaktoren.\n",
    "\n",
    "Ziel dieser Analysen ist es, fundierte Grundlagen f√ºr Standortentscheidungen zu schaffen und Quartiere mit √ºberdurchschnittlichem Renditepotenzial zu priorisieren.\n",
    "\n",
    "## Objective 2 ‚Äì Preisstrategie und Ertragsprognose\n",
    "**Strategisches Ziel:** Entwicklung evidenzbasierter Preisstrategien sowie realistischer Prognosen zu erzielbaren Einnahmen aus Airbnb-Vermietungen.\n",
    "\n",
    "**Informationsbedarfe:**\n",
    "- Ermittlung der wichtigsten Einflussfaktoren auf die Preisgestaltung im Z√ºrcher Airbnb-Markt.\n",
    "- Analyse markt√ºblicher Preisspannen f√ºr verschiedene Objektarten und Standorte.\n",
    "- Identifikation saisonaler Schwankungen in Buchungszahlen und Preisniveaus.\n",
    "- Bewertung des Zusammenhangs zwischen Preis, Ausstattung, Aufenthaltsdauer und Auslastung.\n",
    "\n",
    "Diese Erkenntnisse unterst√ºtzen die wirtschaftliche Bewertung potenzieller Investitionsobjekte und erm√∂glichen die Feinjustierung der Preisgestaltung f√ºr maximale Auslastung und Ertrag.\n",
    "\n",
    "## Objective 3 ‚Äì Performance Optimierung und Benchmarking\n",
    "**Strategisches Ziel:** Ableitung von Handlungsempfehlungen zur Verbesserung der operativen Performance basierend auf erfolgreichen Marktteilnehmern.\n",
    "\n",
    "**Informationsbedarfe:**\n",
    "- Analyse von Unterschieden zwischen besonders erfolgreichen Hosts (z.B. Superhosts) und durchschnittlichen Anbietern.\n",
    "- Identifikation von Merkmalen und Services, die die G√§stezufriedenheit und Buchungsraten erh√∂hen.\n",
    "- Untersuchung der Bedeutung von Bewertungen, Reaktionsgeschwindigkeit und Mindestaufenthaltsdauer f√ºr die Performance.\n",
    "- Definition konkreter Massnahmen zur Erlangung und Aufrechterhaltung des Superhost-Status.\n",
    "\n",
    "Diese Informationen bilden die Basis f√ºr gezielte operative Verbesserungen und die Entwicklung eines professionellen, standardisierten Vermietungsansatzes.\n",
    "\n",
    "## Objective 4 ‚Äì Listing-Optimierung durch Textanalyse\n",
    "**Strategisches Ziel:** Untersuchung des Einflusses der Beschreibungstexte auf das Buchungsverhalten und die Bewertung durch G√§ste.\n",
    "\n",
    "**Informationsbedarf:**\n",
    "- Analyse sprachlicher Merkmale (Tonfall, L√§nge, Stilistik) in Listing-Beschreibungen.\n",
    "- Untersuchung semantischer Inhalte in Bezug auf Vertrauen, Exklusivit√§t, Komfort etc.\n",
    "- Vergleich von Textmerkmalen zwischen hochfrequentierten und wenig gebuchten Objekten.\n",
    "- Ermittlung potenzieller Optimierungsans√§tze zur Verbesserung der Listings.\n",
    "\n",
    "Die Textanalyse soll Aufschluss dar√ºber geben, ob bestimmte Formulierungen, Strukturen oder Emotionen in Beschreibungen einen messbaren Einfluss auf Buchungszahlen und Bewertungen haben. Ziel ist es, Empfehlungen f√ºr eine wirkungsvolle Kommunikation im digitalen Raum abzuleiten.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ad3b5",
   "metadata": {},
   "source": [
    "# Step 2: Collecting Data\n",
    "\n",
    "Die f√ºr diese Analyse verwendeten Datens√§tze wurden urspr√ºnglich von [Inside Airbnb](http://insideairbnb.com/get-the-data/#Zurich) (Datenstand ca. 23. M√§rz 2025) und [Stadt Z√ºrich Open Data](https://data.stadt-zuerich.ch/dataset/bau_hae_preis_stockwerkeigentum_zimmerzahl_stadtquartier_od5155) (Datenstand ca. 20. Januar 2025) bezogen.\n",
    "\n",
    "Diese Rohdaten wurden bereits in eine Supabase-Datenbank geladen und dort in den Tabellen `cleaned_listings` und `cleaned_selling_prices` zentral bereinigt und aufbereitet. Die Spaltennamen und Datentypen in diesen Supabase-Tabellen entsprechen den Definitionen der Dataclasses in `bina_models.py`.\n",
    "\n",
    "**In Supabase durchgef√ºhrte Aufbereitungsschritte umfassen:**\n",
    "* **Schema-Validierung und -Anpassung:** Sicherstellung, dass die Datenstruktur den `Listing`- und `SellingPrices`-Modellen entspricht\n",
    "* **Behandlung von Duplikaten.**\n",
    "* **Standardisierung von Formaten** `Datum`, `Boolean\n",
    "* **Parsing komplexer Felder** (Preis-Strings zu numerischen Werten, initiale Textverarbeitung). F√ºr `amenities` wurde sichergestellt, dass es als Liste von Strings geladen wird. `bathrooms` wurde als numerischer Wert `float` etabliert\n",
    "* **Umgang mit fehlenden Werten (initial)**\n",
    "* **Typkonvertierungen** gem√§ss `bina_models.py`\n",
    "\n",
    "F√ºr diese Analyse greifen wir √ºber den benutzerdefinierten Python-Service `AirbnbAnalysisService` auf diese bereits in Supabase aufbereiteten Tabellen zu. In diesem Abschnitt wird genauer auf die oben genannten Schritte eingegangen.\n",
    "\n",
    "\n",
    "## Datenquellen und -beschaffung via Supabase f√ºr `Listings`\n",
    "\n",
    "### 1. Fehlende Werte identifizieren und einordnen / Z√§hlen der fehlenden Werte pro Spalte f√ºr `listings`\n",
    "Um eine fundierte Grundlage f√ºr den weiteren Analyseprozess zu schaffen, ist es essenziell, zun√§chst das Ausmass fehlender Werte im Datensatz zu quantifizieren. Die Identifikation von Spalten mit fehlenden Werten erm√∂glicht es, potenzielle Datenqualit√§tsprobleme fr√ºhzeitig zu erkennen und geeignete Massnahmen zur Datenbereinigung abzuleiten.\n",
    "Ziel ist es zu verstehen, wo welche Spalten fehlende Werte `NULLs` enthalten und was das f√ºr die sp√§tere Analyse bedeutet.\n",
    "\n",
    "**SQL Query:**\n",
    "```sql\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  SUM(CASE WHEN id IS NULL THEN 1 ELSE 0 END) AS null_id,\n",
    "  SUM(CASE WHEN listing_url IS NULL THEN 1 ELSE 0 END) AS null_listing_url,\n",
    "  SUM(CASE WHEN scrape_id IS NULL THEN 1 ELSE 0 END) AS null_scrape_id,\n",
    "  SUM(CASE WHEN last_scraped IS NULL THEN 1 ELSE 0 END) AS null_last_scraped,\n",
    "  SUM(CASE WHEN source IS NULL THEN 1 ELSE 0 END) AS null_source,\n",
    "  SUM(CASE WHEN name IS NULL THEN 1 ELSE 0 END) AS null_name,\n",
    "  SUM(CASE WHEN description IS NULL THEN 1 ELSE 0 END) AS null_description,\n",
    "  SUM(CASE WHEN neighborhood_overview IS NULL THEN 1 ELSE 0 END) AS null_neighborhood_overview,\n",
    "  SUM(CASE WHEN picture_url IS NULL THEN 1 ELSE 0 END) AS null_picture_url,\n",
    "  SUM(CASE WHEN host_id IS NULL THEN 1 ELSE 0 END) AS null_host_id,\n",
    "  SUM(CASE WHEN host_url IS NULL THEN 1 ELSE 0 END) AS null_host_url,\n",
    "  SUM(CASE WHEN host_name IS NULL THEN 1 ELSE 0 END) AS null_host_name,\n",
    "  SUM(CASE WHEN host_since IS NULL THEN 1 ELSE 0 END) AS null_host_since,\n",
    "  SUM(CASE WHEN host_location IS NULL THEN 1 ELSE 0 END) AS null_host_location,\n",
    "  SUM(CASE WHEN host_about IS NULL THEN 1 ELSE 0 END) AS null_host_about,\n",
    "  SUM(CASE WHEN host_response_time IS NULL THEN 1 ELSE 0 END) AS null_host_response_time,\n",
    "  SUM(CASE WHEN host_response_rate IS NULL THEN 1 ELSE 0 END) AS null_host_response_rate,\n",
    "  SUM(CASE WHEN host_acceptance_rate IS NULL THEN 1 ELSE 0 END) AS null_host_acceptance_rate,\n",
    "  SUM(CASE WHEN host_is_superhost IS NULL THEN 1 ELSE 0 END) AS null_host_is_superhost,\n",
    "  SUM(CASE WHEN host_thumbnail_url IS NULL THEN 1 ELSE 0 END) AS null_host_thumbnail_url,\n",
    "  SUM(CASE WHEN host_picture_url IS NULL THEN 1 ELSE 0 END) AS null_host_picture_url,\n",
    "  SUM(CASE WHEN host_neighbourhood IS NULL THEN 1 ELSE 0 END) AS null_host_neighbourhood,\n",
    "  SUM(CASE WHEN host_listings_count IS NULL THEN 1 ELSE 0 END) AS null_host_listings_count,\n",
    "  SUM(CASE WHEN host_total_listings_count IS NULL THEN 1 ELSE 0 END) AS null_host_total_listings_count,\n",
    "  SUM(CASE WHEN host_verifications IS NULL THEN 1 ELSE 0 END) AS null_host_verifications,\n",
    "  SUM(CASE WHEN host_has_profile_pic IS NULL THEN 1 ELSE 0 END) AS null_host_has_profile_pic,\n",
    "  SUM(CASE WHEN host_identity_verified IS NULL THEN 1 ELSE 0 END) AS null_host_identity_verified,\n",
    "  SUM(CASE WHEN neighbourhood IS NULL THEN 1 ELSE 0 END) AS null_neighbourhood,\n",
    "  SUM(CASE WHEN neighbourhood_cleansed IS NULL THEN 1 ELSE 0 END) AS null_neighbourhood_cleansed,\n",
    "  SUM(CASE WHEN neighbourhood_group_cleansed IS NULL THEN 1 ELSE 0 END) AS null_neighbourhood_group_cleansed,\n",
    "  SUM(CASE WHEN latitude IS NULL THEN 1 ELSE 0 END) AS null_latitude,\n",
    "  SUM(CASE WHEN longitude IS NULL THEN 1 ELSE 0 END) AS null_longitude,\n",
    "  SUM(CASE WHEN property_type IS NULL THEN 1 ELSE 0 END) AS null_property_type,\n",
    "  SUM(CASE WHEN room_type IS NULL THEN 1 ELSE 0 END) AS null_room_type,\n",
    "  SUM(CASE WHEN accommodates IS NULL THEN 1 ELSE 0 END) AS null_accommodates,\n",
    "  SUM(CASE WHEN bathrooms IS NULL THEN 1 ELSE 0 END) AS null_bathrooms,\n",
    "  SUM(CASE WHEN bathrooms_text IS NULL THEN 1 ELSE 0 END) AS null_bathrooms_text,\n",
    "  SUM(CASE WHEN bedrooms IS NULL THEN 1 ELSE 0 END) AS null_bedrooms,\n",
    "  SUM(CASE WHEN beds IS NULL THEN 1 ELSE 0 END) AS null_beds,\n",
    "  SUM(CASE WHEN amenities IS NULL THEN 1 ELSE 0 END) AS null_amenities,\n",
    "  SUM(CASE WHEN price IS NULL THEN 1 ELSE 0 END) AS null_price,\n",
    "  SUM(CASE WHEN minimum_nights IS NULL THEN 1 ELSE 0 END) AS null_minimum_nights,\n",
    "  SUM(CASE WHEN maximum_nights IS NULL THEN 1 ELSE 0 END) AS null_maximum_nights,\n",
    "  SUM(CASE WHEN minimum_minimum_nights IS NULL THEN 1 ELSE 0 END) AS null_minimum_minimum_nights,\n",
    "  SUM(CASE WHEN maximum_minimum_nights IS NULL THEN 1 ELSE 0 END) AS null_maximum_minimum_nights,\n",
    "  SUM(CASE WHEN minimum_maximum_nights IS NULL THEN 1 ELSE 0 END) AS null_minimum_maximum_nights,\n",
    "  SUM(CASE WHEN maximum_maximum_nights IS NULL THEN 1 ELSE 0 END) AS null_maximum_maximum_nights,\n",
    "  SUM(CASE WHEN minimum_nights_avg_ntm IS NULL THEN 1 ELSE 0 END) AS null_minimum_nights_avg_ntm,\n",
    "  SUM(CASE WHEN maximum_nights_avg_ntm IS NULL THEN 1 ELSE 0 END) AS null_maximum_nights_avg_ntm,\n",
    "  SUM(CASE WHEN calendar_updated IS NULL THEN 1 ELSE 0 END) AS null_calendar_updated,\n",
    "  SUM(CASE WHEN has_availability IS NULL THEN 1 ELSE 0 END) AS null_has_availability,\n",
    "  SUM(CASE WHEN availability_30 IS NULL THEN 1 ELSE 0 END) AS null_availability_30,\n",
    "  SUM(CASE WHEN availability_60 IS NULL THEN 1 ELSE 0 END) AS null_availability_60,\n",
    "  SUM(CASE WHEN availability_90 IS NULL THEN 1 ELSE 0 END) AS null_availability_90,\n",
    "  SUM(CASE WHEN availability_365 IS NULL THEN 1 ELSE 0 END) AS null_availability_365,\n",
    "  SUM(CASE WHEN calendar_last_scraped IS NULL THEN 1 ELSE 0 END) AS null_calendar_last_scraped,\n",
    "  SUM(CASE WHEN number_of_reviews IS NULL THEN 1 ELSE 0 END) AS null_number_of_reviews,\n",
    "  SUM(CASE WHEN number_of_reviews_ltm IS NULL THEN 1 ELSE 0 END) AS null_number_of_reviews_ltm,\n",
    "  SUM(CASE WHEN number_of_reviews_l30d IS NULL THEN 1 ELSE 0 END) AS null_number_of_reviews_l30d,\n",
    "  SUM(CASE WHEN first_review IS NULL THEN 1 ELSE 0 END) AS null_first_review,\n",
    "  SUM(CASE WHEN last_review IS NULL THEN 1 ELSE 0 END) AS null_last_review,\n",
    "  SUM(CASE WHEN review_scores_rating IS NULL THEN 1 ELSE 0 END) AS null_review_scores_rating,\n",
    "  SUM(CASE WHEN review_scores_accuracy IS NULL THEN 1 ELSE 0 END) AS null_review_scores_accuracy,\n",
    "  SUM(CASE WHEN review_scores_cleanliness IS NULL THEN 1 ELSE 0 END) AS null_review_scores_cleanliness,\n",
    "  SUM(CASE WHEN review_scores_checkin IS NULL THEN 1 ELSE 0 END) AS null_review_scores_checkin,\n",
    "  SUM(CASE WHEN review_scores_communication IS NULL THEN 1 ELSE 0 END) AS null_review_scores_communication,\n",
    "  SUM(CASE WHEN review_scores_location IS NULL THEN 1 ELSE 0 END) AS null_review_scores_location,\n",
    "  SUM(CASE WHEN review_scores_value IS NULL THEN 1 ELSE 0 END) AS null_review_scores_value,\n",
    "  SUM(CASE WHEN license IS NULL THEN 1 ELSE 0 END) AS null_license,\n",
    "  SUM(CASE WHEN instant_bookable IS NULL THEN 1 ELSE 0 END) AS null_instant_bookable,\n",
    "  SUM(CASE WHEN calculated_host_listings_count IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count,\n",
    "  SUM(CASE WHEN calculated_host_listings_count_entire_homes IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count_entire_homes,\n",
    "  SUM(CASE WHEN calculated_host_listings_count_private_rooms IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count_private_rooms,\n",
    "  SUM(CASE WHEN calculated_host_listings_count_shared_rooms IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count_shared_rooms,\n",
    "  SUM(CASE WHEN reviews_per_month IS NULL THEN 1 ELSE 0 END) AS null_reviews_per_month\n",
    "FROM listings;\n",
    "```\n",
    "Die Berechnung der Anzahl sowie des prozentualen Anteils fehlender Werte pro Spalte bietet eine klare √úbersicht dar√ºber, welche Merkmale besonders betroffen sind. \n",
    "Auf dieser Basis k√∂nnen fundierte Entscheidungen hinsichtlich Imputation, L√∂schung oder anderer Strategien zur Behandlung fehlender Daten getroffen werden.\n",
    "\n",
    "### 2. Kategorisierung der Spalten nach Analyse-Relevanz f√ºr `listings`\n",
    "Ein zentraler Schritt bei der Behandlung fehlender Werte besteht darin, die betroffenen Spalten hinsichtlich ihrer Bedeutung f√ºr die Analyse zu kategorisieren.\n",
    "Diese Einordnung erm√∂glicht eine systematische Ableitung geeigneter Massnahmen im Umgang mit fehlenden Daten.\n",
    "Im Folgenden wird eine beispielhafte Kategorisierung vorgenommen:\n",
    "\n",
    "| Kategorie                                               | Beispielhafte Spalten                                                           | Empfohlener Umgang mit fehlenden Werten               |\n",
    "| ------------------------------------------------------- | -------------------------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "| üü• **Kritisch (essenzielle Kerninformationen)**          | `id`, `price`, `latitude`, `longitude`, `room_type`, `accommodates`             | Zeilen mit fehlenden Werten sollten entfernt werden.  |\n",
    "| üüß **Relevant f√ºr Analysen (w√ºnschenswert vollst√§ndig)** | `beds`, `bedrooms`, `review_scores_*`, `availability_365`, `reviews_per_month`  | Fehlende Werte sollten durch Imputation oder Flags behandelt werden. |\n",
    "| üü® **Optional / rein informativ / technische Informationen**                        | `host_about`, `description`, `host_thumbnail_url`                               | Fehlende Werte k√∂nnen in der Regel ignoriert werden.  |\n",
    "\n",
    "Die Zuordnung erfolgt kontextabh√§ngig, basierend auf der Zielsetzung der Analyse. \n",
    "Kritische Spalten sind f√ºr grundlegende Berechnungen unerl√§sslich und d√ºrfen keine L√ºcken enthalten, w√§hrend bei optionalen oder technischen Feldern eine h√∂here Toleranz gegen√ºber fehlenden Werten besteht.\n",
    "\n",
    "### 3. Zentrale Leitfragen zur Bewertung fehlender Werte f√ºr `listings`\n",
    "Bei der Bewertung fehlender Werte sollten bestimmte Leitfragen ber√ºcksichtigt werden, um fundierte Entscheidungen √ºber den weiteren Umgang mit den Daten treffen zu k√∂nnen. Diese Fragen helfen, zwischen tolerierbaren und problematischen Auspr√§gungen zu unterscheiden:\n",
    "\n",
    "- **Wie viele Eintr√§ge sind betroffen?**\n",
    "  Ein hoher Anteil fehlender Werte (z.‚ÄØB. mehr als 30‚ÄØ%) kann die Aussagekraft einer Spalte erheblich beeintr√§chtigen und sollte als kritisch bewertet werden.\n",
    "- **Wird die Spalte sp√§ter f√ºr Berechnungen oder Modellierung verwendet?**\n",
    "  Fehlt ein Wert in einem f√ºr mathematische Operationen relevanten Feld, kann dies zu Verzerrungen oder Fehlern f√ºhren.\n",
    "- **Kann der fehlende Wert sinnvoll ersetzt werden?**\n",
    "  In manchen F√§llen ist eine Imputation m√∂glich, z.‚ÄØB. durch Verwendung des Mittelwerts, Medians oder eines Platzhalterwertes wie \"unknown\".\n",
    "- **Tr√§gt das Fehlen des Wertes eine eigene Information?**\n",
    "  Ein `NULL`-Wert kann unter Umst√§nden auch eine inhaltliche Bedeutung haben, z.‚ÄØB. dass ein Gast keine Bewertung abgegeben hat. In solchen F√§llen kann es sinnvoll sein, den fehlenden Wert explizit als \"nicht vorhanden\" zu interpretieren.\n",
    "\n",
    "Diese √úberlegungen unterst√ºtzen eine datengetriebene und analytisch begr√ºndete Entscheidungsfindung im Umgang mit fehlenden Werten.\n",
    "\n",
    "### 4. Kategorisierung aller Spalten nach Relevanz f√ºr `listings`\n",
    "Zur systematischen Behandlung fehlender Werte und zur Priorisierung von Datenbereinigungsschritten wurden alle Spalten des Datensatzes in drei Kategorien eingeteilt. Die Einordnung basiert auf ihrer analytischen Relevanz, insbesondere im Hinblick auf Zielgr√∂ssen wie die Berechnung der Rentabilit√§t (ROI), r√§umliche Analysen (z.‚ÄØB. Heatmaps) sowie die Bewertung von Angebotsqualit√§t und Nutzerverhalten.\n",
    "\n",
    "| Kategorie                             | Spaltennamen                                                                                                          | Begr√ºndung |\n",
    "|--------------------------------------|-----------------------------------------------------------------------------------------------------------------------|------------|\n",
    "| üü• **High Impact (essentiell)**       | `id`, `latitude`, `longitude`, `price`, `room_type`, `accommodates`, `neighbourhood_cleansed`, `availability_365`, `number_of_reviews`, `reviews_per_month`, `review_scores_rating` | Diese Spalten sind zentral f√ºr Kernanalysen wie ROI-Berechnung, geografische Visualisierungen (z.‚ÄØB. Heatmaps) und zur Beurteilung der Angebotsqualit√§t. Fehlende Werte f√ºhren zu erheblichen Einschr√§nkungen der Aussagekraft. |\n",
    "| üüß **Medium Impact (n√ºtzlich, aber nicht kritisch)** | `bathrooms`, `bedrooms`, `beds`, `host_id`, `host_listings_count`, `host_total_listings_count`, `property_type`, `review_scores_*`, `first_review`, `last_review`, `instant_bookable`, `calculated_host_listings_count_*`, `number_of_reviews_ltm`, `number_of_reviews_l30d`, `has_availability`, `minimum_nights`, `maximum_nights`, `amenities` | Diese Merkmale erg√§nzen die Analysen sinnvoll und tragen zur Erkl√§rung von Erfolgsfaktoren bei (z.‚ÄØB. welche Eigenschaften machen ein Listing attraktiv oder profitabel). Fehlende Werte sind tolerierbar, sollten aber m√∂glichst behandelt werden. |\n",
    "| üü® **Low Impact (optional oder informativ)** | `listing_url`, `scrape_id`, `last_scraped`, `source`, `name`, `description`, `neighborhood_overview`, `picture_url`, `host_url`, `host_name`, `host_since`, `host_location`, `host_about`, `host_response_time`, `host_response_rate`, `host_acceptance_rate`, `host_is_superhost`, `host_thumbnail_url`, `host_picture_url`, `host_neighbourhood`, `host_verifications`, `host_has_profile_pic`, `host_identity_verified`, `neighbourhood`, `neighbourhood_group_cleansed`, `bathrooms_text`, `calendar_updated`, `calendar_last_scraped`, `license`, `minimum_minimum_nights`, `maximum_minimum_nights`, `minimum_maximum_nights`, `maximum_maximum_nights`, `minimum_nights_avg_ntm`, `maximum_nights_avg_ntm` | Diese Spalten enthalten vorwiegend Metadaten, beschreibende Texte, Bilder oder technische Informationen. Sie sind f√ºr Business-Intelligence-Analysen oder geografische Auswertungen nur bedingt relevant, k√∂nnen aber im Rahmen von UI-Design, Vollst√§ndigkeitspr√ºfungen oder NLP-Analysen von Interesse sein. |\n",
    "\n",
    "Die vorliegende Klassifizierung stellt eine arbeitsorientierte Grundlage f√ºr alle weiteren Entscheidungen zur Datenvorverarbeitung dar.\n",
    "\n",
    "### 5. Bereinigung kritischer Felder und Markierung unvollst√§ndiger Eintr√§ge (Flagging) f√ºr `listings`\n",
    "Im Rahmen der Datenbereinigung wurde eine zweistufige Strategie verfolgt, um mit fehlenden Werten umzugehen. Zun√§chst wurden alle Datens√§tze entfernt, die in den als *High Impact* klassifizierten Spalten fehlende Werte aufwiesen. Diese Spalten sind f√ºr zentrale Analysen wie Rentabilit√§tsberechnungen, geografische Auswertungen und die allgemeine Bewertung der Angebotsqualit√§t unerl√§sslich. Fehlende Werte in diesen Feldern w√ºrden die Aussagekraft der Analysen massiv beeintr√§chtigen.\n",
    "\n",
    "Im Gegensatz dazu wurde bei den als *Medium Impact* eingestuften Spalten auf das L√∂schen von Zeilen verzichtet. Stattdessen wurde ein **Flagging-Mechanismus** eingef√ºhrt: F√ºr jede Zeile wurde ein boolesches Flag (`missing_data_flag`) gesetzt, das anzeigt, ob in mindestens einem dieser mittleren Felder ein Wert fehlt. Dieses Vorgehen erm√∂glicht es, die Informationen zu fehlenden Werten zu einem sp√§teren Zeitpunkt gezielt wiederzuverwenden ‚Äì etwa zur Modellbewertung, Filterung oder bei der Entwicklung von Imputationsstrategien.\n",
    "\n",
    "Die folgende SQL-Abfrage implementiert beide Schritte:\n",
    "```sql\n",
    "CREATE TABLE cleaned_listings AS\n",
    "SELECT *,\n",
    "  -- Setze Flag f√ºr Medium Impact Spalten mit fehlenden Werten\n",
    "  CASE\n",
    "    WHEN\n",
    "      bathrooms IS NULL OR\n",
    "      bedrooms IS NULL OR\n",
    "      beds IS NULL OR\n",
    "      host_id IS NULL OR\n",
    "      host_listings_count IS NULL OR\n",
    "      host_total_listings_count IS NULL OR\n",
    "      property_type IS NULL OR\n",
    "      review_scores_accuracy IS NULL OR\n",
    "      review_scores_cleanliness IS NULL OR\n",
    "      review_scores_checkin IS NULL OR\n",
    "      review_scores_communication IS NULL OR\n",
    "      review_scores_location IS NULL OR\n",
    "      review_scores_value IS NULL OR\n",
    "      first_review IS NULL OR\n",
    "      last_review IS NULL OR\n",
    "      instant_bookable IS NULL OR\n",
    "      calculated_host_listings_count IS NULL OR\n",
    "      calculated_host_listings_count_entire_homes IS NULL OR\n",
    "      calculated_host_listings_count_private_rooms IS NULL OR\n",
    "      calculated_host_listings_count_shared_rooms IS NULL OR\n",
    "      number_of_reviews_ltm IS NULL OR\n",
    "      number_of_reviews_l30d IS NULL OR\n",
    "      has_availability IS NULL OR\n",
    "      minimum_nights IS NULL OR\n",
    "      maximum_nights IS NULL OR\n",
    "      amenities IS NULL\n",
    "    THEN TRUE\n",
    "    ELSE FALSE\n",
    "  END AS missing_data_flag\n",
    "\n",
    "FROM listings\n",
    "-- High Impact: Zeilen l√∂schen, wenn diese Spalten NULL sind\n",
    "WHERE \n",
    "  id IS NOT NULL AND\n",
    "  latitude IS NOT NULL AND\n",
    "  longitude IS NOT NULL AND\n",
    "  price IS NOT NULL AND\n",
    "  room_type IS NOT NULL AND\n",
    "  accommodates IS NOT NULL AND\n",
    "  neighbourhood_cleansed IS NOT NULL AND\n",
    "  availability_365 IS NOT NULL AND\n",
    "  number_of_reviews IS NOT NULL AND\n",
    "  reviews_per_month IS NOT NULL AND\n",
    "  review_scores_rating IS NOT NULL;\n",
    "```\n",
    "Mit dieser Vorgehensweise ist sichergestellt, dass alle f√ºr die Kernanalysen relevanten Spalten vollst√§ndig vorliegen, w√§hrend gleichzeitig potenziell informative L√ºcken in weniger zentralen Spalten nicht verloren gehen, sondern gezielt gekennzeichnet werden.\n",
    "\n",
    "### 6. Auswertung des `missing_data_flag` udn Analyse der unvollst√§ndigen Datens√§tze f√ºr `listings`\n",
    "Nach der Bereinigung der *High Impact*-Spalten wurde ein Flag (`missing_data_flag`) eingef√ºhrt, das anzeigt, ob ein Datensatz in einer oder mehreren *Medium Impact*-Spalten fehlende Werte enth√§lt. Um den Umfang des verbleibenden Datenqualit√§tsproblems besser einsch√§tzen zu k√∂nnen, wurde eine erste Auswertung dieses Flags vorgenommen.\n",
    "\n",
    "**Die Auswertung beantwortet unter anderem folgende Fragen:**\n",
    "- Wie viele Datens√§tze enthalten noch fehlende Werte in *Medium Impact*-Feldern?\n",
    "- Wie gross ist ihr Anteil am Gesamtbestand?\n",
    "- Welche strategischen Optionen ergeben sich daraus (z.‚ÄØB. Imputation, gezielter Ausschluss)?\n",
    "\n",
    "**In SQL:**\n",
    "```sql\n",
    "-- Z√§hle, wie viele Zeilen fehlende Werte in Medium Impact Feldern haben\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  SUM(CASE WHEN missing_data_flag = TRUE THEN 1 ELSE 0 END) AS rows_with_missing,\n",
    "  ROUND(100.0 * SUM(CASE WHEN missing_data_flag = TRUE THEN 1 ELSE 0 END) / COUNT(*), 2) AS percent_with_missing\n",
    "FROM cleaned_listings;\n",
    "```\n",
    "Diese Kennzahlen bieten eine Grundlage f√ºr datenbasierte Entscheidungen im weiteren Verlauf der Analyse. Beispielsweise kann entschieden werden, ob die betroffenen Zeilen durch geeignete Verfahren erg√§nzt (Imputation) oder selektiv ausgeschlossen werden sollen.\n",
    "\n",
    "### 7. Finalisierung und Typisierung der Tabelle `cleaned_listings`\n",
    "Nach der ersten Bereinigung des Datensatzes und dem Setzen eines Flags f√ºr unvollst√§ndige *Medium Impact*-Spalten wurde die Tabelle `cleaned_listings` final strukturiert. Ziel war es, eine konsolidierte und konsistente Datenbasis zu schaffen, mit der im weiteren Analyseprozess effizient und ohne zus√§tzliche Nachbearbeitung gearbeitet werden kann.\n",
    "\n",
    "**Vorgehen:**\n",
    "1. Zun√§chst wurde eine Sicherungskopie der bereinigten Tabelle erstellt.\n",
    "2. Anschliessend wurde die urspr√ºngliche Version entfernt.\n",
    "3. Eine neue, typisierte Tabelle `cleaned_listings` wurde auf Basis des bisherigen Inhalts erstellt.\n",
    "\n",
    "Besonderes Augenmerk lag dabei auf der **Daten-Typisierung**, um typische Inkonsistenzen ‚Äì wie zum Beispiel Prozentangaben im Textformat (\"95%\") ‚Äì direkt im SQL-Prozess zu bereinigen. Dadurch konnte eine nachgelagerte Datenreinigung in Python vermieden werden.\n",
    "\n",
    "Zudem wurden gezielte **inhaltliche Korrekturen** vorgenommen, etwa das Auff√ºllen fehlender Werte im Feld `neighbourhood` mit dem Standardwert \"Z√ºrich\". \n",
    "\n",
    "Die finale Struktur der Tabelle ist in folgender SQL-Definition abgebildet:\n",
    "```sql\n",
    "CREATE TABLE cleaned_listings (\n",
    "  id NUMERIC,\n",
    "  listing_url TEXT,\n",
    "  scrape_id NUMERIC,\n",
    "  last_scraped DATE,\n",
    "  source TEXT,\n",
    "  name TEXT,\n",
    "  description TEXT,\n",
    "  neighborhood_overview TEXT,\n",
    "  picture_url TEXT,\n",
    "  host_id INT,\n",
    "  host_url TEXT,\n",
    "  host_name TEXT,\n",
    "  host_since DATE,\n",
    "  host_location TEXT,\n",
    "  host_about TEXT,\n",
    "  host_response_time TEXT,\n",
    "  host_response_rate TEXT,\n",
    "  host_acceptance_rate INT,\n",
    "  host_is_superhost BOOLEAN,\n",
    "  host_thumbnail_url TEXT,\n",
    "  host_picture_url TEXT,\n",
    "  host_listings_count INT,\n",
    "  host_total_listings_count INT,\n",
    "  host_verifications TEXT,\n",
    "  host_has_profile_pic BOOLEAN,\n",
    "  host_identity_verified BOOLEAN,\n",
    "  neighbourhood TEXT,\n",
    "  neighbourhood_cleansed TEXT,\n",
    "  neighbourhood_group_cleansed TEXT,\n",
    "  latitude FLOAT,\n",
    "  longitude FLOAT,\n",
    "  property_type TEXT,\n",
    "  room_type TEXT,\n",
    "  accommodates INT,\n",
    "  bathrooms FLOAT,\n",
    "  bedrooms FLOAT,\n",
    "  beds FLOAT,\n",
    "  amenities JSONB,\n",
    "  price FLOAT,\n",
    "  minimum_nights INT,\n",
    "  maximum_nights INT,\n",
    "  minimum_minimum_nights INT,\n",
    "  maximum_minimum_nights INT,\n",
    "  minimum_maximum_nights INT,\n",
    "  maximum_maximum_nights INT,\n",
    "  minimum_nights_avg_ntm FLOAT,\n",
    "  maximum_nights_avg_ntm FLOAT,\n",
    "  has_availability BOOLEAN,\n",
    "  availability_30 INT,\n",
    "  availability_60 INT,\n",
    "  availability_90 INT,\n",
    "  availability_365 INT,\n",
    "  calendar_last_scraped DATE,\n",
    "  number_of_reviews INT,\n",
    "  number_of_reviews_ltm INT,\n",
    "  number_of_reviews_l30d INT,\n",
    "  first_review DATE,\n",
    "  last_review DATE,\n",
    "  review_scores_rating FLOAT,\n",
    "  review_scores_accuracy FLOAT,\n",
    "  review_scores_cleanliness FLOAT,\n",
    "  review_scores_checkin FLOAT,\n",
    "  review_scores_communication FLOAT,\n",
    "  review_scores_location FLOAT,\n",
    "  review_scores_value FLOAT,\n",
    "  instant_bookable BOOLEAN,\n",
    "  calculated_host_listings_count INT,\n",
    "  calculated_host_listings_count_entire_homes INT,\n",
    "  calculated_host_listings_count_private_rooms INT,\n",
    "  reviews_per_month FLOAT,\n",
    "  missing_data_flag BOOLEAN\n",
    ");\n",
    "```\n",
    "Mit dieser finalen Struktur stehen nun bereinigte, konsistent typisierte und vollst√§ndig analysierbare Daten zur Verf√ºgung f√ºr alle nachfolgenden Analysen und Modellierungen.\n",
    "\n",
    "### 8. Finaler Datenimport, Typkonvertierung und strukturierte Bereinigung in `cleaned_listings`\n",
    "Nach mehreren Wochen aktiver Analyse durch die Gruppenmitglieder konnten die tats√§chliche Relevanz und der Nutzungszweck vieler *Medium* und *Low Impact*-Felder deutlich besser eingesch√§tzt werden. Auf dieser Grundlage wurde beschlossen, die bestehende `cleaned_listings`-Tabelle final zu √ºberarbeiten und dabei eine umfassende Typkonvertierung sowie gezielte Bereinigungen durchzuf√ºhren.\n",
    "\n",
    "Ziel dieses Schritts war es, die noch enthaltenen inkonsistenten oder fehleranf√§lligen Werteformate (z.‚ÄØB. `\"N/A\"`, Prozentzeichen, W√§hrungszeichen) systematisch zu bereinigen und in ein robustes Datenmodell zu √ºberf√ºhren, das f√ºr analytische und statistische Auswertungen direkt einsetzbar ist ‚Äì ohne zus√§tzliche Nachbearbeitung in Python oder anderen Tools.\n",
    "\n",
    "**Beispiele f√ºr durchgef√ºhrte Konvertierungen:**\n",
    "- Textuelle Platzhalter wie `\"N/A\"` wurden in `NULL` umgewandelt.\n",
    "- Prozentwerte wie `\"95%\"` wurden bereinigt und als numerische Werte `95` gespeichert.\n",
    "- W√§hrungsangaben wie `\"$123.00\"` wurden durch Entfernen von Sonderzeichen in numerische Gleitkommazahlen `FLOAT` √ºberf√ºhrt.\n",
    "- Wahrheitswerte wie `\"t\"` / `\"f\"` wurden als `BOOLEAN` gespeichert.\n",
    "- JSON-Textfelder `amenities` wurden korrekt in das Datentypformat `JSONB` √ºberf√ºhrt.\n",
    "\n",
    "**Das folgende SQL-Statement zeigt die konkrete Umsetzung:**\n",
    "```sql\n",
    "INSERT INTO cleaned_listings (\n",
    "  id, listing_url, scrape_id, last_scraped, source, name, description,\n",
    "  neighborhood_overview, picture_url, host_id, host_url, host_name, host_since,\n",
    "  host_location, host_about, host_response_time, host_response_rate,\n",
    "  host_acceptance_rate, host_is_superhost, host_thumbnail_url, host_picture_url,\n",
    "  host_listings_count, host_total_listings_count, host_verifications,\n",
    "  host_has_profile_pic, host_identity_verified, neighbourhood, \n",
    "  neighbourhood_cleansed, neighbourhood_group_cleansed, latitude, longitude,\n",
    "  property_type, room_type, accommodates, bathrooms, bedrooms, beds, amenities,\n",
    "  price, minimum_nights, maximum_nights, minimum_minimum_nights,\n",
    "  maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights,\n",
    "  minimum_nights_avg_ntm, maximum_nights_avg_ntm, has_availability,\n",
    "  availability_30, availability_60, availability_90, availability_365,\n",
    "  calendar_last_scraped, number_of_reviews, number_of_reviews_ltm,\n",
    "  number_of_reviews_l30d, first_review, last_review, review_scores_rating,\n",
    "  review_scores_accuracy, review_scores_cleanliness, review_scores_checkin,\n",
    "  review_scores_communication, review_scores_location, review_scores_value,\n",
    "  instant_bookable, calculated_host_listings_count,\n",
    "  calculated_host_listings_count_entire_homes,\n",
    "  calculated_host_listings_count_private_rooms, reviews_per_month,\n",
    "  missing_data_flag\n",
    ")\n",
    "SELECT\n",
    "  NULLIF(id::TEXT, 'N/A')::NUMERIC,\n",
    "  listing_url,\n",
    "  NULLIF(scrape_id::TEXT, 'N/A')::NUMERIC,\n",
    "  NULLIF(last_scraped::TEXT, 'N/A')::DATE,\n",
    "  source,\n",
    "  name,\n",
    "  description,\n",
    "  neighborhood_overview,\n",
    "  picture_url,\n",
    "  NULLIF(host_id::TEXT, 'N/A')::NUMERIC,\n",
    "  host_url,\n",
    "  host_name,\n",
    "  NULLIF(host_since::TEXT, 'N/A')::DATE,\n",
    "  host_location,\n",
    "  host_about,\n",
    "  host_response_time,\n",
    "  host_response_rate,\n",
    "  NULLIF(REPLACE(host_acceptance_rate::TEXT, '%', ''), 'N/A')::BIGINT,\n",
    "  host_is_superhost = 't',\n",
    "  host_thumbnail_url,\n",
    "  host_picture_url,\n",
    "  NULLIF(host_listings_count::TEXT, 'N/A')::NUMERIC,\n",
    "  NULLIF(host_total_listings_count::TEXT, 'N/A')::NUMERIC,\n",
    "  host_verifications,\n",
    "  host_has_profile_pic = 't',\n",
    "  host_identity_verified = 't',\n",
    "  neighbourhood,\n",
    "  neighbourhood_cleansed,\n",
    "  neighbourhood_group_cleansed,\n",
    "  NULLIF(latitude::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(longitude::TEXT, 'N/A')::FLOAT,\n",
    "  property_type,\n",
    "  room_type,\n",
    "  NULLIF(accommodates::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(bathrooms::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(bedrooms::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(beds::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(amenities::TEXT, 'N/A')::JSONB,\n",
    "  NULLIF(REPLACE(REPLACE(\"price\", ',', ''), '$', '')::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(minimum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(maximum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(minimum_minimum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(maximum_minimum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(minimum_maximum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(maximum_maximum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(minimum_nights_avg_ntm::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(maximum_nights_avg_ntm::TEXT, 'N/A')::FLOAT,\n",
    "  has_availability = 't',\n",
    "  NULLIF(availability_30::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(availability_60::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(availability_90::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(availability_365::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(calendar_last_scraped::TEXT, 'N/A')::DATE,\n",
    "  NULLIF(number_of_reviews::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(number_of_reviews_ltm::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(number_of_reviews_l30d::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(first_review::TEXT, 'N/A')::DATE,\n",
    "  NULLIF(last_review::TEXT, 'N/A')::DATE,\n",
    "  NULLIF(review_scores_rating::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_accuracy::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_cleanliness::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_checkin::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_communication::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_location::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_value::TEXT, 'N/A')::FLOAT,\n",
    "  instant_bookable = 't',\n",
    "  NULLIF(calculated_host_listings_count::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(calculated_host_listings_count_entire_homes::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(calculated_host_listings_count_private_rooms::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(reviews_per_month::TEXT, 'N/A')::FLOAT,\n",
    "  missing_data_flag\n",
    "FROM cleaned_listings_backup_14_05_2025;\n",
    "```\n",
    "Diese finale Version der Tabelle cleaned_listings bildet den Ausgangspunkt f√ºr alle weiterf√ºhrenden Analysen und Modelle. \n",
    "Sie stellt sicher, dass s√§mtliche strukturellen Inkonsistenzen beseitigt wurden und bietet ein hohes Mass an Datenqualit√§t, Nachvollziehbarkeit und Robustheit.\n",
    "\n",
    "\n",
    "## Datenquellen und -beschaffung via Supabase f√ºr `SellingPrices`\n",
    "\n",
    "Die Dataclass `SellingPrices` wurde als Erg√§nzung bei der Ausarbeitung der Objectives erstellt und mit Daten zu *Verkaufspreise (Median) pro Wohnung und pro Quadratmeter Wohnungsfl√§che im Stockwerkeigentum, nach Zimmerzahl und Quartier* der [Stadt Z√ºrich Open Data](https://data.stadt-zuerich.ch/dataset/bau_hae_preis_stockwerkeigentum_zimmerzahl_stadtquartier_od5155) bef√ºllt.\n",
    "\n",
    "Die Tabelle `selling_prices`ist nicht so reich an Attributen wie die `listings` Tabelle von Airbnb. Desweiteren ben√∂tigten wir fast nur die Preise, weshalb die meisten Attribute dieser Tabelle ignoriert werden konnten.\n",
    "\n",
    "In diesem Abschnitt wird Schritt f√ºr Schritt beschrieben, wie die `selling_prices` Tabelle f√ºr die Datenanalysen vorbereitet wurde.\n",
    "\n",
    "### 1. Typanpassung und Neuanlage f√ºr `cleaned_selling_prices`\n",
    "Analog zur Bearbeitung der `listings`-Tabelle wurde auch f√ºr die Wohnpreisdaten eine neue, typisierte Tabelle erstellt. Ziel war es, Datentypen so anzupassen, dass eine direkte Weiterverarbeitung der Werte m√∂glich ist ‚Äì insbesondere in Bezug auf numerische Analysen.\n",
    "\n",
    "Beim Import der CSV-Datei wurden alle Spalten zun√§chst als Text `STRING` interpretiert. F√ºr die Preisinformationen war dies jedoch ungeeignet, da diese Felder in sp√§teren Analysen arithmetisch verarbeitet werden sollen (z.‚ÄØB. Mittelwertberechnungen, Preisvergleiche, Visualisierungen). Deshalb wurden gezielt die drei preisbezogenen Attribute in den passenden numerischen Datentyp `INTEGER` √ºberf√ºhrt:\n",
    "- `HAPreisWohnflaeche`: Preis pro Quadratmeter\n",
    "- `HAMedianPreis`: Medianpreis\n",
    "- `HASumPreis`: Gesamtpreis\n",
    "\n",
    "```sql\n",
    "CREATE TABLE cleaned_ha_preise (\n",
    "  Stichtagdatjahr INTEGER,\n",
    "  DatenstandCd TEXT,\n",
    "  HAArtLevel1Sort INTEGER,\n",
    "  HAArtLevel1Cd INTEGER,\n",
    "  HAArtLevel1Lang TEXT,\n",
    "  HASTWESort INTEGER,\n",
    "  HASTWECd TEXT,\n",
    "  HASTWELang TEXT,\n",
    "  RaumSort TEXT,\n",
    "  RaumCd TEXT,\n",
    "  RaumLang TEXT,\n",
    "  AnzZimmerLevel2Sort_noDM INTEGER,\n",
    "  AnzZimmerLevel2Cd_noDM INTEGER,\n",
    "  AnzZimmerLevel2Lang_noDM TEXT,\n",
    "  AnzHA TEXT,\n",
    "  HAPreisWohnflaeche INTEGER,\n",
    "  HAMedianPreis INTEGER,\n",
    "  HASumPreis INTEGER\n",
    ");\n",
    "```\n",
    "\n",
    "### 2. Filtern und √úbertragen g√ºltiger Preisdaten f√ºr `cleaned_selling_prices`\n",
    "\n",
    "Um sicherzustellen, dass ausschliesslich qualitativ hochwertige und verarbeitbare Daten in die finale Analyse gelangen, wurden aus der Zwischen- bzw. Staging-Tabelle `stage_selling_prices` nur jene Datens√§tze in die endg√ºltige Tabelle `cleaned_selling_prices` √ºbernommen, bei denen **alle drei preisbezogenen Attribute g√ºltige numerische Werte enthalten**.\n",
    "\n",
    "Insbesondere sollten folgende Fehlerquellen ausgeschlossen werden:\n",
    "- Leere Strings (`''`)\n",
    "- Nicht-numerische Eintr√§ge (z.‚ÄØB. `'K'` bei `HASumPreis`)\n",
    "- Formatierungsfehler (z.‚ÄØB. nicht ganzzahlig)\n",
    "- `NULL`-Werte\n",
    "\n",
    "Durch die Kombination von `IS NOT NULL`, expliziten Ausschl√ºssen und einem regul√§ren Ausdruck `~ '^\\d+$'` wurde sichergestellt, dass nur **reine Ganzzahlen** verarbeitet werden, die f√ºr Aggregationen, Vergleiche und Visualisierungen ohne vorherige Umwandlung nutzbar sind.\n",
    "\n",
    "```sql\n",
    "INSERT INTO cleaned_selling_prices( \n",
    "  Stichtagdatjahr, DatenstandCd, HAArtLevel1Sort, HAArtLevel1Cd, HAArtLevel1Lang,\n",
    "  HASTWESort, HASTWECd, HASTWELang, RaumSort, RaumCd, RaumLang,\n",
    "  AnzZimmerLevel2Sort_noDM, AnzZimmerLevel2Cd_noDM, AnzZimmerLevel2Lang_noDM,\n",
    "  AnzHA, HAPreisWohnflaeche, HAMedianPreis, HASumPreis\n",
    ")\n",
    "SELECT\n",
    "  Stichtagdatjahr,\n",
    "  DatenstandCd,\n",
    "  HAArtLevel1Sort,\n",
    "  HAArtLevel1Cd,\n",
    "  HAArtLevel1Lang,\n",
    "  HASTWESort,\n",
    "  HASTWECd,\n",
    "  HASTWELang,\n",
    "  RaumSort,\n",
    "  RaumCd,\n",
    "  RaumLang,\n",
    "  AnzZimmerLevel2Sort_noDM,\n",
    "  AnzZimmerLevel2Cd_noDM,\n",
    "  AnzZimmerLevel2Lang_noDM,\n",
    "  AnzHA,\n",
    "  NULLIF(HAPreisWohnflaeche, '')::INTEGER,\n",
    "  NULLIF(HAMedianPreis, '')::INTEGER,\n",
    "  NULLIF(HASumPreis, '')::INTEGER\n",
    "FROM stage_selling_prices\n",
    "WHERE\n",
    "  HAPreisWohnflaeche IS NOT NULL AND HAPreisWohnflaeche <> '' AND HAPreisWohnflaeche ~ '^\\d+$' AND\n",
    "  HAMedianPreis IS NOT NULL AND HAMedianPreis <> '' AND HAMedianPreis ~ '^\\d+$' AND\n",
    "  HASumPreis IS NOT NULL AND HASumPreis <> '' AND HASumPreis <> 'K' AND HASumPreis ~ '^\\d+$';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04732f87",
   "metadata": {},
   "source": "## Datenaufbereitung f√ºr Analyse"
  },
  {
   "cell_type": "code",
   "id": "f467e925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:58:53.792233Z",
     "start_time": "2025-06-02T13:58:47.108870Z"
    }
   },
   "source": [
    "# === Bibliotheken importieren ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import nltk\n",
    "import dataclasses\n",
    "\n",
    "# NLTK Ressourcen (Downloads)\n",
    "nltk_resources = ['wordnet', 'stopwords', 'punkt', 'omw-1.4']\n",
    "for resource in nltk_resources:\n",
    "    try:\n",
    "        resource_path_part = f'corpora/{resource}.zip' if resource in ['wordnet', 'stopwords', 'omw-1.4'] else f'tokenizers/{resource}.zip'\n",
    "        nltk.data.find(resource_path_part)\n",
    "        print(f\"NLTK Ressource '{resource}' bereits vorhanden.\")\n",
    "    except LookupError: # Korrektes Abfangen von LookupError\n",
    "        print(f\"NLTK Ressource '{resource}' nicht gefunden. Versuche Download...\")\n",
    "        try:\n",
    "            nltk.download(resource, quiet=False)\n",
    "            print(f\"NLTK Ressource '{resource}' erfolgreich heruntergeladen.\")\n",
    "        except Exception as e: # Allgemeiner Fehler beim Download\n",
    "            print(f\"Fehler beim Herunterladen von '{resource}': {e}. Bitte manuell pr√ºfen mit nltk.download('{resource}').\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (mean_squared_error, r2_score)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Importiere den Service und die Modelle\n",
    "# Stelle sicher, dass airbnb_analysis_service.py und bina_models.py im selben Verzeichnis oder im Python-Pfad sind.\n",
    "try:\n",
    "    from airbnb_analysis_service import AirbnbAnalysisService\n",
    "    from bina_models import Listing, SellingPrices\n",
    "except ImportError as e:\n",
    "    print(f\"Fehler beim Importieren des Services oder der Modelle: {e}\")\n",
    "    AirbnbAnalysisService = None; Listing = None; SellingPrices = None\n",
    "\n",
    "# Plotting-Einstellungen\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "# %matplotlib inline # Zeile f√ºr Jupyter Notebooks, um Plots inline anzuzeigen (kann hier auskommentiert bleiben)\n",
    "\n",
    "# === Daten laden via Service ===\n",
    "listings_df = pd.DataFrame() # Wird direkt mit den Daten aus dem Service bef√ºllt\n",
    "selling_prices_df = pd.DataFrame()\n",
    "\n",
    "if AirbnbAnalysisService:\n",
    "    try:\n",
    "        service = AirbnbAnalysisService()\n",
    "        print(\"Lade Airbnb Listings via Service (aus Supabase `cleaned_listings`)...\")\n",
    "        listings_objects = service.get_listings()\n",
    "\n",
    "        if listings_objects and isinstance(listings_objects, list) and len(listings_objects) > 0:\n",
    "            if hasattr(listings_objects[0], 'model_dump'): listings_data = [l.model_dump(exclude_none=True) for l in listings_objects]\n",
    "            elif hasattr(listings_objects[0], 'dict'): listings_data = [l.dict(exclude_none=True) for l in listings_objects]\n",
    "            elif dataclasses.is_dataclass(listings_objects[0]): listings_data = [dataclasses.asdict(l) for l in listings_objects]\n",
    "            else: listings_data = [l.__dict__ for l in listings_objects]\n",
    "            listings_df = pd.DataFrame(listings_data) # Direkte Zuweisung zu listings_df\n",
    "            print(f\"Airbnb Listings erfolgreich geladen. Shape: {listings_df.shape}\")\n",
    "        else:\n",
    "            print(\"Keine Listings-Daten vom Service erhalten oder Liste ist leer.\")\n",
    "\n",
    "        print(\"\\nLade Immobilien-Verkaufspreise via Service (aus Supabase `cleaned_selling_prices`)...\")\n",
    "        selling_prices_objects = service.get_selling_prices()\n",
    "        if selling_prices_objects and isinstance(selling_prices_objects, list) and len(selling_prices_objects) > 0:\n",
    "            if hasattr(selling_prices_objects[0], 'model_dump'): selling_prices_data = [sp.model_dump(exclude_none=True) for sp in selling_prices_objects]\n",
    "            elif hasattr(selling_prices_objects[0], 'dict'): selling_prices_data = [sp.dict(exclude_none=True) for sp in selling_prices_objects]\n",
    "            elif dataclasses.is_dataclass(selling_prices_objects[0]): selling_prices_data = [dataclasses.asdict(sp) for sp in selling_prices_objects]\n",
    "            else: selling_prices_data = [sp.__dict__ for sp in selling_prices_objects]\n",
    "            selling_prices_df = pd.DataFrame(selling_prices_data) # Direkte Zuweisung zu selling_prices_df\n",
    "            print(f\"Immobilien-Verkaufspreise erfolgreich geladen. Shape: {selling_prices_df.shape}\")\n",
    "        else:\n",
    "            print(\"Keine Verkaufspreis-Daten vom Service erhalten oder Liste ist leer.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden der Daten via Service: {e}\")\n",
    "else:\n",
    "    print(\"AirbnbAnalysisService konnte nicht importiert werden. Daten k√∂nnen nicht geladen werden.\")\n",
    "\n",
    "# === Erste Inspektion der (aus Supabase geladenen) Daten ===\n",
    "if not listings_df.empty:\n",
    "    print(\"\\n--- Listings DataFrame (aus Supabase): Erste 5 Zeilen ---\"); print(listings_df.head())\n",
    "    print(f\"\\n--- Listings DataFrame (aus Supabase): Dimensionen --- \\nShape: {listings_df.shape}\")\n",
    "    print(\"\\n--- Listings DataFrame (aus Supabase): Info ---\"); listings_df.info()\n",
    "    print(\"\\n--- Listings DataFrame (aus Supabase): Fehlende Werte (Top 10) ---\"); print(listings_df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print(\"Listings DataFrame ist leer oder konnte nicht geladen werden.\")\n",
    "\n",
    "if not selling_prices_df.empty:\n",
    "    print(\"\\n\\n--- Selling Prices DataFrame (aus Supabase): Erste 5 Zeilen ---\"); print(selling_prices_df.head())\n",
    "    print(\"\\n--- Selling Prices DataFrame (aus Supabase): Info ---\"); selling_prices_df.info()\n",
    "else:\n",
    "    print(\"\\nSelling Prices DataFrame ist leer oder konnte nicht geladen werden.\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mseaborn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msns\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mast\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "ec1095bc",
   "metadata": {},
   "source": [
    "## Finale Datenanpassungen und DataFrame Engineering f√ºr Analyse\n",
    "\n",
    "Obwohl die Daten in Supabase grundlegend bereinigt wurden, f√ºhren wir hier finale Anpassungen durch, die spezifisch f√ºr die Analysen und Modellierungen in diesem Notebook notwendig sind. Wir erstellen eine Arbeitskopie `df_analysis` von listings_df`."
   ]
  },
  {
   "cell_type": "code",
   "id": "84d2fa25",
   "metadata": {},
   "source": [
    "df_analysis = pd.DataFrame() # Initialisiere df_analysis als leeren DataFrame\n",
    "\n",
    "if not listings_df.empty:\n",
    "    df_analysis = listings_df.copy() # Arbeitskopie erstellen\n",
    "\n",
    "    # 1. Preisspalte ('price') - finale Pr√ºfung und Filterung\n",
    "    # Annahme: 'price' ist bereits float aus Supabase (gem√§ss bina_models.Listing.price: Optional[float])\n",
    "    if 'price' in df_analysis.columns:\n",
    "        df_analysis['price'] = pd.to_numeric(df_analysis['price'], errors='coerce')\n",
    "        df_analysis.dropna(subset=['price'], inplace=True)\n",
    "        if not df_analysis.empty and df_analysis['price'].nunique() > 1 :\n",
    "            price_q_low_notebook = df_analysis['price'].quantile(0.005)\n",
    "            price_q_high_notebook = df_analysis['price'].quantile(0.995)\n",
    "            if pd.notna(price_q_low_notebook) and pd.notna(price_q_high_notebook):\n",
    "                 df_analysis = df_analysis[df_analysis['price'].between(price_q_low_notebook, price_q_high_notebook, inclusive='both')]\n",
    "    else:\n",
    "        print(f\"KRITISCH: Preisspalte 'price' fehlt.\"); df_analysis['price'] = np.nan\n",
    "\n",
    "    # 2. Numerische Spalten: Finale Imputation f√ºr Modellierung\n",
    "    # 'bathrooms' ist Optional[float]\n",
    "    # 'beds' ist Optional[float]\n",
    "    numeric_cols_to_impute_final = [\n",
    "        'bedrooms', 'bathrooms', 'accommodates', 'beds',\n",
    "        'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "        'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "        'review_scores_value', 'reviews_per_month', 'number_of_reviews', 'availability_365',\n",
    "        'host_listings_count', 'host_total_listings_count'\n",
    "    ]\n",
    "    for col in numeric_cols_to_impute_final:\n",
    "        if col in df_analysis.columns:\n",
    "            df_analysis[col] = pd.to_numeric(df_analysis[col], errors='coerce')\n",
    "            if df_analysis[col].isnull().sum() > 0:\n",
    "                if not df_analysis[col].isnull().all():\n",
    "                    df_analysis[col] = df_analysis[col].fillna(df_analysis[col].median())\n",
    "                else:\n",
    "                     df_analysis[col] = df_analysis[col].fillna(0)\n",
    "        else:\n",
    "            print(f\"Info: Numerische Spalte '{col}' f√ºr finale Imputation fehlt.\"); df_analysis[col] = np.nan\n",
    "\n",
    "    # 3. Prozentuale Host-Metriken\n",
    "    # 'host_response_rate': Optional[str] (z.B. \"90%\")\n",
    "    if 'host_response_rate' in df_analysis.columns:\n",
    "        df_analysis['host_response_rate'] = df_analysis['host_response_rate'].replace(['N/A', None, ''], np.nan)\n",
    "        # Da es als String von Supabase kommen kann (gem. bina_models)\n",
    "        if df_analysis['host_response_rate'].dropna().apply(lambda x: isinstance(x, str)).any():\n",
    "             df_analysis['host_response_rate'] = df_analysis['host_response_rate'].str.rstrip('%').astype(float) / 100.0\n",
    "        else:\n",
    "            df_analysis['host_response_rate'] = pd.to_numeric(df_analysis['host_response_rate'], errors='coerce')\n",
    "            mask_hrr_analysis = (df_analysis['host_response_rate'] > 1.0) & (df_analysis['host_response_rate'] <= 100.0)\n",
    "            df_analysis.loc[mask_hrr_analysis, 'host_response_rate'] = df_analysis.loc[mask_hrr_analysis, 'host_response_rate'] / 100.0\n",
    "\n",
    "        if not df_analysis['host_response_rate'].isnull().all(): df_analysis['host_response_rate'] = df_analysis['host_response_rate'].fillna(df_analysis['host_response_rate'].median())\n",
    "        else: df_analysis['host_response_rate'] = df_analysis['host_response_rate'].fillna(0.5)\n",
    "    else:\n",
    "        print(f\"Info: Spalte 'host_response_rate' fehlt.\"); df_analysis['host_response_rate'] = np.nan\n",
    "\n",
    "    # 'host_acceptance_rate_percent': Optional[int] (z.B. 90 f√ºr 90%)\n",
    "    if 'host_acceptance_rate_percent' in df_analysis.columns:\n",
    "        df_analysis['host_acceptance_rate_percent'] = pd.to_numeric(df_analysis['host_acceptance_rate_percent'], errors='coerce') / 100.0\n",
    "        if not df_analysis['host_acceptance_rate_percent'].isnull().all(): df_analysis['host_acceptance_rate_percent'] = df_analysis['host_acceptance_rate_percent'].fillna(df_analysis['host_acceptance_rate_percent'].median())\n",
    "        else: df_analysis['host_acceptance_rate_percent'] = df_analysis['host_acceptance_rate_percent'].fillna(0.5)\n",
    "    else:\n",
    "        print(f\"Info: Spalte 'host_acceptance_rate_percent' fehlt.\"); df_analysis['host_acceptance_rate_percent'] = np.nan\n",
    "\n",
    "    for rate_col in ['host_response_rate', 'host_acceptance_rate_percent']:\n",
    "        if rate_col in df_analysis.columns: df_analysis[rate_col] = np.clip(df_analysis[rate_col], 0, 1)\n",
    "\n",
    "    # 4. Amenities ('amenities' ist Optional[list[str]] in bina_models)\n",
    "    if 'amenities' in df_analysis.columns:\n",
    "        def count_amenities_from_model_list(amenity_input): # Bereits angepasst f√ºr Listen\n",
    "            if isinstance(amenity_input, list): return len(amenity_input)\n",
    "            if pd.isna(amenity_input): return 0\n",
    "            if isinstance(amenity_input, str): # Seltener Fallback f√ºr Strings\n",
    "                 if amenity_input in ['[]', '{}', ''] or not amenity_input.strip(): return 0\n",
    "                 try:\n",
    "                     parsed_list = ast.literal_eval(amenity_input)\n",
    "                     return len(parsed_list) if isinstance(parsed_list, list) else 0\n",
    "                 except: return 0\n",
    "            return 0\n",
    "        df_analysis['num_amenities'] = df_analysis['amenities'].apply(count_amenities_from_model_list)\n",
    "    else:\n",
    "        df_analysis['num_amenities'] = 0; print(f\"Warnung: Spalte 'amenities' nicht gefunden.\")\n",
    "\n",
    "    # 5. Superhost Status ('host_is_superhost' ist Optional[bool])\n",
    "    if 'host_is_superhost' in df_analysis.columns:\n",
    "        df_analysis['host_is_superhost'] = df_analysis['host_is_superhost'].map({True: 1, False: 0}).fillna(0).astype(int)\n",
    "    else:\n",
    "        df_analysis['host_is_superhost'] = 0; print(f\"Info: Spalte 'host_is_superhost' fehlt, wird mit 0 initialisiert.\")\n",
    "\n",
    "    # 6. Host Response Time ('host_response_time' ist Optional[str])\n",
    "    if 'host_response_time' in df_analysis.columns:\n",
    "        df_analysis['host_response_time'] = df_analysis['host_response_time'].fillna('N/A').astype('category')\n",
    "    else:\n",
    "        df_analysis['host_response_time'] = 'N/A'; df_analysis['host_response_time'] = df_analysis['host_response_time'].astype('category')\n",
    "\n",
    "    # 7. Host Identity Verified ('host_identity_verified' ist Optional[bool])\n",
    "    if 'host_identity_verified' in df_analysis.columns:\n",
    "        df_analysis['host_identity_verified'] = df_analysis['host_identity_verified'].map({True: 1, False: 0}).fillna(0).astype(int)\n",
    "    else:\n",
    "        df_analysis['host_identity_verified'] = 0\n",
    "\n",
    "    # 8. Standortspalte (`loc_col_for_analysis_notebook`) - Auswahl und Sicherstellung des Typs\n",
    "    # Definiere eine lokale Variable f√ºr die Standortspalte, die in diesem Notebook verwendet wird\n",
    "    loc_col_for_analysis_notebook = None\n",
    "    if 'neighbourhood_group_cleansed' in df_analysis.columns and df_analysis['neighbourhood_group_cleansed'].nunique() >= 1:\n",
    "        loc_col_for_analysis_notebook = 'neighbourhood_group_cleansed'\n",
    "    elif 'neighbourhood_cleansed' in df_analysis.columns and df_analysis['neighbourhood_cleansed'].nunique() >= 1:\n",
    "        loc_col_for_analysis_notebook = 'neighbourhood_cleansed'\n",
    "    elif 'neighbourhood' in df_analysis.columns and df_analysis['neighbourhood'].nunique() >=1:\n",
    "        loc_col_for_analysis_notebook = 'neighbourhood'\n",
    "\n",
    "    if loc_col_for_analysis_notebook:\n",
    "        print(f\"Verwende '{loc_col_for_analysis_notebook}' als prim√§re Standortspalte f√ºr Analysen in diesem Notebook.\")\n",
    "        df_analysis[loc_col_for_analysis_notebook] = df_analysis[loc_col_for_analysis_notebook].fillna('Unknown').astype(str)\n",
    "    else:\n",
    "        print(f\"KRITISCH: Keine valide Standortspalte gefunden. Erstelle 'location_fallback'.\");\n",
    "        df_analysis['location_fallback'] = 'Unknown'; loc_col_for_analysis_notebook = 'location_fallback'\n",
    "    # Stelle sicher, dass die verwendete Spalte existiert, auch wenn es der Fallback ist\n",
    "    if loc_col_for_analysis_notebook not in df_analysis.columns: df_analysis[loc_col_for_analysis_notebook] = 'Unknown'\n",
    "    df_analysis[loc_col_for_analysis_notebook] = df_analysis[loc_col_for_analysis_notebook].astype(str)\n",
    "\n",
    "\n",
    "    # 9. Room Type ('room_type' ist Optional[str])\n",
    "    if 'room_type' in df_analysis.columns: df_analysis['room_type'] = df_analysis['room_type'].fillna('Unknown').astype('category')\n",
    "    else: print(f\"KRITISCH: Spalte 'room_type' fehlt.\"); df_analysis['room_type'] = 'Unknown'; df_analysis['room_type'] = df_analysis['room_type'].astype('category')\n",
    "\n",
    "    # 10. Textspalten f√ºr NLP (UC4)\n",
    "    text_cols_nlp_list = ['description', 'name', 'neighborhood_overview', 'host_about']\n",
    "    for col in text_cols_nlp_list:\n",
    "        if col in df_analysis.columns: df_analysis[col] = df_analysis[col].fillna('').astype(str)\n",
    "        else: print(f\"Info: Textspalte '{col}' f√ºr NLP fehlt.\"); df_analysis[col] = ''\n",
    "\n",
    "    # Log-Transformation des Preises f√ºr Regression (UC2) und ggf. andere Analysen\n",
    "    if 'price' in df_analysis.columns and df_analysis['price'].nunique() > 1 and pd.api.types.is_numeric_dtype(df_analysis['price']):\n",
    "        df_analysis['price_log'] = np.log1p(df_analysis['price'])\n",
    "    else:\n",
    "        df_analysis['price_log'] = np.nan\n",
    "\n",
    "    # Finale Bereinigung von Zeilen, falls Preis nach allem immer noch NaN ist\n",
    "    if 'price' in df_analysis.columns: df_analysis.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "    print(f\"\\nFinale Datenanpassungen im Notebook abgeschlossen. Shape des DataFrames `df_analysis`: {df_analysis.shape}\")\n",
    "    if df_analysis.empty: print(\"WARNUNG: DataFrame `df_analysis` ist nach finalen Anpassungen leer!\")\n",
    "    else:\n",
    "        print(\"\\n√úberpr√ºfung der wichtigsten Spalten nach finaler Anpassung (erste 5 Zeilen von `df_analysis`):\")\n",
    "        cols_to_show_final = ['price', loc_col_for_analysis_notebook, 'room_type', 'accommodates', 'bedrooms',\n",
    "                              'bathrooms', 'num_amenities', 'host_is_superhost',\n",
    "                              'review_scores_rating', 'host_response_time',\n",
    "                              'host_response_rate', 'host_acceptance_rate_percent', 'price_log']\n",
    "        existing_cols_to_show_final = [col for col in cols_to_show_final if col in df_analysis.columns]\n",
    "        if existing_cols_to_show_final:\n",
    "          print(df_analysis[existing_cols_to_show_final].head())\n",
    "else:\n",
    "    print(\"Urspr√ºnglicher Listings DataFrame (`listings_df`) ist leer. Datenaufbereitung √ºbersprungen.\")\n",
    "    df_analysis = pd.DataFrame()\n",
    "    loc_col_for_analysis_notebook = 'location_fallback' # Fallback f√ºr loc_col_for_analysis_notebook"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d089dc0",
   "metadata": {},
   "source": [
    "from airbnb_analysis_service import AirbnbAnalysisService\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # create service class\n",
    "    airbnbAnalysis = AirbnbAnalysisService()\n",
    "\n",
    "    # get all tables in form of a list\n",
    "    listings = airbnbAnalysis.get_listings()\n",
    "\n",
    "    print(f\"listings {listings[0]}\")\n",
    "\n",
    "    # Schritt 1: Umwandeln in DataFrames\n",
    "    listings_df = pd.DataFrame([l.__dict__ for l in listings])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8fb0d95",
   "metadata": {},
   "source": [
    "# Step 3: Analyzing Data\n",
    "\n",
    "## Objective 1 ‚Äì Marktpotenzial und Standortanalyse\n",
    "Im Rahmen dieses ersten Untersuchungsziels soll eine fundierte Analyse des Marktpotenzials sowie eine differenzierte Standortbewertung f√ºr Kurzzeitvermietung √ºber Airbnb in der stadt Z√ºrich erfolgen. Ziel ist es, f√ºr die InvestZurich AG belastbare Entscheidungsgrundlagen zu schaffen, um vielversprechende Investitionsgebiete zu identifizieren und zu priorisieren.\n",
    "\n",
    "Z√ºrich ist als internationale Wirtschaftsmetropole, Bildungsstandort und Tourismusziel von konstant hoher Nachfrage gepr√§gt. Besonders im Bereich tempor√§rer Unterk√ºnfte - wie sie Airbnb bietet - ergeben sich daraus regelm√§ssig neue Marktchance, aber auch dynamische Herausforderungen. F√ºr eine Immobilien-Investmentstrategie in diesem Segment sind sowohl mikrogeografische Unterschiede zwischen Quartieren als auch spezifische Angebots- und Nachfragestrukturen zentral.\n",
    "\n",
    "Daher verfolgt dieses Kapitel die Frage, wo innerhalb Z√ºrich das gr√∂sste Potenzial f√ºr Airbnb-Investitionen liegt - unter Ber√ºcksichtigung von Preisniveau, Nachfrageintensit√§t und Angebotsstrktur je Kreis. Zus√§tzlich wird untersucht, welche Wohnungstypen (z.B. Anzahl Zimmer, Wohnungsgr√∂sse) besonders gefragt oder unterversorgt sind, um daraus konkrete Handlungsempfehlungen f√ºr die k√ºnftige Immobilienauswahl ableiten zu k√∂nnen.\n",
    "\n",
    "Zur Beantwortung dieser fragestellungen werden verschiedene Datenquellen herangezogen, explorative Visualisierungen erstellt und relevante statistische Kennzahlen berechnet.\n",
    "\n",
    "### Anzahl Listings pro Kreis\n",
    "Ein zentraler Ausgangspunkt zur Analyse des Marktpotenzials im Z√ºrcher Airbnb-Markt ist die Betrachtung der derzeitigen Angebotsverteilung √ºber die verschiedenen Stadtkreise hinweg. Die folgende Visualisierung zeigt die absolute Anzahl an Airbnb-Angeboten (\"Listings\") pro Kreis. Dadurch lassen sich erste Aussagen √ºber die Marktaktivit√§t und m√∂gliche S√§ttigung oder Unterversorgung einzelner Stadtteile treffen.\n",
    "\n",
    "Die nachfolgende Darstellung zeigt die Anzahl Listing pro Kreis:"
   ]
  },
  {
   "cell_type": "code",
   "id": "eaca0cb3",
   "metadata": {},
   "source": [
    "# Gruppierung ‚Äì Anzahl Listings pro Stadtteilgruppe\n",
    "kreis_counts = listings_df[\"neighbourhood_group_cleansed\"].value_counts().reset_index()\n",
    "kreis_counts.columns = [\"neighbourhood_group_cleansed\", \"count\"]\n",
    "kreis_counts_sorted = kreis_counts.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Plot in fig1 speichern\n",
    "fig1, ax = plt.subplots(figsize=(12,6))\n",
    "bar_color = \"#5DADE2\"\n",
    "barplot = sns.barplot(\n",
    "    data=kreis_counts_sorted,\n",
    "    x=\"neighbourhood_group_cleansed\",\n",
    "    y=\"count\",\n",
    "    ax=ax,\n",
    "    color=bar_color\n",
    ")\n",
    "\n",
    "# Zahlen √ºber den Balken anzeigen\n",
    "for bar in barplot.patches:\n",
    "    height = bar.get_height()\n",
    "    barplot.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{int(height)}',\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "# Achsentitel und Design\n",
    "ax.set_title(\"Anzahl Airbnb-Listings pro Kreis in Z√ºrich\", fontsize=14)\n",
    "ax.set_xlabel(\"Kreis\")\n",
    "ax.set_ylabel(\"Anzahl Listings\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig1.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9cfa85ce",
   "metadata": {},
   "source": [
    "Wie aus der Visualisierung deutlich hervorgeht, konzentriert sich das Angebot derzeit stark auf bestimmte Stadtteile. Besonders Kreis 11 sticht mit 72 aktiven Listings hervor, gefolgt von Kreis 4 und Kreis 8 (jeweils 63) sowie Kreis 7 (60). Diese Kreise zeichnen sich offenbar durch eine bereits hohe Marktdurchdringung im Bereich Kurzzeitvermietung aus.\n",
    "\n",
    "Demgegen√ºber zeigen Kreis 10 (25 Listings), Kreis 5 (22 Listings) und insbesondere Kreis 12 (nur 3 Listings) eine deutlich geringere Pr√§senz auf Airbnb. Diese niedrigeren Zahlen k√∂nnen verschieden interpretiert werden: Einerseits k√∂nnten sie auf geringere Nachfrage oder restriktivere Regulierungen hindeuten. Andererseits besteht hier m√∂glicherweise ein bislang unerschlossenes Marktpotenzial, das gezielt erschlossen werden k√∂nnte ‚Äì etwa durch gezielte Investitionen in passende Wohnungstypen und differenzierte Angebotsstrategien.\n",
    "\n",
    "- Hohe Listings-Zahlen (z.B. Kreise 4, 8, 11): Diese Quartiere sind vermutlich stark frequentiert und bieten bereits funktionierende Gesch√§ftsmodelle. F√ºr Investoren k√∂nnten diese Bezirke trotz m√∂glicher Konkurrenz weiterhin attraktiv sein ‚Äì sofern Nachfrage, Auslastung und Preisniveau entsprechend hoch sind.\n",
    "\n",
    "- Niedrige Listings-Zahlen (z.B. Kreise 5, 10, 12): Diese Bereiche k√∂nnten neue Chancen er√∂ffnen, insbesondere wenn dort eine latente Nachfrage besteht, die bislang nicht durch Airbnb-Angebote gedeckt wurde. Eine tiefere Analyse von Besucherstr√∂men, Infrastruktur und lokalen Gegebenheiten ist hier entscheidend.\n",
    "\n",
    "### Durchschnittlicher Preis pro Nacht und Kreis\n",
    "Im zweiten Schritt der Standortanalyse richtet sich der Fokus auf die durchschnittlichen √úbernachtungspreise pro Airbnb-Listing, differenziert nach Keisen in Z√ºrich. Diese Kennzahl ist von zentraler Bedeutung f√ºr die Bewertung der potenziellen Ertragskraft eines Investments: Je h√∂her der durchschnittliche Preis pro Nacht, desto gr√∂sser ist ‚Äì bei vergleichbarer Auslastung ‚Äì das Umsatzpotenzial einer Unterkunft.\n",
    "\n",
    "Die nachfolgende Visualisierung zeigt die durchschnittlichen Preise pro Nacht (in CHF) f√ºr jedes Z√ºrcher Stadtquartier:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdff7bc6",
   "metadata": {},
   "source": [
    "# Daten filtern\n",
    "listings_df = listings_df[\n",
    "    (listings_df['price'] > 0) &\n",
    "    (listings_df['availability_365'] > 0) &\n",
    "    (listings_df['neighbourhood'].notnull())\n",
    "]\n",
    "\n",
    "# Gruppieren nach neighbourhood_group_cleansed\n",
    "group_stats = listings_df.groupby(\"neighbourhood_group_cleansed\").agg({\n",
    "    \"price\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Sortieren nach Preis\n",
    "group_stats_sorted = group_stats.sort_values(by=\"price\", ascending=False)\n",
    "\n",
    "# Plot in fig2 speichern\n",
    "fig2, ax = plt.subplots(figsize=(12,6))\n",
    "sns.barplot(data=group_stats_sorted, x=\"neighbourhood_group_cleansed\", y=\"price\", ax=ax)\n",
    "ax.set_title(\"Durchschnittlicher Preis pro Kreis / Nacht\")\n",
    "ax.set_ylabel(\"Durchschnittlicher Preis (CHF)\")\n",
    "ax.set_xlabel(\"Kreis\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Durchschnittspreise oberhalb der Balken anzeigen\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{height:.0f}',\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "fig2.tight_layout()\n",
    "\n",
    "durchschnittspreis = listings_df[\"price\"].mean()\n",
    "print(f\"Durchschnittlicher Preis aller Airbnb-Angebote: {durchschnittspreis:.2f} CHF\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e1e244d",
   "metadata": {},
   "source": [
    "Der auff√§lligste Ausreisser ist klar Kreis 2, mit einem durchschnittlichen Preis von 487 CHF pro Nacht. Dieser Wert liegt deutlich √ºber dem Marktdurchschnitt von 195 CHF und hebt sich stark von allen anderen Kreisen ab. Kreis 2 liegt direkt am Z√ºrichsee und umfasst prestigetr√§chtige Wohnlagen wie Enge und Wollishofen ‚Äì Stadtteile, die bei Touristen durch Seelage, Ruhe und Exklusivit√§t besonders gefragt sind. F√ºr Investoren bietet dieser Kreis somit ein √ºberdurchschnittlich hohes Preisniveau, das allerdings mit entsprechend hohen Immobilienpreisen und regulatorischen H√ºrden einhergehen d√ºrfte.\n",
    "\n",
    "Es folgen Kreis 1 (246 CHF) ‚Äì das historische und touristische Zentrum der Stadt ‚Äì sowie Kreis 5 (213 CHF), das trendige ehemalige Industriequartier mit hoher kultureller Dichte und urbanem Flair. Auch Kreis 8 und 4 (je 206 CHF) zeigen attraktive durchschnittliche √úbernachtungspreise.\n",
    "\n",
    "Der Grossteil der √ºbrigen Kreise bewegt sich im Bereich zwischen 130 und 170 CHF pro Nacht. Den niedrigsten Durchschnittspreis verzeichnet Kreis 12 mit 98 CHF, was auf eine geringere touristische Attraktivit√§t oder geringere Zahlungsbereitschaft hinweist.\n",
    "\n",
    "**Fazit und strategische √úberlegungen:**\n",
    "- Premium-Strategie: Investitionen in Kreise mit hohen durchschnittlichen Preisen (v.a. 2, 1, 5, 4, 8) versprechen potenziell hohe Ums√§tze pro Nacht. Diese Strategie setzt jedoch meist h√∂here Einstiegskosten, intensivere Konkurrenz und gegebenenfalls strengere Auflagen voraus.\n",
    "- Wachstumsstrategie: In Kreisen mit bislang niedrigem Angebot und moderaten Preisen (z.B. 10, 12) k√∂nnten gezielte Investitionen lohnenswert sein ‚Äì insbesondere, wenn dort Nachfragepotenziale bestehen, die bislang nicht durch Airbnb-Angebote gedeckt sind.\n",
    "- Mischstrategie: Eine Kombination aus hochpreisigen Lagen mit etabliertem Marktumfeld und aufstrebenden, preisg√ºnstigen Quartieren k√∂nnte f√ºr InvestZurich AG ein ausgewogenes Risiko-Ertrags-Profil darstellen.\n",
    "\n",
    "In Kombination mit der zuvor analysierten Angebotsdichte ergibt sich ein differenziertes Bild: Ein hoher Preis bedeutet nicht zwangsl√§ufig geringe Konkurrenz, ebenso ist ein niedriges Preisniveau nicht automatisch ein Ausschlusskriterium f√ºr Investitionen.\n",
    "\n",
    "### Durchschnittliche Verf√ºgbarkeit der Airbnb-Listings\n",
    "Nach der Analyse von Angebotsdichte und durchschnittlichem √úbernachtungspreis liefert ein weiterer wichtiger Indikator zus√§tzliche Einblicke in die Marktdynamik: die Verf√ºgbarkeit von Airbnb-Angeboten pro Jahr und pro Stadtkreis.\n",
    "\n",
    "Im dritten Analyseschritt betrachten wir die durchschnittliche Verf√ºgbarkeit von Airbnb-Angeboten in den einzelnen Z√ºrcher Stadtkreisen ‚Äì gemessen an der Variable availability_365. Diese beschreibt, an wie vielen Tagen im Jahr ein Airbnb theoretisch verf√ºgbar ist. Eine niedrige Verf√ºgbarkeit kann darauf hinweisen, dass ein Objekt h√§ufig gebucht und damit stark nachgefragt ist ‚Äì also eine hohe Auslastung aufweist. Die nachfolgende Abbildung zeigt, an wie vielen Tagen die Airbnb's durchschnittlich pro Kreis innerhalb der n√§chsten 365 Tagen noch buchbar sind."
   ]
  },
  {
   "cell_type": "code",
   "id": "36e1f1a9",
   "metadata": {},
   "source": [
    "# Daten bereinigen und aggregieren\n",
    "availability_stats = listings_df.groupby(\"neighbourhood_group_cleansed\").agg({\n",
    "    \"availability_365\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Sortieren nach Verf√ºgbarkeit\n",
    "availability_stats_sorted = availability_stats.sort_values(by=\"availability_365\", ascending=False)\n",
    "\n",
    "# Plot in fig3 speichern\n",
    "fig3, ax = plt.subplots(figsize=(12,6))\n",
    "bar_color = \"#5DADE2\"\n",
    "sns.barplot(\n",
    "    data=availability_stats_sorted,\n",
    "    x=\"neighbourhood_group_cleansed\",\n",
    "    y=\"availability_365\",\n",
    "    color=bar_color,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Werte √ºber den Balken anzeigen\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{height:.0f}',  # ganze Tage ohne Nachkommastellen\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "# Titel, Achsen und Layout\n",
    "ax.set_title(\"Durchschnittliche Verf√ºgbarkeit (Tage/Jahr) von Airbnbs pro Kreis\", fontsize=14)\n",
    "ax.set_xlabel(\"Kreis\")\n",
    "ax.set_ylabel(\"√ò Verf√ºgbarkeit pro Jahr (Tage)\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig3.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99e9cc83",
   "metadata": {},
   "source": [
    "**Interpretation der Verf√ºgbarkeiten:**\n",
    "\n",
    "Die geringsten durchschnittlichen Verf√ºgbarkeiten zeigen sich in...\n",
    "- Kreis 10 (138 Tage)\n",
    "- Kreis 5 (151 Tage)\n",
    "- Kreis 2 (157 Tage)\n",
    "\n",
    "Diese Zahlen legen nahe, dass die dort gelisteten Unterk√ºnfte besonders h√§ufig gebucht sind ‚Äì ein klares Zeichen f√ºr eine hohe Marktnachfrage und attraktive Standorte f√ºr Investitionen. Solche Kreise sind aus Investorensicht spannend, da sie auf eine gute Auslastung und stabile Einnahmen hindeuten.\n",
    "\n",
    "Umgekehrt haben Kreise mit hoher Verf√ºgbarkeit wie:\n",
    "- Kreis 1 (227 Tage)\n",
    "- Kreis 9 (224 Tage)\n",
    "- Kreis 3 (213 Tage)\n",
    "eher ein √úberangebot oder eine geringere Buchungsfrequenz. Hier k√∂nnten Unterk√ºnfte teilweise leer stehen oder noch nicht optimal ausgelastet sein ‚Äì potenziell ein Zeichen f√ºr ein schw√§cheres Nachfrageprofil.\n",
    "-\n",
    "Es ist allerdings zu beachten, dass niedrige Verf√ºgbarkeiten auch durch Kalendersperrungen durch Gastgeber oder gesetzliche Einschr√§nkungen verursacht werden k√∂nnen. Dennoch: In der Regel gilt eine niedrige Verf√ºgbarkeit als positives Marktzeichen, sofern sie auf eine tats√§chliche G√§stebuchung zur√ºckzuf√ºhren ist.\n",
    "\n",
    "**Verbindung zu bisherigen Erkenntnissen:**\n",
    "- Kreis 2 ist besonders interessant: Er kombiniert sehr hohe Preise (487 CHF/Nacht) mit vergleichsweise geringer Verf√ºgbarkeit ‚Äì ein Indiz f√ºr lukrative, stark nachgefragte Premium-Listings.\n",
    "- Kreis 10, obwohl mit moderaten Preisen und geringer Angebotsdichte, weist die geringste Verf√ºgbarkeit auf. Dies k√∂nnte auf eine hohe Nachfrage bei gleichzeitig geringem Wettbewerb hinweisen ‚Äì ein vielversprechender Nischenmarkt.\n",
    "\n",
    "### Einfluss des Unterkunftstyps auf die Verf√ºgbarkeit\n",
    "Nachdem wir die Angebotsdichte, Preisstruktur und durchschnittliche Verf√ºgbarkeit pro Stadtkreis betrachtet haben, widmet sich dieser Abschnitt der Frage, ob auch der Unterkunftstyp einen Einfluss auf die Beliebtheit und Auslastung eines Airbnb-Angebots hat. Daf√ºr wurde erneut die Variable availability_365 verwendet und mittels Boxplot-Visualisierung nach Unterkunftstyp aufgeschl√ºsselt. Die nachfolgende Visualisierung zeigt die Verteilungsstruktur der j√§hrlichen Verf√ºgbarkeit f√ºr die drei  Unterkunftsarten, Private Room, Entire Home/Apt und Hotel Room auf Airbnb in Z√ºrich."
   ]
  },
  {
   "cell_type": "code",
   "id": "ae22afe3",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "df = listings_df[\n",
    "    (listings_df[\"availability_365\"].notnull()) &\n",
    "    (listings_df[\"room_type\"].notnull())\n",
    "]\n",
    "\n",
    "# Extreme Verf√ºgbarkeiten beschr√§nken (nur bis 365 Tage erlaubt)\n",
    "df = df[df[\"availability_365\"] <= 365]\n",
    "\n",
    "# Plot in fig4 speichern\n",
    "fig4, ax = plt.subplots(figsize=(12,6))\n",
    "box_color = \"#5DADE2\"\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"room_type\",\n",
    "    y=\"availability_365\",\n",
    "    color=box_color,\n",
    "    showfliers=True,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Layout\n",
    "ax.set_title(\"Verf√ºgbarkeitsverteilung je Unterkunftstyp\", fontsize=14)\n",
    "ax.set_xlabel(\"Unterkunftstyp\")\n",
    "ax.set_ylabel(\"Verf√ºgbarkeit im Jahr (Tage)\")\n",
    "ax.tick_params(axis='x', rotation=0)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig4.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40fbe6df",
   "metadata": {},
   "source": [
    "**Einige zentrale Beobachtungen:**\n",
    "- Private Rooms zeigen eine sehr breite Streuung, mit Verf√ºgbarkeiten zwischen nahezu 0 und 365 Tagen. Der Median liegt jedoch relativ tief, was darauf hindeutet, dass diese Objekte h√§ufig gebucht oder blockiert sind ‚Äì ein m√∂glicher Hinweis auf hohe Nachfrage.\n",
    "- Entire Homes/Apartments weisen ebenfalls eine grosse Spannbreite auf, mit einem Median leicht oberhalb der Private Rooms. Dies l√§sst vermuten, dass sie etwas seltener gebucht oder bewusster dosiert verf√ºgbar gemacht werden ‚Äì etwa durch Gastgeber, die sie auch selbst nutzen.\n",
    "- Hotel Rooms zeigen eine deutlich engere Verteilung mit einem h√∂heren Median und vergleichsweise hoher konstanter Verf√ºgbarkeit (oft √ºber 250 Tage). Dies spiegelt die professionell betriebene Natur dieser Angebote wider, welche meist permanent buchbar und weniger von privaten Nutzungszyklen abh√§ngig sind. Gleichzeitig kann die hohe Verf√ºgbarkeit aber auch auf niedrigere Auslastung hindeuten, wenn der Markt ges√§ttigt ist oder Nachfrage fehlt.\n",
    "\n",
    "In dieser Darstellung ist der Unterkunftstyp \"Private Room\" tendenziell am wenigsten verf√ºgbar, was als Indikator f√ºr hohe Nachfrage interpretiert werden kann ‚Äì entweder durch eine Vielzahl an Buchungen oder durch punktuell aktivierte Verf√ºgbarkeit. Investitionen in dieses Segment k√∂nnten sich f√ºr Anbieter mit begrenzten Immobilienressourcen (z.B. einzelne Zimmer in bewohnten Wohnungen) lohnen.\n",
    "\n",
    "### Verf√ºgbarkeit in Abh√§ngigkeit von der Unterkunftskapazit√§t\n",
    "Ein weiterer entscheidender Faktor bei der Bewertung des Marktpotenzials von Airbnb-Angeboten ist die Gr√∂sse bzw. G√§stekapazit√§t der Unterkunft ‚Äì gemessen an der maximalen Anzahl von Personen, die eine Unterkunft gleichzeitig beherbergen kann (accommodates). Das folgende Balkendiagramm untersucht, wie sich die durchschnittliche j√§hrliche Verf√ºgbarkeit in Abh√§ngigkeit dieser Kapazit√§t ver√§ndert."
   ]
  },
  {
   "cell_type": "code",
   "id": "b9685a38",
   "metadata": {},
   "source": [
    "# Daten vorbereiten\n",
    "df = listings_df[\n",
    "    (listings_df[\"accommodates\"].notnull()) &\n",
    "    (listings_df[\"availability_365\"].notnull()) &\n",
    "    (listings_df[\"accommodates\"] > 0)\n",
    "]\n",
    "\n",
    "# Aggregation und Sortierung nach Verf√ºgbarkeit (absteigend)\n",
    "availability_stats = df.groupby(\"accommodates\")[\"availability_365\"].mean().reset_index()\n",
    "availability_stats_sorted = availability_stats.sort_values(by=\"availability_365\", ascending=False)\n",
    "\n",
    "# Plot in fig5 speichern\n",
    "fig5, ax = plt.subplots(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    data=availability_stats_sorted,\n",
    "    x=\"accommodates\",\n",
    "    y=\"availability_365\",\n",
    "    color=\"#5DADE2\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Balkenbeschriftung\n",
    "for index, row in availability_stats_sorted.iterrows():\n",
    "    ax.text(\n",
    "        x=index,\n",
    "        y=row[\"availability_365\"] + 5,\n",
    "        s=f\"{row['availability_365']:.0f} Tage\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=9,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# Layout\n",
    "ax.set_title(\"Durchschnittliche Verf√ºgbarkeit nach Unterkunftskapazit√§t\", fontsize=14)\n",
    "ax.set_xlabel(\"Maximale G√§steanzahl (accommodates)\")\n",
    "ax.set_ylabel(\"√ò Verf√ºgbarkeit (Tage/Jahr)\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig5.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff6c11fd",
   "metadata": {},
   "source": [
    "**Interpretation der Visualisierung:**\n",
    "\n",
    "Die Balkengrafik zeigt auf den ersten Blick ein nicht-lineares Muster\n",
    "- Listings mit einer Kapazit√§t von 8 Personen (115 Tage) und 6 Personen (134 Tage) sind im Durchschnitt am wenigsten verf√ºgbar ‚Äì was auf eine sehr hohe Nachfrage und h√§ufige Buchungen schliessen l√§sst.\n",
    "- Ebenfalls vergleichsweise niedrige Verf√ºgbarkeiten zeigen sich bei Unterk√ºnften f√ºr 1‚Äì2 G√§ste (ca. 187‚Äì188 Tage), was auf konstant gute Auslastung bei kleinen Einheiten hindeutet.\n",
    "- Deutlich h√∂here Verf√ºgbarkeiten zeigen sich hingegen bei Kapazit√§ten von 7 G√§sten (254 Tage) und vor allem bei sehr grossen Unterk√ºnften mit 14 G√§sten (289 Tage) ‚Äì hier scheint die Nachfrage (relativ zur Angebotskapazit√§t) geringer oder die Zielgruppe eingeschr√§nkt zu sein.\n",
    "- Mittelgrosse Kapazit√§ten (z.B. 3‚Äì5 G√§ste) weisen eine ausgeglichene Verf√ºgbarkeit im Bereich von 200‚Äì217 Tagen auf ‚Äì ein Zeichen f√ºr solide, aber nicht √ºberdurchschnittliche Nachfrage.\n",
    "\n",
    "Die Daten deuten darauf hin, dass vor allem Unterk√ºnfte mit mittlerer bis hoher Kapazit√§t (6‚Äì8 G√§ste) besonders stark nachgefragt werden ‚Äì wie anhand ihrer niedrigen durchschnittlichen Verf√ºgbarkeit ersichtlich ist. Dies k√∂nnte daran liegen, dass diese Objekte ideal f√ºr Familien, kleine Gruppen oder Gesch√§ftsreiseteams sind ‚Äì also Zielgruppen mit √ºberdurchschnittlicher Buchungsh√§ufigkeit\n",
    "\n",
    "F√ºr die InvestZurich AG ergeben sich aus der Analyse der Unterkunftskapazit√§ten konkrete strategische Implikationen. Besonders attraktiv erscheinen Investitionen in Immobilien mit einer Kapazit√§t f√ºr 6 bis 8 Personen, da diese Einheiten im Durchschnitt am h√§ufigsten gebucht werden und somit eine besonders hohe Auslastung aufweisen. Auch kleinere Objekte f√ºr 1 bis 2 G√§ste bleiben relevant, da sie eine solide Nachfrage zeigen und im Markt weit verbreitet sind ‚Äì sie bieten insbesondere f√ºr Alleinreisende oder Paare eine geeignete Unterkunftsform. Mit Vorsicht zu bewerten sind hingegen sehr grosse Unterk√ºnfte, etwa mit einer Kapazit√§t f√ºr 14 Personen. Obwohl diese Angebote am Markt verf√ºgbar sind, deutet ihre vergleichsweise hohe Verf√ºgbarkeit darauf hin, dass sie seltener gebucht werden und somit ein erh√∂htes Auslastungsrisiko bergen.\n",
    "\n",
    "### Klassifikation von Top Performern mittels Random Forest\n",
    "Um potenziell erfolgreiche Airbnb-Angebote systematisch identifizieren zu k√∂nnen, wurde ein Klassifikationsmodell auf Basis eines Random Forest Algorithmus entwickelt. Ziel war es, sogenannte Top Performer zu erkennen ‚Äì also Angebote, die sowohl hinsichtlich ihres Preises als auch ihrer Anzahl an Bewertungen √ºber dem Median liegen. Diese Kombination wurde als Indikator f√ºr wirtschaftlich erfolgreiche und gleichzeitig nachgefragte Angebote interpretiert.\n",
    "\n",
    "Die Modellierung erfolgte in mehreren Schritten. Zun√§chst wurde das zugrunde liegende Datenset bereinigt und nur solche Eintr√§ge ber√ºcksichtigt, die vollst√§ndige Informationen zu Preis, Raumanzahl, Badezimmern, Unterkunftskapazit√§t, Unterkunftstyp und Lage enthielten. Anschliessend wurde die Zielvariable top_performer bin√§r kodiert: Ein Listing erhielt den Wert 1, wenn sowohl Preis als auch Anzahl der Bewertungen √ºber dem jeweiligen Median lagen; andernfalls wurde es mit 0 klassifiziert.\n",
    "\n",
    "Als erkl√§rende Merkmale wurden f√ºnf Variablen ausgew√§hlt: accommodates, bedrooms, bathrooms, room_type sowie neighbourhood_group_cleansed. Kategorische Variablen wurden mittels Label-Encoding numerisch transformiert, bevor das Modell mit einem RandomForestClassifier (100 B√§ume) trainiert wurde. Die Daten wurden im Verh√§ltnis 70% zu 30% in Trainings- und Testdaten aufgeteilt.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8c094945",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Daten vorbereiten\n",
    "df = listings_df.copy()\n",
    "\n",
    "# Filter und Bereinigung\n",
    "df = df[\n",
    "    (df[\"price\"] > 0) & (df[\"price\"] < 1000) &\n",
    "    (df[\"number_of_reviews\"].notnull()) &\n",
    "    (df[\"bedrooms\"].notnull()) &\n",
    "    (df[\"bathrooms\"].notnull()) &\n",
    "    (df[\"accommodates\"].notnull()) &\n",
    "    (df[\"room_type\"].notnull()) &\n",
    "    (df[\"neighbourhood_group_cleansed\"].notnull())\n",
    "]\n",
    "\n",
    "# Zielvariable konstruieren (Top Performer = Preis und Reviews √ºber Median)\n",
    "df[\"top_performer\"] = (\n",
    "    (df[\"price\"] > df[\"price\"].median()) &\n",
    "    (df[\"number_of_reviews\"] > df[\"number_of_reviews\"].median())).astype(int)\n",
    "\n",
    "# Feature-Auswahl\n",
    "features = [\n",
    "    \"accommodates\", \"bedrooms\", \"bathrooms\",\n",
    "    \"room_type\", \"neighbourhood_group_cleansed\"\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[\"top_performer\"]\n",
    "\n",
    "# Kategorische Variablen encodieren\n",
    "le_room = LabelEncoder()\n",
    "le_neigh = LabelEncoder()\n",
    "X[\"room_type\"] = le_room.fit_transform(X[\"room_type\"])\n",
    "X[\"neighbourhood_group_cleansed\"] = le_neigh.fit_transform(X[\"neighbourhood_group_cleansed\"])\n",
    "\n",
    "# Train/Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance visualisieren\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "fig6, ax = plt.subplots(figsize=(10,6))\n",
    "sns.barplot(\n",
    "    x=importances.values,\n",
    "    y=importances.index,\n",
    "    color=\"#5DADE2\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(\"Feature Importance\")\n",
    "ax.set_ylabel(\"Merkmale\")\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "fig6.tight_layout()\n",
    "\n",
    "# Confusion Matrix\n",
    "fig7, ax = plt.subplots(figsize=(6,6))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=14)\n",
    "ax.grid(False)\n",
    "fig7.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0df91d63",
   "metadata": {},
   "source": [
    "Das Modell erzielte auf dem Testdatensatz eine Gesamtgenauigkeit von 85%. Der F1-Score f√ºr die Klasse der Top Performer (1) lag bei 0.59, w√§hrend die Klasse der Nicht-Performer (0) einen deutlich h√∂heren F1-Score von 0.91 erreichte. Diese Differenz verdeutlicht, dass das Modell besonders gut darin ist, weniger erfolgreiche Angebote zu erkennen, w√§hrend die Identifikation von Top Performern anspruchsvoller bleibt. Die Confusion Matrix zeigt, dass 17 der 30 tats√§chlichen Top Performer korrekt vorhergesagt wurden, w√§hrend 13 nicht erkannt wurden. Gleichzeitig wurden 11 Objekte f√§lschlicherweise als Top Performer klassifiziert.\n",
    "\n",
    "Besonders aufschlussreich ist die Analyse der Merkmalswichtigkeit im Modell: Das wichtigste Kriterium f√ºr die Klassifikation war die Unterkunftskapazit√§t (accommodates), gefolgt von der Lage (neighbourhood_group_cleansed) und der Anzahl der Schlafzimmer. Geringere Bedeutung hatten dagegen die Anzahl der Badezimmer sowie der Unterkunftstyp.\n",
    "\n",
    "Diese Ergebnisse best√§tigen die vorherigen Analysen der Nachfrageverteilung: Erfolgreiche Airbnb-Angebote sind h√§ufig in der Lage, mehrere G√§ste zu beherbergen und befinden sich in bestimmten, gefragten Stadtteilen. Das Random Forest Modell bietet somit eine fundierte Grundlage, um Investitionsentscheidungen datenbasiert zu unterst√ºtzen. Es kann als erg√§nzendes Werkzeug dienen, um Immobilienangebote fr√ºhzeitig auf ihr Potenzial zur erfolgreichen Kurzzeitvermietung hin zu pr√ºfen. Weiteres Optimierungspotenzial besteht durch die Integration zus√§tzlicher Einflussfaktoren wie z.B. Ausstattung, Bewertungsscores oder saisonale Schwankungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93893b",
   "metadata": {},
   "source": [
    "## Objective 2 ‚Äì Preisstrategie & Ertragsprognose\n",
    "\n",
    "Analyse der Preistreiber und Erstellung eines Regressionsmodells zur Quantifizierung des Einflusses verschiedener Merkmale auf den Preis `price`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Aufbereitung der Immobilienverkaufsdaten aus `SellingPrices`\n",
    "`selling_prices_df` wurde bereits in \"Step 2\" geladen und inspiziert. Wir f√ºhren nun die Aggregation durch."
   ],
   "id": "39c0fb4c62aa435d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'selling_prices_df' in locals() or 'selling_prices_df' in globals():\n",
    "    if not selling_prices_df.empty:\n",
    "        # Stelle sicher, dass die relevanten Spalten vorhanden sind\n",
    "        required_columns_sp = ['raumlang', 'hapreiswohnflaeche']\n",
    "        if all(col in selling_prices_df.columns for col in required_columns_sp):\n",
    "\n",
    "            # Kopie erstellen, um SettingWithCopyWarning zu vermeiden\n",
    "            processed_selling_prices_df = selling_prices_df.copy()\n",
    "\n",
    "            # Konvertiere 'hapreiswohnflaeche' in einen numerischen Typ, Fehler werden zu NaN\n",
    "            processed_selling_prices_df['hapreiswohnflaeche'] = pd.to_numeric(processed_selling_prices_df['hapreiswohnflaeche'], errors='coerce')\n",
    "\n",
    "            # Entferne Zeilen, bei denen 'raumlang' (Quartier) oder 'hapreiswohnflaeche' (Preis pro m¬≤) NaN ist\n",
    "            # oder 'raumlang' leer ist.\n",
    "            processed_selling_prices_df.dropna(subset=['raumlang', 'hapreiswohnflaeche'], inplace=True)\n",
    "            # Entferne Zeilen, wo 'raumlang' nur aus Leerzeichen besteht oder leer ist\n",
    "            processed_selling_prices_df = processed_selling_prices_df[processed_selling_prices_df['raumlang'].str.strip() != '']\n",
    "\n",
    "\n",
    "            # Gruppiere nach 'raumlang' (Quartier) und berechne den Median von 'hapreiswohnflaeche'\n",
    "            selling_prices_agg_df = processed_selling_prices_df.groupby('raumlang')['hapreiswohnflaeche'].median().reset_index()\n",
    "\n",
    "            # Umbenennen der Spalten f√ºr bessere Lesbarkeit und Konsistenz\n",
    "            selling_prices_agg_df.rename(columns={\n",
    "                'raumlang': 'Quartier', # Dies ist der Name des Quartiers aus den Verkaufsdaten\n",
    "                'hapreiswohnflaeche': 'Median_Preis_pro_m2_Quartier'\n",
    "            }, inplace=True)\n",
    "\n",
    "            print(\"Aggregierte Immobilienpreise pro Quartier (Median Preis pro m¬≤)\")\n",
    "            print(selling_prices_agg_df.head())\n",
    "\n",
    "            # √úberpr√ºfen auf fehlende Werte im aggregierten DataFrame\n",
    "            print(\"\\nFehlende Werte in selling_prices_agg_df:\")\n",
    "            print(selling_prices_agg_df.isnull().sum())\n",
    "        else:\n",
    "            print(f\"Fehler: Die erforderlichen Spalten ({', '.join(required_columns_sp)}) wurden nicht im DataFrame 'selling_prices_df' gefunden.\")\n",
    "            print(\"Vorhandene Spaltennamen in selling_prices_df:\", selling_prices_df.columns)\n",
    "else:\n",
    "    print(\"Der DataFrame 'selling_prices_df' aus Step 2 ist leer.\")"
   ],
   "id": "c657947af287218",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Aufbereitung der Airbnb aus `Listings` f√ºr die Ertragsanalyse\n",
    "Jetzt k√ºmmern wir uns um die Ertragsseite. Wir verwenden deinen bereits in \"Step 2\" aufbereiteten DataFrame `df_analysis` (die Arbeitskopie von `listings_df`). Ziel ist es, die potenziellen j√§hrlichen Einnahmen pro Airbnb-Angebot zu sch√§tzen und diese dann pro Quartier zu aggregieren.\n",
    "\n",
    "**Die relevanten Spalten in `df_analysis` sind:**\n",
    "- Die definierte Standortspalte (gespeichert in der Variable `loc_col_for_analysis_notebook`)\n",
    "- `price` (Preis pro Nacht)\n",
    "- `availability_365` (Verf√ºgbarkeit √ºber 365 Tage), woraus wir eine Sch√§tzung f√ºr die Belegung ableiten k√∂nnen"
   ],
   "id": "8633fd1fbe5770bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df_analysis wurde bereits in deinem \"Step 2\" des Notebooks umfassend vorbereitet.\n",
    "# loc_col_for_analysis_notebook wurde in deinem \"Step 2\" definiert und enth√§lt den Namen der relevanten Standortspalte.\n",
    "\n",
    "if 'df_analysis' in locals() or 'df_analysis' in globals():\n",
    "    if not df_analysis.empty:\n",
    "        # Stelle sicher, dass die relevante Standortspalte und Preisspalte existieren\n",
    "        # loc_col_for_analysis_notebook sollte aus deinem vorherigen Code-Teil verf√ºgbar sein.\n",
    "        # Falls nicht, musst du sie hier erneut definieren oder sicherstellen, dass sie global ist.\n",
    "        # Beispiel: loc_col_for_analysis_notebook = 'neighbourhood_cleansed' # oder was auch immer es war\n",
    "\n",
    "        # √úberpr√ºfe, ob die Variable loc_col_for_analysis_notebook existiert\n",
    "        if 'loc_col_for_analysis_notebook' not in locals() and 'loc_col_for_analysis_notebook' not in globals():\n",
    "            print(\"Fehler: Variable 'loc_col_for_analysis_notebook' ist nicht definiert. Bitte stelle sicher, dass sie aus Step 2 √ºbernommen wurde.\")\n",
    "            # Definiere einen Fallback oder brich ab, je nach Anforderung\n",
    "            # loc_col_for_analysis_notebook = 'neighbourhood_cleansed' # Beispiel-Fallback\n",
    "\n",
    "        required_cols_airbnb = [loc_col_for_analysis_notebook, 'price', 'availability_365']\n",
    "        if all(col in df_analysis.columns for col in required_cols_airbnb):\n",
    "\n",
    "            airbnb_revenue_df = df_analysis.copy()\n",
    "\n",
    "            # Bereinigung und Konvertierung f√ºr die Berechnung\n",
    "            airbnb_revenue_df['price'] = pd.to_numeric(airbnb_revenue_df['price'], errors='coerce')\n",
    "            airbnb_revenue_df['availability_365'] = pd.to_numeric(airbnb_revenue_df['availability_365'], errors='coerce')\n",
    "\n",
    "            # Entferne Eintr√§ge, wo Preis oder Verf√ºgbarkeit NaN sind oder Standort leer ist\n",
    "            airbnb_revenue_df.dropna(subset=[loc_col_for_analysis_notebook, 'price', 'availability_365'], inplace=True)\n",
    "            airbnb_revenue_df = airbnb_revenue_df[airbnb_revenue_df[loc_col_for_analysis_notebook].astype(str).str.strip() != '']\n",
    "\n",
    "            # Berechnung der gesch√§tzten j√§hrlichen Einnahmen pro Listing\n",
    "            # Annahme: Tage, an denen das Listing NICHT verf√ºgbar ist (availability_365), sind gebuchte Tage.\n",
    "            # Dies ist eine Vereinfachung, da Tage auch geblockt sein k√∂nnten.\n",
    "            # Eine konservativere Annahme f√ºr die Belegung w√§re z.B. 50% der verf√ºgbaren Tage oder (365-availability_365)\n",
    "            # Hier verwenden wir (365 - availability_365) als Sch√§tzung f√ºr gebuchte Tage.\n",
    "            # Wir stellen sicher, dass gebuchte Tage nicht negativ werden, falls availability_365 > 365 (sollte nicht sein)\n",
    "            airbnb_revenue_df['estimated_booked_days_yearly'] = (365 - airbnb_revenue_df['availability_365']).clip(lower=0)\n",
    "            airbnb_revenue_df['estimated_yearly_revenue'] = airbnb_revenue_df['price'] * airbnb_revenue_df['estimated_booked_days_yearly']\n",
    "\n",
    "            # Einige Listings k√∂nnten einen Preis von 0 haben oder 0 gebuchte Tage, was zu 0 Einnahmen f√ºhrt.\n",
    "            # √úberpr√ºfe, ob estimated_yearly_revenue valide Werte hat (nicht negativ)\n",
    "            airbnb_revenue_df = airbnb_revenue_df[airbnb_revenue_df['estimated_yearly_revenue'] >= 0]\n",
    "\n",
    "            # Aggregation der gesch√§tzten j√§hrlichen Einnahmen pro Quartier (Median)\n",
    "            # Wir verwenden hier den Median, um Ausreissern weniger Gewicht zu geben.\n",
    "            airbnb_revenue_agg_df = airbnb_revenue_df.groupby(loc_col_for_analysis_notebook)['estimated_yearly_revenue'].median().reset_index()\n",
    "\n",
    "            airbnb_revenue_agg_df.rename(columns={\n",
    "                loc_col_for_analysis_notebook: 'Quartier', # Umbenennung f√ºr Konsistenz beim Mergen\n",
    "                'estimated_yearly_revenue': 'Median_Estimated_Yearly_Revenue_Airbnb'\n",
    "            }, inplace=True)\n",
    "\n",
    "            print(\"\\nAggregierte gesch√§tzte j√§hrliche Airbnb-Einnahmen pro Quartier (Median)\")\n",
    "            print(airbnb_revenue_agg_df.head())\n",
    "\n",
    "            print(f\"\\nAnzahl der Quartiere im Airbnb-Ertrags-DataFrame: {airbnb_revenue_agg_df.shape[0]}\")\n",
    "\n",
    "            print(\"\\nFehlende Werte in airbnb_revenue_agg_df:\")\n",
    "            print(airbnb_revenue_agg_df.isnull().sum())\n",
    "else:\n",
    "    print(\"Der DataFrame 'df_analysis' wurde in Step 2 nicht definiert oder ist nicht zug√§nglich.\")"
   ],
   "id": "2ef1ce51179204f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zusammenf√ºhren der Datens√§tze\n",
    "In diesem Schritt werden wir `selling_prices_agg_df` und `airbnb_revenue_agg_df` √ºber die gemeinsame Spalte `Quartier` zusammenf√ºhren."
   ],
   "id": "c9a4e26097bb3442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# selling_prices_agg_df und airbnb_revenue_agg_df sollten nun existieren.\n",
    "if ('selling_prices_agg_df' in locals() or 'selling_prices_agg_df' in globals()) and \\\n",
    "   ('airbnb_revenue_agg_df' in locals() or 'airbnb_revenue_agg_df' in globals()):\n",
    "\n",
    "    if not selling_prices_agg_df.empty and not airbnb_revenue_agg_df.empty:\n",
    "\n",
    "        # Zusammenf√ºhren der beiden DataFrames √ºber die Spalte 'Quartier'\n",
    "        # Wir verwenden einen 'inner' Merge, um nur Quartiere zu behalten, f√ºr die wir beide Arten von Daten haben.\n",
    "        # Alternativ k√∂nnte man 'outer' verwenden und die fehlenden Werte sp√§ter behandeln.\n",
    "        combined_analysis_df = pd.merge(selling_prices_agg_df, airbnb_revenue_agg_df, on='Quartier', how='inner')\n",
    "\n",
    "        print(\"Kombinierter DataFrame aus Immobilienpreisen und Airbnb-Ertr√§gen\")\n",
    "        print(combined_analysis_df.head())\n",
    "\n",
    "        print(f\"\\nShape des kombinierten DataFrames: {combined_analysis_df.shape}\")\n",
    "        print(f\"Dies bedeutet, wir haben f√ºr {combined_analysis_df.shape[0]} Quartiere sowohl Preis- als auch Ertragsdaten.\")\n",
    "\n",
    "        print(\"\\nFehlende Werte im combined_analysis_df:\")\n",
    "        print(combined_analysis_df.isnull().sum())\n",
    "\n",
    "        # Kurze √úberpr√ºfung der Datentypen, um sicherzustellen, dass die numerischen Spalten korrekt sind\n",
    "        print(\"\\nDatentypen im combined_analysis_df:\")\n",
    "        print(combined_analysis_df.dtypes)\n",
    "\n",
    "    else:\n",
    "        print(\"Einer der DataFrames (selling_prices_agg_df oder airbnb_revenue_agg_df) ist leer.\")\n",
    "else:\n",
    "    print(\"selling_prices_agg_df oder airbnb_revenue_agg_df wurde nicht gefunden.\")"
   ],
   "id": "45e0f4a25dc0f994",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rentabilit√§tsanalyse\n",
    "\n",
    "In diesem Schritt werden wir anhand des zusammengef√ºhrten DataFrame `combined_analysis_df` eine **Rentabilit√§tskennzahl** berechnen, um die Quartiere direkter vergleichen zu k√∂nnen. Wir nennen sie `Revenue_Yield_Proxy`. Sie wird als das Verh√§ltnis der medianen j√§hrlichen Airbnb-Einnahmen zum medianen Quadratmeterpreis der Immobilie berechnet. Ein h√∂herer Wert dieser Kennzahl deutet auf eine potenziell bessere Rentabilit√§t hin (h√∂here Einnahmen im Verh√§ltnis zum Preis pro m¬≤)."
   ],
   "id": "3693198a3f251044"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combined_analysis_df sollte nun existieren.\n",
    "# Wir ben√∂tigen auch matplotlib und seaborn f√ºr die Visualisierungen.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # F√ºr den Fall, dass wir Inf-Werte behandeln m√ºssen\n",
    "\n",
    "if 'combined_analysis_df' in locals() or 'combined_analysis_df' in globals():\n",
    "    if not combined_analysis_df.empty:\n",
    "\n",
    "        # Berechnung der Rentabilit√§tskennzahl (Revenue Yield Proxy)\n",
    "        # Dieser Proxy gibt an, wie viel des Quadratmeterpreises potenziell durch j√§hrliche Airbnb-Einnahmen \"gedeckt\" wird.\n",
    "        # Wir m√ºssen sicherstellen, dass Median_Preis_pro_m2_Quartier nicht Null ist, um DivisionByZeroError zu vermeiden.\n",
    "        if (combined_analysis_df['Median_Preis_pro_m2_Quartier'] == 0).any():\n",
    "            print(\"Warnung: Einige Quartiere haben einen Median_Preis_pro_m2_Quartier von 0. Diese werden NaN/Inf in der Renditekennzahl ergeben.\")\n",
    "\n",
    "        # Ersetze 0 im Nenner tempor√§r durch NaN, um Inf zu vermeiden, und f√ºlle dann ggf. mit 0 oder behandle es.\n",
    "        # In diesem Fall ist es unwahrscheinlich, dass der Preis 0 ist, aber eine gute Praxis.\n",
    "        combined_analysis_df['Revenue_Yield_Proxy'] = combined_analysis_df['Median_Estimated_Yearly_Revenue_Airbnb'] / combined_analysis_df['Median_Preis_pro_m2_Quartier'].replace(0, np.nan)\n",
    "\n",
    "        # Falls durch die obige Ersetzung NaNs entstanden sind (weil Preis 0 war), k√∂nnten wir sie mit 0 f√ºllen.\n",
    "        # combined_analysis_df['Revenue_Yield_Proxy'].fillna(0, inplace=True)\n",
    "\n",
    "        # --- Visualisierung ---\n",
    "\n",
    "        # a) Balkendiagramm f√ºr den Revenue_Yield_Proxy pro Quartier\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Revenue_Yield_Proxy', y='Quartier', data=combined_analysis_sorted_df, palette='viridis')\n",
    "        plt.title('Potenzielle Rentabilit√§t (Revenue Yield Proxy) nach Quartier')\n",
    "        plt.xlabel('Revenue Yield Proxy (Median J√§hrl. Airbnb-Ertrag / Median Preis pro m¬≤)')\n",
    "        plt.ylabel('Quartier')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"DataFrame mit Rentabilit√§tskennzahl (Revenue_Yield_Proxy)\")\n",
    "        # Sortieren nach der neuen Kennzahl, um die \"Top\"-Quartiere zu sehen\n",
    "        combined_analysis_sorted_df = combined_analysis_df.sort_values(by='Revenue_Yield_Proxy', ascending=False)\n",
    "        print(combined_analysis_sorted_df)\n",
    "\n",
    "    else:\n",
    "        print(\"Der DataFrame 'combined_analysis_df' ist leer.\")\n",
    "else:\n",
    "    print(\"Der DataFrame 'combined_analysis_df' wurde nicht gefunden.\")"
   ],
   "id": "1d633da10a3a219c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Das Balkendiagramm `Potenzielle Rentabilit√§t (Revenue Yield Proxy) nach Quartier` visualisiert das Ranking aus dem sortierten DataFrame. Kreis 12 ist klar als Quartier mit dem h√∂chsten Revenue_Yield_Proxy zu erkennen, gefolgt von Kreis 4 und Kreis 6. Die Grafik macht die Unterschiede in der potenziellen Rentabilit√§t zwischen den Quartieren sehr deutlich und ist ideal, um die attraktivsten Standorte schnell zu identifizieren.\n",
    "\n",
    "Der DataFrame `combined_analysis_sorted_df` zeigt die 12 Quartiere, f√ºr die wir vollst√§ndige Daten haben, sortiert nach dem `Revenue_Yield_Proxy` in absteigender Reihenfolge. Diese Kennzahl stellt das Verh√§ltnis der medianen gesch√§tzten j√§hrlichen Airbnb-Einnahmen zum medianen Quadratmeterpreis der Immobilien dar. Ein h√∂herer Wert ist hier potenziell besser.\n",
    "\n",
    "**Spitzenreiter:** `Kreis 12` weist mit einem `Revenue_Yield_Proxy` von ca. 3.78 den h√∂chsten Wert auf. Das bedeutet, dass hier die gesch√§tzten j√§hrlichen Airbnb-Einnahmen im Verh√§ltnis zum Quadratmeterpreis am h√∂chsten sind. Dies k√∂nnte auf relativ moderate Immobilienpreise bei gleichzeitig guten Einnahmem√∂glichkeiten hindeuten.\n",
    "\n",
    "**Weitere attraktive Quartiere:** `Kreis 4` (ca. 2.66) und `Kreis 6` (ca. 2.58) folgen dahinter und zeigen ebenfalls ein √ºberdurchschnittlich gutes Verh√§ltnis von Einnahmen zu Immobilienpreisen.\n",
    "\n",
    "**Mittelfeld:** Quartiere wie `Kreis 2`, `Kreis 10` und `Kreis 3` bewegen sich im Mittelfeld mit Werten zwischen ca. 2.31 und 2.35.\n",
    "\n",
    "**Unteres Ende:** `Kreis 1` hat mit ca. 1.60 den niedrigsten `Revenue_Yield_Proxy`. Dies ist nicht √ºberraschend, da `Kreis 1` bekanntermassen sehr hohe Immobilienpreise hat (Altstadt), die durch die Airbnb-Einnahmen (obwohl absolut gesehen auch hoch) verh√§ltnism√§ssig weniger stark \"aufgefangen\" werden. Auch `Kreis 9` und `Kreis 7` zeigen hier vergleichsweise niedrigere Werte."
   ],
   "id": "569a87a66d0637e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Korrelationsanalyse Immobilienpreis vs. Airbnb-Einnahmen\n",
    "\n",
    "In diesem weiterf√ºhrenden Schritt werden wir die Korrelation zwischen den Immobilienpreisen und den Airbnb-Einnahmen untersuchen."
   ],
   "id": "7a5bfba30a2e2670"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "        # Korrelationsanalyse\n",
    "        correlation_matrix = combined_analysis_df[['Median_Preis_pro_m2_Quartier', 'Median_Estimated_Yearly_Revenue_Airbnb', 'Revenue_Yield_Proxy']].corr()\n",
    "        print(\"\\nKorrelationsmatrix:\")\n",
    "        print(correlation_matrix)\n",
    "\n",
    "        # --- Visualisierungen ---\n",
    "\n",
    "        # b) Streudiagramm: Immobilienpreise vs. Airbnb-Einnahmen\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.scatterplot(x='Median_Preis_pro_m2_Quartier', y='Median_Estimated_Yearly_Revenue_Airbnb', hue='Quartier', size='Revenue_Yield_Proxy', sizes=(50,500), data=combined_analysis_df, legend='brief', palette='muted')\n",
    "        plt.title('Immobilienpreise pro m¬≤ vs. Gesch√§tzte j√§hrliche Airbnb-Einnahmen')\n",
    "        plt.xlabel('Median Preis pro m¬≤ (CHF)') # Annahme Euro, anpassen falls andere W√§hrung\n",
    "        plt.ylabel('Median gesch√§tzte j√§hrl. Airbnb-Einnahmen (CHF)')\n",
    "        plt.grid(True)\n",
    "        # Legende ausserhalb des Plots platzieren, um √úberlappung zu vermeiden\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout(rect=[0,0,0.85,1]) # Platz f√ºr Legende schaffen\n",
    "        plt.show()"
   ],
   "id": "490c8cda5f460af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Immobilienpreis vs. Airbnb-Einnahmen:**\n",
    "- `Median_Preis_pro_m2_Quartier` und `Median_Estimated_Yearly_Revenue_Airbnb` weisen eine Korrelation von ca. 0.30 auf.\n",
    "- Es besteht eine schwache positive Korrelation. Das heisst, es gibt eine leichte Tendenz, dass in Quartieren mit h√∂heren Immobilienpreisen auch tendenziell h√∂here Airbnb-Einnahmen erzielt werden. Der Zusammenhang ist jedoch nicht stark ausgepr√§gt, was darauf hindeutet, dass hohe Immobilienpreise nicht automatisch die h√∂chsten Airbnb-Ertr√§ge garantieren.\n",
    "\n",
    "Das Streudiagramm `Immobilienpreise pro m¬≤ vs. Gesch√§tzte j√§hrliche Airbnb-Einnahmen` positioniert die Quartiere im Preis-Ertrags-Raum.\n",
    "- `Kreis 1` befindet sich oben rechts: h√∂chste Preise und hohe (aber nicht die h√∂chsten) Einnahmen.\n",
    "- `Kreis 12` sticht heraus: Es hat nicht die niedrigsten Immobilienpreise, aber die h√∂chsten medianen Airbnb-Einnahmen im Datensatz, was zu seiner f√ºhrenden Position beim `Revenue_Yield_Proxy` f√ºhrt.\n",
    "- Die Punktgr√∂sse, die den `Revenue_Yield_Proxy` darstellt, unterstreicht visuell, welche Quartiere relativ zu ihrem Preisniveau hohe Einnahmen generieren (gr√∂ssere Blasen sind hier besser). `Kreis 12` sollte hier die gr√∂sste Blase haben.\n",
    "Man kann Cluster oder Ausreisser erkennen und die allgemeine Verteilung besser verstehen.\n",
    "\n",
    "**Immobilienpreis vs. Rentabilit√§tskennzahl:**\n",
    "- `Median_Preis_pro_m2_Quartier` und `Revenue_Yield_Proxy` weisen eine Korrelation von ca. -0.48 auf.\n",
    "- Hier zeigt sich eine moderate negative Korrelation. Dies bedeutet, dass mit steigenden Quadratmeterpreisen der `Revenue_Yield_Proxy tendenziell sinkt. Sehr teure Quartiere haben es also schwerer, einen hohen relativen \"Ertrag\" im Sinne unserer Kennzahl zu erzielen, da die hohen Preise die Einnahmen stark relativieren.\n",
    "\n",
    "**Airbnb-Einnahmen vs. Rentabilit√§tskennzahl:**\n",
    "- `Median_Estimated_Yearly_Revenue_Airbnb` und `Revenue_Yield_Proxy` weisen eine Korrelation von ca. 0.67 auf.\n",
    "`Diese moderate bis starke positive Korrelation ist logisch. H√∂here absolute Airbnb-Einnahmen f√ºhren ceteris paribus (bei gleichbleibenden Preisen) zu einem besseren (h√∂heren) Revenue_Yield_Proxy. Dies unterstreicht, dass hohe Einnahmen ein wichtiger Treiber f√ºr die Rentabilit√§t sind, aber immer im Kontext der Immobilienpreise gesehen werden m√ºssen."
   ],
   "id": "9de48b70afb2ae3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "        # c) Heatmap der Korrelationsmatrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "        plt.title('Korrelationsmatrix der Schl√ºsselmetriken')\n",
    "        plt.show()"
   ],
   "id": "70197236312d793c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Die Headmap `Korrelationsmatrix der Schl√ºsselmetriken` ist die grafische Darstellung der zuvor diskutierten Korrelationsmatrix.\n",
    "\n",
    "*Rott√∂ne zeigen positive Korrelationen, Blaut√∂ne negative. Die Intensit√§t der Farbe spiegelt die St√§rke der Korrelation wider.*\n",
    "\n",
    "**Die Heatmap best√§tigt visuell:**\n",
    "- Die moderate negative Korrelation (bl√§ulich) zwischen `Median_Preis_pro_m2_Quartier` und `Revenue_Yield_Proxy`.\n",
    "- Die moderate bis starke positive Korrelation (r√∂tlich) zwischen `Median_Estimated_Yearly_Revenue_Airbnb` und `Revenue_Yield_Proxy`.\n",
    "- Die schwach positive Korrelation (leicht r√∂tlich) zwischen `Median_Preis_pro_m2_Quartier` und `Median_Estimated_Yearly_Revenue_Airbnb`.\n",
    "- Die Heatmap macht es einfach, die wichtigsten Zusammenh√§nge auf einen Blick zu erfassen, ohne die Zahlen direkt lesen zu m√ºssen."
   ],
   "id": "9c976a736b048cb0"
  },
  {
   "cell_type": "markdown",
   "id": "7507721d",
   "metadata": {},
   "source": [
    "## Objective 3 ‚Äì Performance Optimierung & Benchmarking\n",
    "\n",
    "Ziel dieses Untersuchungsabschnitts ist es, die zentralen Erfolgsfaktoren f√ºr den Superhost-Status auf Airbnb datenbasiert zu identifizieren. Im Fokus steht die Frage, welche quantifizierbaren Merkmale Top-Performer (Superhosts) von anderen Gastgebern im Raum Z√ºrich unterscheiden ‚Äì und wie die InvestZurich AG diese Erkenntnisse gezielt zur Optimierung ihrer eigenen Objekte nutzen kann.\n",
    "\n",
    "Der Superhost-Status ist ein Qualit√§tssiegel innerhalb des Airbnb-√ñkosystems, das mit h√∂herer Sichtbarkeit, gesteigerter Buchungswahrscheinlichkeit und verbessertem G√§stevertrauen einhergeht. F√ºr professionelle Anbieter wie die InvestZurich AG stellt dieser Status daher einen strategisch bedeutsamen Wettbewerbsvorteil dar.\n",
    "\n",
    "In einem ersten Schritt wird untersucht, welche Eigenschaften (z.B. Antwortzeit, Buchungsannahmequote, Bewertungsniveau oder Gastgeberaktivit√§t) statistisch signifikant mit dem Superhost-Status korrelieren. Anschliessend werden mittels Klassifikationsmodellen ‚Äì wie etwa Entscheidb√§umen oder Random Forests ‚Äì die einflussreichsten Pr√§diktoren herausgearbeitet.\n",
    "\n",
    "Das Ziel besteht darin, auf Grundlage dieser Daten konkrete Handlungspfade f√ºr die InvestZurich AG abzuleiten, etwa zur Verbesserung von Gastgebermetriken oder zur internen Qualit√§tssicherung. Der Fokus liegt dabei nicht nur auf reiner Leistungsdiagnostik, sondern auf einer operationalisierbaren Optimierungsstrategie.\n",
    "?\n",
    "\n",
    "Die nachfolgende Analyse visualisiert zentrale Merkmale, die signifikant mit dem Superhost-Status zusammenh√§ngen ‚Äì und bildet damit die Grundlage f√ºr gezielte Massnahmen zur Performance-Steigerung.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c96e6aeb",
   "metadata": {},
   "source": [
    "from airbnb_analysis_service import AirbnbAnalysisService\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # create service class\n",
    "    airbnbAnalysis = AirbnbAnalysisService()\n",
    "\n",
    "    # get all tables in form of a list\n",
    "    listings = airbnbAnalysis.get_listings()\n",
    "\n",
    "    print(f\"listings {listings[0]}\")\n",
    "\n",
    "    # Schritt 1: Umwandeln in DataFrames\n",
    "    listings_df = pd.DataFrame([l.__dict__ for l in listings])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7da8f2eb",
   "metadata": {},
   "source": [
    "### Datenaufbereitung\n",
    "\n",
    "Im Rahmen der Datenaufbereitung wurden zun√§chst 22 relevante Merkmale ausgew√§hlt, die potenziell Einfluss auf den Superhost-Status haben. Dazu z√§hlen hostbezogene Informationen (z.‚ÄØB. Antwortzeit, Annahmequote, Verifizierung), Objektmerkmale (wie Zimmeranzahl, Preis, Mindestaufenthalt) sowie Bewertungskennzahlen und Aktivit√§tsindikatoren (z.‚ÄØB. Anzahl Bewertungen pro Monat, durchschnittliche Bewertung).\n",
    "\n",
    "Prozentangaben wie die Antwort- und Annahmequote wurden in dezimale Werte umgewandelt, um sie numerisch auswerten zu k√∂nnen. Anschliessend wurden alle Datens√§tze mit fehlendem Superhost-Status entfernt, um eine saubere Klassifikationsbasis zu schaffen. Der Zielwert wurde anschliessend in eine bin√§re Variable √ºberf√ºhrt (1 = Superhost, 0 = Nicht-Superhost).\n",
    "\n",
    "Fehlende numerische Werte wurden mit dem Median der jeweiligen Spalte ersetzt, um Ausreisserverzerrungen zu vermeiden. Schliesslich wurden ausgew√§hlte kategoriale Merkmale, darunter etwa die Zimmerart oder Buchbarkeit, mittels Label Encoding in numerische Kategorien umgewandelt, sodass sie f√ºr maschinelles Lernen geeignet sind."
   ]
  },
  {
   "cell_type": "code",
   "id": "c1a894be",
   "metadata": {},
   "source": [
    "cols = [\n",
    "    'host_is_superhost', 'host_response_time', 'host_response_rate',\n",
    "    'host_acceptance_rate_percent', 'host_total_listings_count', 'host_has_profile_pic',\n",
    "    'host_identity_verified', 'room_type', 'accommodates', 'bathrooms',\n",
    "    'bedrooms', 'beds', 'price', 'minimum_nights', 'number_of_reviews',\n",
    "    'review_scores_rating', 'review_scores_cleanliness', 'review_scores_communication',\n",
    "    'review_scores_value', 'instant_bookable', 'availability_365', 'reviews_per_month'\n",
    "]\n",
    "listings_df = listings_df[cols].copy()\n",
    "def convert_percent(x):\n",
    "    try:\n",
    "        if isinstance(x, str) and '%' in x:\n",
    "            return float(x.strip('%')) / 100\n",
    "        return float(x) / 100\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "listings_df['host_response_rate'] = listings_df['host_response_rate'].apply(convert_percent)\n",
    "\n",
    "listings_df['host_acceptance_rate_percent'] = listings_df['host_acceptance_rate_percent'].apply(convert_percent)\n",
    "\n",
    "listings_df = listings_df[listings_df['host_is_superhost'].notna()]\n",
    "\n",
    "listings_df['host_is_superhost'] = listings_df['host_is_superhost'].astype(str).str.lower().map({'true': 1, 'false': 0, 't': 1, 'f': 0})\n",
    "\n",
    "listings_df.fillna(listings_df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "for col in ['host_response_time', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable', 'room_type']:\n",
    "    listings_df[col] = LabelEncoder().fit_transform(listings_df[col].astype(str))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afcb6de4",
   "metadata": {},
   "source": [
    "### √úberblick √ºber die Verteilung des Superhost-Status\n",
    "\n",
    "Zur ersten quantitativen Einsch√§tzung wurde analysiert, wie viele Anbieter im Datensatz den Superhost-Status tragen und wie hoch deren Anteil im Vergleich zu regul√§ren Hosts ist. Dazu wurden sowohl die absoluten H√§ufigkeiten als auch die prozentuale Verteilung berechnet.\n",
    "\n",
    "Anschliessend wurde die Verteilung visuell mittels Balkendiagramm dargestellt. Die zweiseitige Darstellung zeigt deutlich, wie stark (oder schwach) Superhosts im Verh√§ltnis zur Gesamtmenge vertreten sind. Diese Basisanalyse ist wichtig, um potenzielle Klassenungleichgewichte zu erkennen, die bei der sp√§teren Modellierung ber√ºcksichtigt werden m√ºssen."
   ]
  },
  {
   "cell_type": "code",
   "id": "ce1554ed",
   "metadata": {},
   "source": [
    "print(\"Anzahl Superhosts vs. Nicht-Superhosts:\")\n",
    "print(listings_df['host_is_superhost'].value_counts())\n",
    "print(\"\\nProzentuale Verteilung:\")\n",
    "print(listings_df['host_is_superhost'].value_counts(normalize=True) * 100)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='host_is_superhost', data=listings_df)\n",
    "plt.title(\"Verteilung Superhost vs. andere\")\n",
    "plt.xticks([0,1], ['Nicht Superhost', 'Superhost'])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8b919f15",
   "metadata": {},
   "source": [
    "Im betrachteten Datensatz sind rund 34‚ÄØ% der Anbieter Superhosts, w√§hrend etwa 66‚ÄØ% keine Superhosts sind. Dies zeigt, dass der Superhost-Status zwar kein Standard, aber auch nicht selten ist ‚Äì es handelt sich um eine bedeutende Teilgruppe.\n",
    "\n",
    "Diese Verteilung weist auf eine gewisse Klassenungleichheit hin, was bei der Modellierung beachtet werden sollte (z.‚ÄØB. durch Balancing-Strategien). Gleichzeitig zeigt die relativ hohe Quote von Superhosts, dass der Status erreichbar ist ‚Äì sofern bestimmte Merkmale oder Verhaltensweisen erf√ºllt werden.\n",
    "\n",
    "F√ºr InvestZurich AG bedeutet das: Der Superhost-Status stellt ein realistisches Ziel dar, das auf Grundlage datenbasierter Erkenntnisse gezielt angestrebt werden kann.\n",
    "\n",
    "### Merkmalsvergleich zwischen Superhosts und Nicht-Superhosts\n",
    "\n",
    "In diesem Abschnitt wird untersucht, wie sich die numerischen Merkmale zwischen Superhosts und Nicht-Superhosts unterscheiden. Dazu werden zun√§chst die Mittelwerte aller numerischen Variablen separat f√ºr beide Gruppen berechnet und gegen√ºbergestellt.\n",
    "\n",
    "Anschliessend wird f√ºr jedes Merkmal die prozentuale Differenz berechnet ‚Äì also wie stark sich der Mittelwert bei Superhosts im Vergleich zu Nicht-Superhosts unterscheidet. Diese Analyse zeigt, welche Faktoren bei Superhosts √ºberdurchschnittlich stark ausgepr√§gt sind und somit potenziell entscheidende Erfolgsfaktoren darstellen.\n",
    "\n",
    "Die 15 Merkmale mit dem gr√∂ssten relativen Unterschied werden in einem Balkendiagramm visualisiert. Dadurch wird sichtbar, welche quantitativen Eigenschaften besonders stark mit dem Superhost-Status assoziiert sind ‚Äì z.‚ÄØB. h√§ufige Bewertungen, hohe Sauberkeit oder hohe Buchungsaktivit√§t. Diese Erkenntnisse bilden eine fundierte Grundlage f√ºr die Ableitung konkreter Optimierungsmassnahmen."
   ]
  },
  {
   "cell_type": "code",
   "id": "04108937",
   "metadata": {},
   "source": [
    "grouped_stats = listings_df.groupby('host_is_superhost').mean(numeric_only=True).T\n",
    "diff = (grouped_stats[1] - grouped_stats[0]) / grouped_stats[0] * 100\n",
    "print(\"\\nMittelwerte der Merkmale nach Superhost-Status:\")\n",
    "print(grouped_stats.sort_values(by=1, ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "diff.sort_values(ascending=False).head(15).plot(kind='bar')\n",
    "plt.title(\"Top 15 Merkmale mit gr√∂sstem Unterschied (Superhost vs. Nicht-Superhost)\")\n",
    "plt.ylabel(\"Differenz in %\")\n",
    "plt.xlabel(\"Merkmal\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d84a54c4",
   "metadata": {},
   "source": [
    "Die Auswertung zeigt deutliche Unterschiede zwischen Superhosts und Nicht-Superhosts in mehreren zentralen Merkmalen. Am st√§rksten unterscheiden sich die Gruppen bei folgenden Aspekten:\n",
    "\n",
    "- Anzahl Bewertungen (number_of_reviews): Superhosts erhalten im Durchschnitt mehr als doppelt so viele Bewertungen wie Nicht-Superhosts (+108‚ÄØ%). Dies deutet auf eine h√∂here Buchungsaktivit√§t und Erfahrung hin.\n",
    "- Sofortbuchbarkeit (instant_bookable): Superhosts bieten deutlich h√§ufiger die M√∂glichkeit zur Sofortbuchung an (+67‚ÄØ%), was die Buchungsh√ºrde f√ºr G√§ste senkt und Vertrauen signalisiert.\n",
    "- Anzahl gelisteter Objekte (host_total_listings_count): Superhosts verwalten im Schnitt mehr Objekte (+40‚ÄØ%), was darauf hinweist, dass viele von ihnen Airbnb professionell nutzen.\n",
    "- Monatliche Bewertungsfrequenz (reviews_per_month): Auch hier zeigen sich h√∂here Werte bei Superhosts (+35‚ÄØ%), ein weiterer Hinweis auf kontinuierliche Auslastung und G√§stekontakt.\n",
    "- Antwortzeit (host_response_time): Superhosts reagieren schneller (h√∂herer numerischer Wert entspricht z.‚ÄØB. \"innerhalb weniger Stunden\") ‚Äì ein Plus von 28‚ÄØ% im Vergleich zur Kontrollgruppe.\n",
    "\n",
    "Auch bei Bewertungsdimensionen wie Sauberkeit, Kommunikation und Wertigkeit zeigen sich tendenziell bessere Werte bei Superhosts, wenn auch mit geringerem absoluten Unterschied.\n",
    "\n",
    "Zus√§tzlich f√§llt auf, dass Superhosts k√ºrzere Mindestaufenthalte zulassen, was die Buchungsh√§ufigkeit erh√∂hen kann. Auch die Antwort- und Annahmequote ist bei ihnen deutlich h√∂her, was auf Verl√§sslichkeit und aktives Hosting hinweist.\n",
    "\n",
    "Die Mittelwertanalyse zeigt, dass Superhosts in mehreren operativen Bereichen systematisch besser abschneiden als andere Hosts. Besonders stark unterscheiden sie sich bei der Anzahl an Bewertungen, der Sofortbuchbarkeit, der Gastgeberaktivit√§t und dem Antwortverhalten. Diese Muster deuten auf professionell gef√ºhrte, effizient organisierte Unterk√ºnfte hin.\n",
    "\n",
    "**F√ºr InvestZurich AG ergeben sich daraus folgende strategische Ans√§tze:**\n",
    "- Mehr Bewertungen generieren, z.‚ÄØB. durch aktives Bewertungsmanagement.\n",
    "- Sofortbuchung aktivieren, um die Buchungsquote zu erh√∂hen.\n",
    "- Reaktionszeiten verbessern, idealerweise durch automatisierte Antworten.\n",
    "- Mindestaufenthalte reduzieren, um spontane Buchungen zu erm√∂glichen.\n",
    "- Gastgeberprozesse professionalisieren, vor allem bei wachsender Objektanzahl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c895b",
   "metadata": {},
   "source": [
    "### Verteilungsanalyse\n",
    "\n",
    "Im Anschluss an die Mittelwertanalyse bietet eine detaillierte Betrachtung der Verteilungen zentraler Merkmale zus√§tzliche Einblicke in die Unterschiede zwischen Superhosts und Nicht-Superhosts. W√§hrend Durchschnittswerte erste Hinweise auf potenziell relevante Einflussfaktoren liefern, zeigen Boxplots auf, wie sich diese Merkmale innerhalb der Gruppen tats√§chlich verteilen.\n",
    "\n",
    "F√ºr neun besonders relevante Variablen ‚Äì darunter Antwortverhalten, Bewertungsqualit√§t, Buchungsaktivit√§t und Verf√ºgbarkeit ‚Äì wird die Verteilung jeweils getrennt nach Superhost-Status visualisiert. So lassen sich Muster erkennen, die nicht nur im Mittelwert, sondern auch in der Streuung und Konsistenz deutlich voneinander abweichen."
   ]
  },
  {
   "cell_type": "code",
   "id": "b8683143",
   "metadata": {},
   "source": [
    "features = [\n",
    "    'host_response_time', 'host_response_rate', 'host_acceptance_rate_percent',\n",
    "    'review_scores_rating', 'review_scores_cleanliness', 'review_scores_communication',\n",
    "    'review_scores_value', 'availability_365', 'reviews_per_month'\n",
    "]\n",
    "\n",
    "# Plot-Layout automatisch berechnen\n",
    "n_cols = 3\n",
    "n_rows = -(-len(features) // n_cols)  # Aufrunden\n",
    "\n",
    "plt.figure(figsize=(5 * n_cols, 4 * n_rows))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    sns.boxplot(\n",
    "    x='host_is_superhost',\n",
    "    y=feature,\n",
    "    data=listings_df,\n",
    "    hue='host_is_superhost',\n",
    "    palette='pastel',\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "    plt.title(feature.replace('_', ' ').capitalize())\n",
    "    plt.xlabel(\"Superhost\")\n",
    "    plt.ylabel(\"\")  # optional f√ºr kompaktere Darstellung\n",
    "    plt.xticks([0, 1], ['Nein', 'Ja'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig90, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.boxplot(x='host_is_superhost', y='host_response_rate', data=listings_df,\n",
    "            hue='host_is_superhost', palette='pastel', ax=axes[0])\n",
    "axes[0].set_title(\"Antwortrate nach Superhost-Status\")\n",
    "axes[0].set_xlabel(\"Superhost\")\n",
    "axes[0].set_ylabel(\"Antwortrate\")\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Nein', 'Ja'])\n",
    "axes[0].get_legend().remove()\n",
    "\n",
    "sns.boxplot(x='host_is_superhost', y='host_acceptance_rate_percent', data=listings_df,\n",
    "            hue='host_is_superhost', palette='pastel', ax=axes[1])\n",
    "axes[1].set_title(\"Annahmequote nach Superhost-Status\")\n",
    "axes[1].set_xlabel(\"Superhost\")\n",
    "axes[1].set_ylabel(\"Annahmequote\")\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['Nein', 'Ja'])\n",
    "axes[1].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig91, ax91 = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "reviews = listings_df.groupby('host_is_superhost')['number_of_reviews'].mean()\n",
    "ax91.bar(['Nicht-Superhost', 'Superhost'], reviews, color='slateblue')\n",
    "ax91.set_title(\"Durchschnittliche Anzahl Bewertungen\")\n",
    "ax91.set_ylabel(\"Anzahl Bewertungen\")\n",
    "ax91.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "features = ['review_scores_cleanliness', 'review_scores_communication', 'review_scores_rating']\n",
    "fig92, axes3 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='host_is_superhost', y=feature, data=listings_df,\n",
    "                hue='host_is_superhost', palette='pastel', ax=axes3[i])\n",
    "    axes3[i].set_title(feature.replace('_', ' ').capitalize())\n",
    "    axes3[i].set_xlabel(\"Superhost\")\n",
    "    axes3[i].set_ylabel(\"\")\n",
    "    axes3[i].set_xticks([0, 1])\n",
    "    axes3[i].set_xticklabels(['Nein', 'Ja'])\n",
    "    axes3[i].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c3995c5",
   "metadata": {},
   "source": [
    "Superhosts unterscheiden sich in mehreren zentralen operativen Kennzahlen systematisch von regul√§ren Gastgeber:innen.\n",
    "\n",
    "Ein besonders markanter Unterschied besteht bei der Antwortrate: Superhosts erreichen Werte nahe der maximalen Schwelle (ca. 1.0), w√§hrend die Werte bei Nicht-Superhosts deutlich st√§rker streuen. Auch die Annahmequote ist bei Superhosts im Schnitt deutlich h√∂her ‚Äì ein Hinweis auf professionell gef√ºhrte Buchungsprozesse und verl√§ssliche Kalenderpflege.\n",
    "\n",
    "Die durchschnittliche Anzahl an Bewertungen ist bei Superhosts fast doppelt so hoch. Zwar ist dies nicht als Ursache des Superhost-Status zu interpretieren, es spricht aber f√ºr eine h√∂here Buchungsfrequenz und gr√∂ssere G√§steerfahrung. Damit wird die Bewertungsh√§ufigkeit zu einem indirekten Indikator f√ºr operative Aktivit√§t und Pr√§senz** auf der Plattform.\n",
    "\n",
    "Auch bei den **Bewertungsdimensionen** ‚Äì insbesondere Sauberkeit, Kommunikation und Gesamtbewertung ‚Äì schneiden Superhosts signifikant besser ab. Die Boxplots zeigen nicht nur h√∂here Mittelwerte, sondern auch geringere Streuung, was auf ein stabiles und standardisiertes Qualit√§tsniveau hinweist.\n",
    "### Klassifikationsmodell zur Vorhersage des Superhost-Status\n",
    "\n",
    "Im folgenden Abschnitt wird ein Klassifikationsmodell aufgebaut, das vorhersagen soll, ob ein Gastgeber den Superhost-Status erreicht. Daf√ºr wird ein Random Forest Classifier verwendet.\n",
    "\n",
    "Zun√§chst werden die Daten in Trainings- und Testmengen unterteilt, um die Modellleistung realistisch evaluieren zu k√∂nnen. Nach dem Training des Modells erfolgt eine Klassifikation auf Basis der Testdaten. Die Modellg√ºte wird anhand klassischer Metriken wie Precision, Recall und F1-Score ausgewertet.\n",
    "\n",
    "Dar√ºber hinaus liefert das Modell Einblick in die Feature Importance ‚Äì also die relative Bedeutung einzelner Merkmale f√ºr die Entscheidungsfindung des Modells. Diese Information ist besonders wertvoll, um zu verstehen, welche Variablen am st√§rksten zur Unterscheidung von Superhosts und Nicht-Superhosts beitragen. Die wichtigsten Merkmale werden abschliessend in einem Balkendiagramm visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "id": "92eb1637",
   "metadata": {},
   "source": [
    "X = listings_df.drop('host_is_superhost', axis=1)\n",
    "y = listings_df['host_is_superhost']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "fig93, ax4 = plt.subplots(figsize=(12, 6))\n",
    "indices = np.argsort(model.feature_importances_)[::-1]\n",
    "sns.barplot(x=np.array(X.columns)[indices], y=model.feature_importances_[indices], ax=ax4, color='C0')\n",
    "ax4.set_title(\"Feature Importance im Random Forest Modell\")\n",
    "ax4.set_xticks(range(len(X.columns)))\n",
    "ax4.set_xticklabels(np.array(X.columns)[indices], rotation=90)\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f66be7ac",
   "metadata": {},
   "source": [
    "**Bedeutende Einflussfaktoren:**\n",
    "\n",
    "1. **`host_total_listings_count`:**\n",
    "      Hosts mit mehreren Objekten weisen h√§ufiger den Superhost-Status auf. Dies ist weniger ein Hinweis darauf, dass die Anzahl der vermieteten Wohnungen selbst entscheidend ist, sondern vielmehr darauf, dass diese Hosts Airbnb gewerblich oder zumindest professioneller betreiben. Dadurch sind sie tendenziell besser organisiert und schneiden in anderen relevanten Faktoren wie Reaktionszeit, Buchungsannahme und G√§stekommunikation besser ab. Die Korrelation k√∂nnte zudem dadurch beeinflusst sein, dass erfahrene Gastgeber sich proaktiver um den Superhost-Status bem√ºhen oder besser mit den Anforderungen der Plattform vertraut sind.\n",
    "\n",
    "2. **`host_response_time`:** und **`host_acceptance_rate_percent`**\n",
    "   Eine schnelle Reaktion auf Anfragen und eine hohe Annahmequote gelten als zentrale Anforderungen, da sie Verl√§sslichkeit signalisieren.\n",
    "\n",
    "3. **`reviews_per_month`** und **`review_scores_cleanliness`:**\n",
    "   Regelm√§ssige und qualitativ hochwertige Bewertungen, insbesondere im Bereich Sauberkeit, sprechen f√ºr ein hohes Serviceniveau.\n",
    "\n",
    "**Kritische Einordnung:**\n",
    "\n",
    "- Merkmale wie `host_identity_verified` oder `host_has_profile_pic` tragen im Modell kaum zur Vorhersagekraft bei. Dies kann durch geringe Varianz in diesen Spalten erkl√§rt werden oder darauf hinweisen, dass sie f√ºr G√§ste keine ausschlaggebende Rolle spielen.\n",
    "\n",
    "- Die Ausstattung der Unterkunft (z.‚ÄØB. **`beds`**, **`bathrooms`**, **`room_type`**) ist im Zusammenhang mit dem Superhost-Status weniger relevant, was plausibel erscheint ‚Äì dieser Status bewertet vorrangig das Verhalten des Hosts.\n",
    "\n",
    "- Der Einfluss von **`price`** ist ebenfalls gering. Daraus l√§sst sich schliessen, dass Preisgestaltung allein nicht entscheidend ist ‚Äì wichtiger ist das gebotene Preis-Leistungs-Verh√§ltnis.\n",
    "\n",
    "### Modellvergleich f√ºr Random Forest vs. Logistische Regression\n",
    "\n",
    "Zur Validierung der Modellg√ºte und zur Einordnung der Ergebnisse wird das Random-Forest-Modell mit einer Logistischen Regression verglichen ‚Äì einem einfacheren, gut interpretierbaren Klassifikator. Beide Modelle werden mittels 5-facher Cross-Validation bewertet, zus√§tzlich erfolgt ein Vergleich der ROC-Kurven. Dies erm√∂glicht eine differenzierte Beurteilung der Trennsch√§rfe und Stabilit√§t beider Modelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d6cdef4",
   "metadata": {},
   "source": [
    "log_model = LogisticRegression(max_iter=1000000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "print(\"Logistische Regression - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "rf_cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Random Forest - durchschnittliche CV-Accuracy:\", rf_cv_scores.mean())\n",
    "\n",
    "log_cv_scores = cross_val_score(log_model, X, y, cv=5)\n",
    "print(\"Logistische Regression - durchschnittliche CV-Accuracy:\", log_cv_scores.mean())\n",
    "\n",
    "\n",
    "probs_rf = model.predict_proba(X_test)[:, 1]\n",
    "probs_log = log_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, probs_rf)\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, probs_log)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = {:.2f})'.format(roc_auc_score(y_test, probs_rf)))\n",
    "plt.plot(fpr_log, tpr_log, label='Logistische Regression (AUC = {:.2f})'.format(roc_auc_score(y_test, probs_log)))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-Kurve Vergleich')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f3951cd",
   "metadata": {},
   "source": [
    "### Modellvergleich und Auswahl\n",
    "\n",
    "Die Gegen√ºberstellung der beiden Klassifikatoren zeigt einen deutlichen Leistungsunterschied: Der Random Forest erzielt eine AUC von 0.94, w√§hrend die Logistische Regression bei 0.77 liegt. Auch in der ROC-Kurve wird dieser Unterschied visuell deutlich ‚Äì der Random Forest verl√§uft n√§her an der idealen oberen linken Ecke und weist somit eine h√∂here Trennsch√§rfe auf.\n",
    "\n",
    "Die Cross-Validation-Ergebnisse best√§tigen dieses Bild: Der Random Forest erreicht im Mittel eine h√∂here Genauigkeit, zeigt sich gleichzeitig stabil und robust gegen√ºber unterschiedlichen Trainings-/Test-Splits. Die Logistische Regression liefert akzeptable, aber deutlich schw√§chere Ergebnisse.\n",
    "\n",
    "Der Random Forest ist dem linearen Modell sowohl bei der Gesamtg√ºte (AUC) als auch bei der generalisierbaren Genauigkeit (CV-Score) klar √ºberlegen.\n",
    "\n",
    "Aufgrund seiner nichtlinearen Struktur kann der Random Forest auch komplexe Zusammenh√§nge zwischen den Merkmalen besser abbilden ‚Äì was bei einem vielseitigen Merkmalssatz wie in diesem Fall entscheidend ist.\n",
    "\n",
    "F√ºr die finale Modellierung und die Ableitung strategischer Empfehlungen wird daher auf den Random Forest als Hauptmodell gesetzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc752475",
   "metadata": {},
   "source": [
    "## Objective 4 ‚Äì Listing-Optimierung durch Textanalyse\n",
    "\n",
    "Ziel dieses Untersuchungsabschnitts ist es, den Einfluss von sprachlichen und inhaltlichen Eigenschaften in Listing-Beschreibungen auf die Performance von Airbnb-Angeboten im Raum Z√ºrich systematisch zu analysieren. Im Fokus steht die Frage, ob sich durch gezielte Optimierung von Beschreibungstexten messbare Effekte auf Buchungserfolg, Bewertung oder Preissetzung erzielen lassen ‚Äì und wie die InvestZurich AG diese Erkenntnisse nutzen kann, um ihre Listings gezielt zu verbessern.\n",
    "\n",
    "Im Zentrum der Analyse steht die strukturelle und inhaltliche Auswertung der Textspalte 'description' mithilfe von Methoden der nat√ºrlichen Sprachverarbeitung (Natural Language Processing, NLP). Dabei werden zun√§chst syntaktische Merkmale wie Textl√§nge, Stimmung (Sentiment) und Subjektivit√§t untersucht, um ein Gef√ºhl f√ºr den sprachlichen Charakter der Texte zu bekommen. In einem zweiten Schritt erfolgt eine Themenanalyse (Topic Modeling), um wiederkehrende inhaltliche Muster zu identifizieren.\n",
    "\n",
    "Ziel dieser Analyse ist es, datenbasiert herauszufinden, welche Textmerkmale besonders h√§ufig in gut bewerteten oder hochpreisigen Listings vorkommen ‚Äì oder ob bestimmte sprachliche Stile tendenziell mit besseren Resultaten einhergehen. Auf dieser Basis sollen f√ºr die InvestZurich AG konkrete Empfehlungen zur textbasierten Listing-Optimierung abgeleitet werden, etwa im Hinblick auf Keyword-Nutzung, Tonalit√§t oder Zielgruppenansprache.\n",
    "\n",
    "Die nachfolgende Analyse liefert somit die Grundlage f√ºr eine inhaltlich fundierte und skalierbare Optimierungsstrategie, die √ºber rein visuelle oder lagebezogene Aspekte hinausgeht ‚Äì und gezielt das Potenzial textlicher Kommunikation als Erfolgsfaktor nutzt."
   ]
  },
  {
   "cell_type": "code",
   "id": "f33cefc5",
   "metadata": {},
   "source": [
    "# Stellt sicher, dass df_analysis und die relevante Textspalte (z.B. 'description') existieren.\n",
    "\n",
    "# Haupt-Textspalte f√ºr die detaillierte Analyse (gem√§ss bina_models.Listing)\n",
    "# Andere Textspalten wie 'name', 'neighborhood_overview', 'host_about' k√∂nnen analog analysiert werden.\n",
    "import sys\n",
    "#!{sys.executable} -m pip install supabase\n",
    "#!{sys.executable} -m pip install python-dotenv\n",
    "#!{sys.executable} -m pip install pandas\n",
    "#!{sys.executable} -m pip install nltk\n",
    "#!{sys.executable} -m pip install scikit-learn\n",
    "#!{sys.executable} -m pip install matplotlib seaborn textblob\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Ressourcen laden (nur 1x n√∂tig)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from airbnb_analysis_service import AirbnbAnalysisService\n",
    "\n",
    "airbnbAnalysis = AirbnbAnalysisService()\n",
    "listings = airbnbAnalysis.get_listings()\n",
    "main_text_col_for_nlp = 'description'\n",
    "df_analysis = pd.DataFrame([l.__dict__ for l in listings])\n",
    "\n",
    "if not df_analysis.empty and main_text_col_for_nlp in df_analysis.columns and df_analysis[main_text_col_for_nlp].notna().sum() > 0 :\n",
    "    print(f\"\\n--- Analysen f√ºr Use Case 4 (NLP) basierend auf Spalte '{main_text_col_for_nlp}' ---\")\n",
    "\n",
    "    # Stichprobe f√ºr rechenintensive NLP-Tasks (Gr√∂sse anpassen falls n√∂tig)\n",
    "    # Verwende nur Zeilen, in denen die Haupttextspalte nicht leer ist nach der Vorbereitung (fillna(''))\n",
    "    df_nlp_source = df_analysis[df_analysis[main_text_col_for_nlp].str.strip().astype(bool)]\n",
    "\n",
    "    sample_size_nlp_uc4 = min(1000, len(df_nlp_source))\n",
    "    if len(df_nlp_source) < sample_size_nlp_uc4 : sample_size_nlp_uc4 = len(df_nlp_source)\n",
    "\n",
    "    if sample_size_nlp_uc4 < 20 :\n",
    "         print(f\"Stichprobengr√∂sse ({sample_size_nlp_uc4}) f√ºr '{main_text_col_for_nlp}' zu klein f√ºr NLP-Analyse. √úberspringe.\")\n",
    "    else:\n",
    "        df_nlp = df_nlp_source.sample(n=sample_size_nlp_uc4, random_state=42).copy()\n",
    "        print(f\"NLP-Analyse wird auf einer Stichprobe von {len(df_nlp)} Listings f√ºr '{main_text_col_for_nlp}' durchgef√ºhrt.\")\n",
    "\n",
    "        # --- Textdaten-Vorbereitung f√ºr NLP ---\n",
    "        print(\"\\n--- Textdaten-Vorbereitung f√ºr NLP ---\")\n",
    "        stop_words_de_uc4 = stopwords.words('german')\n",
    "        stop_words_en_uc4 = stopwords.words('english')\n",
    "        custom_stopwords_uc4 = [\n",
    "            'br', 'href', 'www', 'https', 'http', 'com', 'zurich', 'z√ºrich', 'apartment', 'wohnung',\n",
    "            'description', 'guest', 'guests', 'stay', 'place', 'room', 'rooms', 'city', 'haus', 'home',\n",
    "            'house', 'area', 'also', 'well', 'get', 'see', 'us', 'come', 'min', 'one', 'two', 'meter',\n",
    "            'bit', 'eur', 'chf', 'day', 'week', 'nbsp', 'amp', 'quot', 'lt', 'gt', 'apos', 'zurich',\n",
    "            'apartment', 'flat', 'studio', 'appartement' # Generische Airbnb Begriffe\n",
    "        ]\n",
    "        all_stopwords_uc4 = set(stop_words_de_uc4 + stop_words_en_uc4 + custom_stopwords_uc4)\n",
    "\n",
    "        lemmatizer_uc4 = WordNetLemmatizer()\n",
    "\n",
    "        def preprocess_text_nlp(text_series):\n",
    "            processed_texts = []\n",
    "            for text_doc in text_series:\n",
    "                doc = str(text_doc).lower()\n",
    "                doc = re.sub(r'<[^>]+>', ' ', doc) # HTML entfernen\n",
    "                doc = re.sub(r'[^a-z√§√∂√ºss\\s]', ' ', doc) # Nur Buchstaben (inkl. Umlaute) und Leerzeichen\n",
    "                doc = re.sub(r'\\s+', ' ', doc).strip() # √úberfl√ºssige Leerzeichen entfernen\n",
    "\n",
    "                # Sprachabh√§ngige Tokenisierung und Lemmatisierung (einfacher Ansatz)\n",
    "                # F√ºr eine pr√§zisere NLP bei gemischtsprachigen Texten w√§ren fortgeschrittenere Methoden n√∂tig\n",
    "                lang_to_tokenize = 'german' if any(c in '√§√∂√ºss' for c in doc) else 'english'\n",
    "\n",
    "                try:\n",
    "                    tokens = word_tokenize(doc, language=lang_to_tokenize)\n",
    "                except LookupError: # Fallback, falls spezifische Sprachdaten f√ºr punkt fehlen\n",
    "                    try: nltk.download('punkt', quiet=True); tokens = word_tokenize(doc, language=lang_to_tokenize)\n",
    "                    except: tokens = doc.split() # Einfaches Splitten als Notl√∂sung\n",
    "\n",
    "                # Lemmatisierung - WordNetLemmatizer ist prim√§r f√ºr Englisch.\n",
    "                # F√ºr Deutsch w√§ren andere Lemmatizer (z.B. GermaLemma, spaCy mit deutschem Modell) besser.\n",
    "                # Hier als Ann√§herung f√ºr beide Sprachen verwendet.\n",
    "                lemmatized_tokens = [lemmatizer_uc4.lemmatize(token) for token in tokens if token not in all_stopwords_uc4 and len(token) > 2]\n",
    "                processed_texts.append(\" \".join(lemmatized_tokens))\n",
    "            return processed_texts\n",
    "\n",
    "        print(\"Beginne mit der Textvorverarbeitung f√ºr NLP (kann etwas dauern)...\")\n",
    "        df_nlp.loc[:, 'description_cleaned_nlp'] = preprocess_text_nlp(df_nlp[main_text_col_for_nlp])\n",
    "        print(\"Textvorverarbeitung abgeschlossen.\")\n",
    "\n",
    "        if not df_nlp['description_cleaned_nlp'].empty:\n",
    "            example_cleaned_desc_uc4 = df_nlp['description_cleaned_nlp'].head(1)\n",
    "            print(f\"\\nBeispiel f√ºr bereinigte Beschreibung:\\n{example_cleaned_desc_uc4.iloc[0] if not example_cleaned_desc_uc4.empty else 'Keine Daten'}\")\n",
    "\n",
    "        # --- Sentiment Analyse ---\n",
    "        print(\"\\n--- Sentiment Analyse ---\")\n",
    "        def get_sentiment_textblob(text_to_analyze):\n",
    "            if not text_to_analyze or not isinstance(text_to_analyze, str) or not text_to_analyze.strip(): return 0.0, 0.0\n",
    "            try:\n",
    "                # TextBlob versucht, die Sprache zu erkennen. F√ºr Deutsch ist die Genauigkeit manchmal limitiert.\n",
    "                blob = TextBlob(text_to_analyze)\n",
    "                return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "            except Exception as e_sent:\n",
    "                # print(f\"Fehler bei Sentiment Analyse f√ºr Text: '{text_to_analyze[:50]}...' - {e_sent}\")\n",
    "                return 0.0, 0.0\n",
    "\n",
    "        sentiments_nlp_uc4 = df_nlp['description_cleaned_nlp'].apply(get_sentiment_textblob)\n",
    "        df_nlp.loc[:, 'sentiment_polarity'] = sentiments_nlp_uc4.apply(lambda x: x[0])\n",
    "        df_nlp.loc[:, 'sentiment_subjectivity'] = sentiments_nlp_uc4.apply(lambda x: x[1])\n",
    "\n",
    "        print(\"\\nDeskriptive Statistiken f√ºr Sentiment-Scores:\")\n",
    "        print(df_nlp[['sentiment_polarity', 'sentiment_subjectivity']].describe())\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1); sns.histplot(df_nlp['sentiment_polarity'], kde=True, bins=20, color='purple'); plt.title('Verteilung Sentiment-Polarit√§t (Description)')\n",
    "        plt.subplot(1, 2, 2); sns.histplot(df_nlp['sentiment_subjectivity'], kde=True, bins=20, color='orange'); plt.title('Verteilung Sentiment-Subjektivit√§t (Description)')\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        # Korrelation Sentiment mit Performance-Metriken\n",
    "        # Stelle sicher, dass die Spalten f√ºr die Korrelation numerisch sind und existieren\n",
    "        cols_for_sentiment_corr_uc4 = [col for col in ['sentiment_polarity', 'sentiment_subjectivity', 'review_scores_rating', 'price']\n",
    "                                       if col in df_nlp.columns and pd.api.types.is_numeric_dtype(df_nlp[col])]\n",
    "        if len(cols_for_sentiment_corr_uc4) > 2 :\n",
    "            sentiment_corr_df_uc4 = df_nlp[cols_for_sentiment_corr_uc4].corr()\n",
    "            print(\"\\nKorrelation von Sentiment mit Performance-Metriken:\\n\", sentiment_corr_df_uc4)\n",
    "            plt.figure(figsize=(7,5)); sns.heatmap(sentiment_corr_df_uc4, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1); plt.title(\"Sentiment Korrelationen\"); plt.show()\n",
    "        else:\n",
    "            print(\"Nicht gen√ºgend Spalten f√ºr Sentiment-Korrelationsanalyse vorhanden.\")\n",
    "\n",
    "        # --- Topic Modeling (LDA) ---\n",
    "        print(\"\\n--- Topic Modeling (LDA) ---\")\n",
    "        # Nur Texte verwenden, die nach der Bereinigung nicht leer sind\n",
    "        documents_for_lda_uc4 = df_nlp['description_cleaned_nlp'][df_nlp['description_cleaned_nlp'].str.strip().astype(bool)]\n",
    "\n",
    "        if len(documents_for_lda_uc4) > 20: # Mindestanzahl Dokumente f√ºr LDA\n",
    "            try:\n",
    "                # max_features begrenzt das Vokabular f√ºr bessere Performance und klarere Topics\n",
    "                vectorizer_tfidf_uc4 = TfidfVectorizer(max_df=0.90, min_df=5, stop_words=list(all_stopwords_uc4), ngram_range=(1,1), max_features=1000)\n",
    "                tfidf_matrix_uc4 = vectorizer_tfidf_uc4.fit_transform(documents_for_lda_uc4)\n",
    "                feature_names_tfidf_uc4 = vectorizer_tfidf_uc4.get_feature_names_out()\n",
    "\n",
    "                num_topics_uc4 = 5 # ANPASSEN: Anzahl der zu entdeckenden Topics (typischerweise 5-15)\n",
    "                if tfidf_matrix_uc4.shape[1] >= num_topics_uc4: # Gen√ºgend Features f√ºr Topics\n",
    "                    lda_model_uc4 = LatentDirichletAllocation(n_components=num_topics_uc4, random_state=42, learning_method='online', n_jobs=-1, max_iter=15, evaluate_every=1)\n",
    "                    lda_model_uc4.fit(tfidf_matrix_uc4)\n",
    "\n",
    "                    print(f\"\\nTop W√∂rter f√ºr {num_topics_uc4} entdeckte Topics (LDA aus '{main_text_col_for_nlp}'):\")\n",
    "                    def display_topics_lda(model, feature_names, no_top_words):\n",
    "                        for topic_idx, topic_dist in enumerate(model.components_):\n",
    "                            top_words_indices = topic_dist.argsort()[:-no_top_words - 1:-1]\n",
    "                            top_words = [feature_names[i] for i in top_words_indices]\n",
    "                            print(f\"Thema #{topic_idx+1}: {' | '.join(top_words)}\")\n",
    "                    display_topics_lda(lda_model_uc4, feature_names_tfidf_uc4, 10) # Zeige Top 10 W√∂rter pro Topic\n",
    "                else:\n",
    "                    print(\"Nicht gen√ºgend einzigartige Features nach TF-IDF f√ºr LDA (Anzahl Topics vs. Features).\")\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler w√§hrend Topic Modeling: {e}\")\n",
    "        else:\n",
    "            print(\"Nicht gen√ºgend Dokumente f√ºr Topic Modeling vorhanden nach Bereinigung/Filterung.\")\n",
    "else:\n",
    "    print(f\"Analysen f√ºr Use Case 4 (NLP) k√∂nnen nicht durchgef√ºhrt werden (DataFrame `df_analysis` leer oder Spalte '{main_text_col_for_nlp}' fehlt oder enth√§lt keine Texte).\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3428e35",
   "metadata": {},
   "source": [
    "### Textvorbereitung\n",
    "Die Beschreibungen `'description'` wurden bereinigt, tokenisiert, von Stopw√∂rtern befreit und lemmatisiert. Ein Beispiel f√ºr eine bereinigte Beschreibung aus der Stichprobe ist: `enjoy stylish experience centrally located`.\n",
    "\n",
    "### Sentiment Analyse\n",
    " - Die durchschnittliche Sentiment-Polarit√§t der Objektbeschreibungen (basierend auf der Stichprobe `df_nlp`) liegt bei **0.253** (Werte reichen von -0.2 bis +0.925). Eine **leicht positive** Polarit√§t √ºberwiegt.\n",
    "- Die durchschnittliche Subjektivit√§t liegt bei **0.486** (Werte von 0.0 bis 1.0). *Interpretation: Die Texte sind im Durchschnitt weder rein objektiv noch extrem subjektiv, sondern bewegen sich in einem mittleren, werblich-informativen Bereich.*\n",
    "- Korrelation mit Performance:** *(Basierend auf `sentiment_corr_df_uc4`)*\n",
    "    - Polarit√§t vs. `'review_scores_rating'`: **-0.03**\n",
    "    - Polarit√§t vs. `'price'`: **+0.03**\n",
    "\n",
    "**Interpretation:** Eine positivere Sprache in den Beschreibungen f√ºhrt weder zu besseren Bewertungen noch zu h√∂heren Preisen. Auch Subjektivit√§t zeigt keine statistisch relevante Korrelation mit Performance-Metriken.*\n",
    "\n",
    "### Topic Modeling (LDA)\n",
    "Es wurden **5** Hauptthemen in den Objektbeschreibungen der Stichprobe identifiziert.\n",
    "\n",
    "**Thema 1:** Top W√∂rter: `minute | located | station | enjoy | tram | restaurant | train | walk | location | away`\n",
    "(Dieses Thema k√∂nnte sich auf **Lagevorteile und zentrale Erreichbarkeit** beziehen.)\n",
    "\n",
    "**Thema 2:** Top W√∂rter: `booking | ask | case | car | pay | discount | please | parking | need | accessible`\n",
    "(Dieses Thema behandelt **Buchungshinweise, Erreichbarkeit und m√∂gliche Zusatzkosten**.)\n",
    "\n",
    "**Thema 3:** Top W√∂rter: `simple | life | centrally | peaceful | located | enjoy | quiet | keep | national | museum`\n",
    "(Hier geht es um **Atmosph√§re und Lage ‚Äì ruhige, kulturell attraktive Wohnlage**.)\n",
    "\n",
    "**Thema 4:** Top W√∂rter: `photo | paradeplatz | painting | bijou | luxuriously | digital | optic | europaallee | frame | fiber`\n",
    "(Dieses Thema beschreibt **Design, Kunst, Luxusausstattung und spezifische Stadtteile (Z√ºrich)**.)\n",
    "\n",
    "**Thema 5:** Top W√∂rter: `bed | kitchen | bathroom | bedroom | equipped | living | balcony | fully | machine | shower`\n",
    "(Fokus liegt hier klar auf der **Innenausstattung und praktischen Einrichtung** der Unterkunft.)\n",
    "\n",
    "**Wie k√∂nnten diese Themen mit der Performance zusammenh√§ngen?**\n",
    " Eine weiterf√ºhrende Analyse k√∂nnte untersuchen, ob bestimmte Themen (z.‚ÄØB. Lage oder Luxusausstattung) h√§ufiger mit h√∂herer Bewertung oder h√∂heren Preisen korrelieren. Dazu w√§re es sinnvoll, jedem Listing das dominante Thema zuzuordnen und dann den Preis/Score innerhalb jeder Themengruppe zu vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22341b30",
   "metadata": {},
   "source": [
    "# Step 4: Presenting Information\n",
    "In diesem Kapitel werden die zentralen Erkenntnisse der vier analysierten Objectives zusammengefasst und √ºbersichtlich dargestellt. Abschliessend wird eine √ºbergreifende Schlussfolgerung gezogen, die alle Ergebnisse in einen gemeinsamen strategischen Kontext bringt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6325e",
   "metadata": {},
   "source": [
    "## Objective 1 ‚Äì Marktpotenzial und Standortanalyse\n",
    "Im Rahmen von Objecitve 1 wurde eine Standort- und Potenzialanalyse f√ºr den Airbnb-Markt in der Stadt Z√ºrich durchgef√ºhrt. Dabei wurden verschiedene Perspektiven ber√ºcksichtigt: die Verteilung und Anzahl der Angebote pro Stadtkreis, Preisniveaus, Auslastung bzw. Verf√ºgbarkeit, Unterkunftstypen, G√§stekapazit√§ten sowie die Klassifikation besonders erfolgreicher Inserate mittels eines Random-Forest-Modells.\n",
    "\n",
    "Die Ergebnisse zeigen deutlich, dass sich das Investitionspotenzial nicht pauschal auf einzelne Stadtteile oder Unterkunftstypen reduzieren l√§sst. Vielmehr entsteht ein differenziertes Bild, bei dem mehrere Faktoren zusammenwirken. Auf Basis der durchgef√ºhrten Analysen lassen sich f√ºr die InvestZurich AG folgende zentrale Handlungsempfehlungen ableiten:\n",
    "\n",
    "### Hohe Nachfrage f√ºr Standortwahl gezielt nutzen\n",
    "\n",
    "Kreise mit niedriger durchschnittlicher Verf√ºgbarkeit, wie z.B. Kreis 10, Kreis 5 und Kreis 2, weisen auf eine hohe Buchungsauslastung hin. Besonders Kreis 2 f√§llt zudem durch ein sehr hohes Preisniveau auf, was auf ein √ºberdurchschnittlich hohes Umsatzpotenzial hindeutet. Gleichzeitig ist hier das Angebot vergleichsweise gering, was auf eine attraktive Marktl√ºcke hinweisen kann. Investitionen sollten gezielt auf Stadtteile ausgerichtet werden, die hohe Nachfrage mit √ºberschaubarem Wettbewerb kombinieren."
   ]
  },
  {
   "cell_type": "code",
   "id": "1b5890ce",
   "metadata": {},
   "source": [
    "display(fig3)\n",
    "display(fig2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f46c1e15",
   "metadata": {},
   "source": [
    "### Unterkunftsgr√∂sse und Kapazit√§t strategisch w√§hlen\n",
    "\n",
    "Die Analyse der Unterkunftskapazit√§t zeigt, dass insbesondere Objekte mit Platz f√ºr 6 bis 8 Personen stark nachgefragt sind. Diese Einheiten weisen eine signifikant niedrigere Verf√ºgbarkeit auf und lassen auf eine hohe Beliebtheit schliessen. Gleichzeitig erm√∂glichen sie durch h√∂here Preise pro Nacht ein attraktives Umsatzpotenzial. Auch kleinere Einheiten f√ºr 1 bis 2 G√§ste bleiben relevant, da sie eine solide Auslastung erzielen und ein breites Zielpublikum ansprechen."
   ]
  },
  {
   "cell_type": "code",
   "id": "aca6b628",
   "metadata": {},
   "source": [
    "display(fig5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5040547e",
   "metadata": {},
   "source": [
    "### Geeignete Unterkunftstypen priorisieren\n",
    "\n",
    "Im Vergleich der Unterkunftstypen zeigt sich, dass \"Private Rooms\" und \"Entire Homes/Apartments\" h√§ufiger gebucht werden als z.B. Hotelzimmer, was durch geringere durchschnittliche Verf√ºgbarkeiten belegt wird. F√ºr eine skalierbare Investmentstrategie bieten sich insbesondere ganze Wohnungen an, da sie mehr Flexibilit√§t in Preisgestaltung, Ausstattung und Zielgruppenansprache erm√∂glichen."
   ]
  },
  {
   "cell_type": "code",
   "id": "0727ee8a",
   "metadata": {},
   "source": [
    "display(fig4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d886380",
   "metadata": {},
   "source": [
    "### Datenbasiertes Auswahlverfahren etablieren\n",
    "\n",
    "Das entwickelte Random-Forest-Modell zur Klassifikation von Top Performern erm√∂glicht eine erste Einsch√§tzung, ob ein Angebot Potenzial f√ºr hohe Nachfrage und Ertrag aufweist. Die wichtigsten Einflussfaktoren im Modell waren dabei die Kapazit√§t, Lage und Anzahl der Schlafzimmer. Dieses Modell kann als unterst√ºtzendes Tool genutzt werden, um neue Angebote im Markt vorab zu bewerten und Investitionsrisiken zu minimieren."
   ]
  },
  {
   "cell_type": "code",
   "id": "1277111a",
   "metadata": {},
   "source": [
    "display(fig6)\n",
    "display(fig7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93dd69fc",
   "metadata": {},
   "source": [
    "## Objective 2 ‚Äì Preisstrategie und Ertragsprognose\n",
    "Basierend auf dieser detaillierten Analyse in **Step 3** k√∂nnen wir folgende Schl√ºsse f√ºr die \"InvestZurich AG\" ziehen:\n",
    "\n",
    "1. **Nicht nur auf absolute Einnahmen achten:** Obwohl Quartiere wie `Kreis 1` hohe absolute Airbnb-Einnahmen generieren k√∂nnen, sind die Immobilienpreise dort so exorbitant, dass die relative Rentabilit√§t (gemessen am `Revenue_Yield_Proxy`) am niedrigsten ist.\n",
    "\n",
    "2. **Attraktive Quartiere identifiziert:**\n",
    "- `Kreis 12` sticht als das potenziell rentabelste Quartier hervor, basierend auf dem h√∂chsten `Revenue_Yield_Proxy`.\n",
    "- `Kreis 4` und `Kreis 6` bieten ebenfalls sehr attraktive `Revenue_Yield_Proxy-Werte`.\n",
    "\n",
    "3. **Diversifikationspotenzial:** Das Mittelfeld (`Kreis 2`, `10`, `3`, `5`, `8`) bietet solide `Revenue_Yield_Proxy`-Werte und k√∂nnte f√ºr eine Diversifikationsstrategie interessant sein.\n",
    "\n",
    "4. **Vorsicht bei teuersten Lagen f√ºr reine Renditeobjekte:** F√ºr Investitionen mit Fokus auf laufende Rendite im Verh√§ltnis zum Kapitaleinsatz (pro m¬≤) scheinen die teuersten Lagen (`Kreis 1`, `Kreis 7`, `Kreis 9`) weniger geeignet.\n",
    "\n",
    "**Wichtige Einschr√§nkung:** Unser `Revenue_Yield_Proxy` ist eine Vereinfachung und ber√ºcksichtigt nicht die spezifische Gr√∂sse der Airbnb-Objekte im Verh√§ltnis zum Quadratmeterpreis. F√ºr detailliertere ROI-Betrachtungen w√§ren weitere Daten (z.B. durchschnittliche Wohnungsgr√∂ssen) oder die Analyse spezifischer Objektkategorien notwendig. Dennoch bietet diese Kennzahl eine wertvolle erste Orientierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2bdd85",
   "metadata": {},
   "source": [
    "## Objective 3 ‚Äì Marktpotenzial und Standortanalyse\n",
    "\n",
    "Im Rahmen von Objective 3 wurde analysiert, welche quantitativen und qualitativen Merkmale Superhosts auf Airbnb im Raum Z√ºrich von anderen Gastgebern unterscheiden. Ziel war es, InvestZurich AG datenbasiert aufzuzeigen, wie der Superhost-Status gezielt erreicht werden kann. Zum Einsatz kamen Mittelwertvergleiche, Boxplot-Analysen, ein Random-Forest-Klassifikator sowie ein Modellvergleich mit logistischer Regression.\n",
    "\n",
    "Die Ergebnisse belegen klar, dass Superhosts durch ein konsistentes Gesamtprofil √ºberzeugen ‚Äì insbesondere in den Bereichen **Reaktionsverhalten, Buchungszuverl√§ssigkeit, G√§stefeedback** und **operative Pr√§senz**. Daraus ergeben sich folgende priorisierte Handlungsempfehlungen:\n",
    "\n",
    "### Gastgeberverhalten konsequent optimieren\n",
    "\n",
    "Die Analyse zeigt, dass Superhosts in mehreren operativen Dimensionen systematisch besser abschneiden als regul√§re Gastgeber:innen. Eine der deutlichsten Abweichungen findet sich im Antwortverhalten: Superhosts reagieren nicht nur schneller, sondern auch konsequenter auf Buchungsanfragen. Die Antwortraten liegen nahezu durchg√§ngig bei 100‚ÄØ%, w√§hrend sie bei Nicht-Superhosts deutlich st√§rker streuen ‚Äì teils sogar unter die von Airbnb geforderte Mindestgrenze von 90‚ÄØ%. Auch die Annahmequote ist bei Superhosts signifikant h√∂her und konsistenter. Dieses verl√§ssliche Buchungsverhalten ist eine zentrale Voraussetzung f√ºr Vertrauen auf Plattformen wie Airbnb.\n",
    "\n",
    "InvestZurich AG sollte automatisierte Antwortfunktionen und standardisierte Buchungsprozesse einf√ºhren, um eine Antwortrate von mindestens 90‚ÄØ% sicherzustellen. Zus√§tzlich sollten Kalendersysteme mit Echtzeit-Verf√ºgbarkeit integriert werden, um Absagen zu vermeiden und die Annahmequote stabil hoch zu halten."
   ]
  },
  {
   "cell_type": "code",
   "id": "810b2c96",
   "metadata": {},
   "source": [
    "display(fig90)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "801f99ff",
   "metadata": {},
   "source": [
    "### Buchungserfahrung strategisch aufbauen\n",
    "\n",
    "Superhosts weisen im Mittel mehr als doppelt so viele Bewertungen auf wie Nicht-Superhosts. Dies l√§sst sich zwar nicht 1:1 in Buchungen √ºbersetzen, deutet aber auf eine deutlich h√∂here Aktivit√§t und Sichtbarkeit auf der Plattform hin. Bewertungen wirken wie ein soziales Vertrauenssignal und verbessern zugleich die algorithmische Platzierung bei Airbnb.\n",
    "\n",
    "InvestZurich AG sollte f√ºr neue Inserate gezielte Nachfrageanreize schaffen ‚Äì etwa durch zeitlich befristete Einf√ºhrungsangebote, niedrige Mindestaufenthalte oder erh√∂hte Verf√ºgbarkeit. Ziel ist es, m√∂glichst schnell die ersten 10‚Äì15 Bewertungen zu sammeln, um eine solide Buchungshistorie aufzubauen und Sichtbarkeit im Ranking zu erh√∂hen.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "61162f3d",
   "metadata": {},
   "source": [
    "display(fig91)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d39c4526",
   "metadata": {},
   "source": [
    "### Bewertungsqualit√§t aktiv steuern\n",
    "\n",
    "Superhosts erzielen durchg√§ngig bessere Bewertungen in den Bereichen Sauberkeit, Kommunikation und Gesamtbewertung ‚Äì mit geringerer Streuung als Nicht-Superhosts. Diese Konstanz weist auf strukturierte Abl√§ufe und kontrollierte Serviceprozesse hin. Schlechte Einzelbewertungen sind selten, was das Vertrauen k√ºnftiger G√§ste st√§rkt und die Conversion-Rate erh√∂ht.\n",
    "\n",
    "InvestZurich AG sollte standardisierte Checklisten f√ºr Reinigung, Check-in und G√§stekommunikation einf√ºhren. Zudem sollten Bewertungen systematisch ausgewertet werden, um Schwachstellen zu identifizieren. G√§ste sollten aktiv zur Bewertung eingeladen werden, z.‚ÄØB. √ºber Follow-up-Nachrichten oder QR-Codes vor Ort."
   ]
  },
  {
   "cell_type": "code",
   "id": "309d3206",
   "metadata": {},
   "source": [
    "display(fig92)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "42fbdb95",
   "metadata": {},
   "source": [
    "### Datengetrieben entscheiden mit Modellunterst√ºtzung\n",
    "\n",
    "Das Machine-Learning-Modell zeigt, dass insbesondere Merkmale wie Anzahl Inserate, Annahmequote, Bewertungsh√§ufigkeit und Servicequalit√§t starke Pr√§diktoren f√ºr den Superhost-Status sind. Diese Erkenntnisse sind nicht nur erkl√§rend, sondern bieten eine Grundlage zur operativen Steuerung und Priorisierung im Portfolio.\n",
    "\n",
    "InvestZurich AG sollte das ML-Modell zur laufenden Objektbewertung einsetzen. Erg√§nzend kann ein internes Dashboard entwickelt werden, das die wichtigsten KPI-L√ºcken visualisiert und datenbasiert Handlungsempfehlungen f√ºr jedes Objekt ableitet."
   ]
  },
  {
   "cell_type": "code",
   "id": "b60e7e67",
   "metadata": {},
   "source": [
    "display(fig93)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9f0950b",
   "metadata": {},
   "source": [
    "## Objective 4 ‚Äì Listing-Optimierung durch Textanalyse\n",
    "\n",
    "Die nachfolgend abgeleiteten Empfehlungen basieren auf einer datengetriebenen Analyse von Listing-Beschreibungen mithilfe moderner NLP-Verfahren (Natural Language Processing). Im Zentrum standen linguistische Merkmale wie Stimmung (Sentiment), Subjektivit√§t und thematische Inhalte. Ziel war es, herauszufinden, ob und wie sich Textgestaltung auf die Performance von Airbnb-Listings auswirkt ‚Äì etwa in Bezug auf Bewertung, Preisniveau oder Sichtbarkeit.\n",
    "\n",
    "Auch wenn die Korrelationen mit Performance-Metriken nur schwach ausfielen, zeigen sich klare Muster hinsichtlich typischer Themen, Sprachstile und Wortwahl, die f√ºr die Optimierung von Listing-Texten genutzt werden k√∂nnen. Die folgenden Handlungsempfehlungen bieten InvestZurich AG eine pragmatische Grundlage f√ºr die strategische Weiterentwicklung ihrer textlichen Kommunikation auf Airbnb.\n",
    "\n",
    "1. **Positivit√§t gezielt einsetzen:**  \n",
    "   Da eine insgesamt leicht **positive Sprachweise** in den Listings vorherrscht, die jedoch **nicht direkt mit besseren Bewertungen oder h√∂heren Preisen korreliert**, sollte die Sprache zwar weiterhin einladend, aber gleichzeitig **faktenbasiert und informativ** bleiben. Eine **ausgewogene Mischung aus subjektiver und objektiver Sprache** scheint optimal zu sein.\n",
    "\n",
    "2. **Wichtige Themen gezielt hervorheben:**  \n",
    "   Die Topic-Modellierung zeigt, dass Themen wie **Lage, Ausstattung, Atmosph√§re und Buchungsdetails** h√§ufig vorkommen. Diese Inhalte sollten in zuk√ºnftigen Listings klar und strukturiert adressiert werden ‚Äì insbesondere dann, wenn sie f√ºr die Zielgruppe relevant sind.\n",
    "\n",
    "3. **Keywords zur Sichtbarkeitssteigerung nutzen:**  \n",
    "   Die identifizierten Top-W√∂rter der Themen (z.‚ÄØB. \"kitchen\", \"station\", \"central\", \"luxurious\") k√∂nnen gezielt als **Keywords** in Titeln und in den ersten S√§tzen der Beschreibungen verwendet werden, um die **Auffindbarkeit in der Airbnb-Suche** zu verbessern.\n",
    "\n",
    "4. **Zielgruppenspezifische Ansprache entwickeln:**  \n",
    "   Unterschiedliche Themen sprechen unterschiedliche Zielgruppen an (z.‚ÄØB. \"ruhige Lage\" f√ºr Familien, \"schnelles WLAN\" f√ºr Gesch√§ftsreisende). Die Listings k√∂nnten daher **zielgruppenorientiert angepasst** werden, um verschiedene G√§stesegmente gezielt anzusprechen und die Conversion-Rate zu steigern.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
