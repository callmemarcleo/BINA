{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab07e6c4",
   "metadata": {},
   "source": [
    "# Datengetriebene Analyse zur Optimierung von Airbnb-Investitionen in Zürich für \"InvestZurich AG\"\n",
    "\n",
    "**Kontext:**\n",
    "Dieser Report wurden im Rahmen des MSc in Wirtschaftsinformatik (BFH-OST-HSLU-FFHS) im Zuge des BINA-Moduls (Business Intelligence & Business Analytics) im Frühlingssemester 2025 erstellt. Die Fallstudie wurde als Gruppenarbeit erarbeitet und stellt einen Teil des Modul-Kompetenznachweises dar.\n",
    "\n",
    "**Autoren:**\n",
    "- Bielmann Tobias (BFH)\n",
    "- Hösli Marc (BFH)\n",
    "- Künzli Joel (BFH)\n",
    "- Mühlemann Robin (BFH)\n",
    "- Sinzig Basil (BFH)\n",
    "\n",
    "**Datum:**\n",
    "2. Juni 2025\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "Die vorliegende Fallstudie untersucht den Airbnb-Markt der Stadt Zürich, zur Optimierung von Investitionsstrategien, für unsere hypothetische Investorenfirma \"InvestZurich AG\". In einem zunehmend wettbewerbsintensiven Umfeld für Kurzzeitvermietungen ist es für Investoren entscheidend, datengestützte Entscheidungen zu treffen, um die Rentabilität zu maximieren und Risiken zu minimieren.\n",
    "Dieses Projekt zielt darauf ab, die Prinzipien des DDDM und die im Modul BINA erlernten Analysemethoden (inkl. Descriptive Statistics, Regression, Classification, Clustering, Time Series Analysis und Datenvisualisierung) anzuwenden, um InvestZurich AG bei der Beantwortung zentraler Fragen in Bezug auf Marktpotenzial, Preisgestaltung, Wettbewerbsanalyse, Rentabilität und Risikomanagement in Zürich zu unterstützen.\n",
    "\n",
    "Die Vorgehensweise folgt dem von CPA Canada entwickelten Framework \"From Data to Decisions\", das datenbasierte Entscheidungsprozesse in fünf aufeinander aufbauenden Schritten strukturiert. In dieser Arbeit werden die Schritte 1 bis 4 adressiert:\n",
    "1. Defining objectives and information needs\n",
    "2. Collecting Data\n",
    "3. Analyzing Data\n",
    "4. Presenting Information\n",
    "\n",
    "Zu Beginn werden die strategischen Ziele der InvestZurich AG sowie die daraus abgeleiteten Informationsbedürfnisse definiert. Dabei geht es darum, die relevanten Fragestellungen zu identifizieren, die für Investitionsentscheidungen von zentraler Bedeutung sind, beispielsweise zur Standortattraktivität, zur Preisgestaltung oder zur erwarteten Auslastung. Nur wenn die Informationsbedarfe klar formuliert sind, kann die Analyse zielgerichtet erfolgen.\n",
    "\n",
    "Anschliessend liegt der Fokus auf die Erhebung, Auswahl und Aufbereitung geeigneter Datenquellen. Dazu zählen strukturierte Airbnb-Daten ebenso wie ergänzende Informationen zu Wohungspreisen in der Stadt Zürich. Die Daten werden bereinigt und so vorbereitet, dass eine valide und aussagekräftige Analyse möglich ist.\n",
    "\n",
    "Im dritten Schritt erfolgt die Auswertung mithilfe den im Modul BINA erlernten Analysemethoden. Ziel ist es, aus den Daten konkrete Muster, Zusammenhänge und Trends abzuleiten, die für die InvestZurich AG wirtschaftlich relevante Erkenntnisse liefern.\n",
    "\n",
    "Abschliessend werden die Analyseergebnisse zielgruppengerecht aufbereitet. Dabei stehen visuelle Elemente im Fokus, um zentrale Erkenntnisse klar und verständlich zu vermitteln. Auf dieser Grundlage werden konkrete, umsetzbare Handlungsmpfehlungen für die InvestZurich AG formuliert, die sie bei ihrer Entscheidungsfindung unterstützen sollen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241fc32",
   "metadata": {},
   "source": [
    "# Step 1: Defining Objectives and Information Needs\n",
    "\n",
    "Der erste Schritt des CPA-Frameworks \"From Data to Decisions\" besteht in der klaren Definition der strategischen Zielsetzungen sowie der daraus abgeleiteten Informationsbedarfe. Dieser Schritt bildet die Grundlage für alle folgenden Phasen der datengestützten Entscheidungsfindung. Eine präzise Formulierung der geschäftlichen Ziele sowie der damit verbundenen Informationsanforderungen ist entscheidend, um die Analyse strukturiert und zielgerichtet ausrichten zu können.\n",
    "\n",
    "Im Rahmen dieser Fallstudie steht die Optimierung von Investitionen im Airbnb-Markt der Stadt Zürich im Fokus. Für die fiktive Investorenfirma InvestZurich AG sollen auf Basis datengetriebener Analysen Entscheidungsgrundlagen erarbeitet werden, um Investitionsrisiken zu minimieren, Chancen systematisch zu identifizieren und die operative Performance der Vermietungsobjekte zu steigern. Die strategischen Ziele lassen sich in vier zentrale Themenfelder unterteilen.\n",
    "\n",
    "## Objective 1 – Marktpotenzial und Standortanalyse\n",
    "**Strategisches Ziel:** Identifikation besonders attraktiver Standorte für Airbnb-Investitionen in der Stadt Zürich.\n",
    "\n",
    "**Informationsbedarfe:**\n",
    "- Analyse der Nachfrage nach Kurzzeitvermietungen in den einzelnen Stadtquartieren.\n",
    "- Identifikation unterversorgter Wohnungstypen hinsichtlich Grösse oder Zimmeranzahl.\n",
    "- Vergleich von Auslastung und erzielbaren Preisen zwischen verschiedenen Quartieren.\n",
    "- Untersuchung relevanter sozioökonomischer und infrastruktureller Standortfaktoren.\n",
    "\n",
    "Ziel dieser Analysen ist es, fundierte Grundlagen für Standortentscheidungen zu schaffen und Quartiere mit überdurchschnittlichem Renditepotenzial zu priorisieren.\n",
    "\n",
    "## Objective 2 – Preisstrategie und Ertragsprognose\n",
    "**Strategisches Ziel:** Entwicklung evidenzbasierter Preisstrategien sowie realistischer Prognosen zu erzielbaren Einnahmen aus Airbnb-Vermietungen.\n",
    "\n",
    "**Informationsbedarfe:**\n",
    "- Ermittlung der wichtigsten Einflussfaktoren auf die Preisgestaltung im Zürcher Airbnb-Markt.\n",
    "- Analyse marktüblicher Preisspannen für verschiedene Objektarten und Standorte.\n",
    "- Identifikation saisonaler Schwankungen in Buchungszahlen und Preisniveaus.\n",
    "- Bewertung des Zusammenhangs zwischen Preis, Ausstattung, Aufenthaltsdauer und Auslastung.\n",
    "\n",
    "Diese Erkenntnisse unterstützen die wirtschaftliche Bewertung potenzieller Investitionsobjekte und ermöglichen die Feinjustierung der Preisgestaltung für maximale Auslastung und Ertrag.\n",
    "\n",
    "## Objective 3 – Performance Optimierung und Benchmarking\n",
    "**Strategisches Ziel:** Ableitung von Handlungsempfehlungen zur Verbesserung der operativen Performance basierend auf erfolgreichen Marktteilnehmern.\n",
    "\n",
    "**Informationsbedarfe:**\n",
    "- Analyse von Unterschieden zwischen besonders erfolgreichen Hosts (z.B. Superhosts) und durchschnittlichen Anbietern.\n",
    "- Identifikation von Merkmalen und Services, die die Gästezufriedenheit und Buchungsraten erhöhen.\n",
    "- Untersuchung der Bedeutung von Bewertungen, Reaktionsgeschwindigkeit und Mindestaufenthaltsdauer für die Performance.\n",
    "- Definition konkreter Massnahmen zur Erlangung und Aufrechterhaltung des Superhost-Status.\n",
    "\n",
    "Diese Informationen bilden die Basis für gezielte operative Verbesserungen und die Entwicklung eines professionellen, standardisierten Vermietungsansatzes.\n",
    "\n",
    "## Objective 4 – Listing-Optimierung durch Textanalyse\n",
    "**Strategisches Ziel:** Untersuchung des Einflusses der Beschreibungstexte auf das Buchungsverhalten und die Bewertung durch Gäste.\n",
    "\n",
    "**Informationsbedarf:**\n",
    "- Analyse sprachlicher Merkmale (Tonfall, Länge, Stilistik) in Listing-Beschreibungen.\n",
    "- Untersuchung semantischer Inhalte in Bezug auf Vertrauen, Exklusivität, Komfort etc.\n",
    "- Vergleich von Textmerkmalen zwischen hochfrequentierten und wenig gebuchten Objekten.\n",
    "- Ermittlung potenzieller Optimierungsansätze zur Verbesserung der Listings.\n",
    "\n",
    "Die Textanalyse soll Aufschluss darüber geben, ob bestimmte Formulierungen, Strukturen oder Emotionen in Beschreibungen einen messbaren Einfluss auf Buchungszahlen und Bewertungen haben. Ziel ist es, Empfehlungen für eine wirkungsvolle Kommunikation im digitalen Raum abzuleiten.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ad3b5",
   "metadata": {},
   "source": [
    "# Step 2: Collecting Data\n",
    "\n",
    "Die für diese Analyse verwendeten Datensätze wurden ursprünglich von [Inside Airbnb](http://insideairbnb.com/get-the-data/#Zurich) (Datenstand ca. 23. März 2025) und [Stadt Zürich Open Data](https://data.stadt-zuerich.ch/dataset/bau_hae_preis_stockwerkeigentum_zimmerzahl_stadtquartier_od5155) (Datenstand ca. 20. Januar 2025) bezogen.\n",
    "\n",
    "Diese Rohdaten wurden bereits in eine Supabase-Datenbank geladen und dort in den Tabellen `cleaned_listings` und `cleaned_selling_prices` zentral bereinigt und aufbereitet. Die Spaltennamen und Datentypen in diesen Supabase-Tabellen entsprechen den Definitionen der Dataclasses in `bina_models.py`.\n",
    "\n",
    "**In Supabase durchgeführte Aufbereitungsschritte umfassen:**\n",
    "* **Schema-Validierung und -Anpassung:** Sicherstellung, dass die Datenstruktur den `Listing`- und `SellingPrices`-Modellen entspricht\n",
    "* **Behandlung von Duplikaten.**\n",
    "* **Standardisierung von Formaten** `Datum`, `Boolean\n",
    "* **Parsing komplexer Felder** (Preis-Strings zu numerischen Werten, initiale Textverarbeitung). Für `amenities` wurde sichergestellt, dass es als Liste von Strings geladen wird. `bathrooms` wurde als numerischer Wert `float` etabliert\n",
    "* **Umgang mit fehlenden Werten (initial)**\n",
    "* **Typkonvertierungen** gemäss `bina_models.py`\n",
    "\n",
    "Für diese Analyse greifen wir über den benutzerdefinierten Python-Service `AirbnbAnalysisService` auf diese bereits in Supabase aufbereiteten Tabellen zu. In diesem Abschnitt wird genauer auf die oben genannten Schritte eingegangen.\n",
    "\n",
    "\n",
    "## Datenquellen und -beschaffung via Supabase für `Listings`\n",
    "\n",
    "### 1. Fehlende Werte identifizieren und einordnen / Zählen der fehlenden Werte pro Spalte für `listings`\n",
    "Um eine fundierte Grundlage für den weiteren Analyseprozess zu schaffen, ist es essenziell, zunächst das Ausmass fehlender Werte im Datensatz zu quantifizieren. Die Identifikation von Spalten mit fehlenden Werten ermöglicht es, potenzielle Datenqualitätsprobleme frühzeitig zu erkennen und geeignete Massnahmen zur Datenbereinigung abzuleiten.\n",
    "Ziel ist es zu verstehen, wo welche Spalten fehlende Werte `NULLs` enthalten und was das für die spätere Analyse bedeutet.\n",
    "\n",
    "**SQL Query:**\n",
    "```sql\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  SUM(CASE WHEN id IS NULL THEN 1 ELSE 0 END) AS null_id,\n",
    "  SUM(CASE WHEN listing_url IS NULL THEN 1 ELSE 0 END) AS null_listing_url,\n",
    "  SUM(CASE WHEN scrape_id IS NULL THEN 1 ELSE 0 END) AS null_scrape_id,\n",
    "  SUM(CASE WHEN last_scraped IS NULL THEN 1 ELSE 0 END) AS null_last_scraped,\n",
    "  SUM(CASE WHEN source IS NULL THEN 1 ELSE 0 END) AS null_source,\n",
    "  SUM(CASE WHEN name IS NULL THEN 1 ELSE 0 END) AS null_name,\n",
    "  SUM(CASE WHEN description IS NULL THEN 1 ELSE 0 END) AS null_description,\n",
    "  SUM(CASE WHEN neighborhood_overview IS NULL THEN 1 ELSE 0 END) AS null_neighborhood_overview,\n",
    "  SUM(CASE WHEN picture_url IS NULL THEN 1 ELSE 0 END) AS null_picture_url,\n",
    "  SUM(CASE WHEN host_id IS NULL THEN 1 ELSE 0 END) AS null_host_id,\n",
    "  SUM(CASE WHEN host_url IS NULL THEN 1 ELSE 0 END) AS null_host_url,\n",
    "  SUM(CASE WHEN host_name IS NULL THEN 1 ELSE 0 END) AS null_host_name,\n",
    "  SUM(CASE WHEN host_since IS NULL THEN 1 ELSE 0 END) AS null_host_since,\n",
    "  SUM(CASE WHEN host_location IS NULL THEN 1 ELSE 0 END) AS null_host_location,\n",
    "  SUM(CASE WHEN host_about IS NULL THEN 1 ELSE 0 END) AS null_host_about,\n",
    "  SUM(CASE WHEN host_response_time IS NULL THEN 1 ELSE 0 END) AS null_host_response_time,\n",
    "  SUM(CASE WHEN host_response_rate IS NULL THEN 1 ELSE 0 END) AS null_host_response_rate,\n",
    "  SUM(CASE WHEN host_acceptance_rate IS NULL THEN 1 ELSE 0 END) AS null_host_acceptance_rate,\n",
    "  SUM(CASE WHEN host_is_superhost IS NULL THEN 1 ELSE 0 END) AS null_host_is_superhost,\n",
    "  SUM(CASE WHEN host_thumbnail_url IS NULL THEN 1 ELSE 0 END) AS null_host_thumbnail_url,\n",
    "  SUM(CASE WHEN host_picture_url IS NULL THEN 1 ELSE 0 END) AS null_host_picture_url,\n",
    "  SUM(CASE WHEN host_neighbourhood IS NULL THEN 1 ELSE 0 END) AS null_host_neighbourhood,\n",
    "  SUM(CASE WHEN host_listings_count IS NULL THEN 1 ELSE 0 END) AS null_host_listings_count,\n",
    "  SUM(CASE WHEN host_total_listings_count IS NULL THEN 1 ELSE 0 END) AS null_host_total_listings_count,\n",
    "  SUM(CASE WHEN host_verifications IS NULL THEN 1 ELSE 0 END) AS null_host_verifications,\n",
    "  SUM(CASE WHEN host_has_profile_pic IS NULL THEN 1 ELSE 0 END) AS null_host_has_profile_pic,\n",
    "  SUM(CASE WHEN host_identity_verified IS NULL THEN 1 ELSE 0 END) AS null_host_identity_verified,\n",
    "  SUM(CASE WHEN neighbourhood IS NULL THEN 1 ELSE 0 END) AS null_neighbourhood,\n",
    "  SUM(CASE WHEN neighbourhood_cleansed IS NULL THEN 1 ELSE 0 END) AS null_neighbourhood_cleansed,\n",
    "  SUM(CASE WHEN neighbourhood_group_cleansed IS NULL THEN 1 ELSE 0 END) AS null_neighbourhood_group_cleansed,\n",
    "  SUM(CASE WHEN latitude IS NULL THEN 1 ELSE 0 END) AS null_latitude,\n",
    "  SUM(CASE WHEN longitude IS NULL THEN 1 ELSE 0 END) AS null_longitude,\n",
    "  SUM(CASE WHEN property_type IS NULL THEN 1 ELSE 0 END) AS null_property_type,\n",
    "  SUM(CASE WHEN room_type IS NULL THEN 1 ELSE 0 END) AS null_room_type,\n",
    "  SUM(CASE WHEN accommodates IS NULL THEN 1 ELSE 0 END) AS null_accommodates,\n",
    "  SUM(CASE WHEN bathrooms IS NULL THEN 1 ELSE 0 END) AS null_bathrooms,\n",
    "  SUM(CASE WHEN bathrooms_text IS NULL THEN 1 ELSE 0 END) AS null_bathrooms_text,\n",
    "  SUM(CASE WHEN bedrooms IS NULL THEN 1 ELSE 0 END) AS null_bedrooms,\n",
    "  SUM(CASE WHEN beds IS NULL THEN 1 ELSE 0 END) AS null_beds,\n",
    "  SUM(CASE WHEN amenities IS NULL THEN 1 ELSE 0 END) AS null_amenities,\n",
    "  SUM(CASE WHEN price IS NULL THEN 1 ELSE 0 END) AS null_price,\n",
    "  SUM(CASE WHEN minimum_nights IS NULL THEN 1 ELSE 0 END) AS null_minimum_nights,\n",
    "  SUM(CASE WHEN maximum_nights IS NULL THEN 1 ELSE 0 END) AS null_maximum_nights,\n",
    "  SUM(CASE WHEN minimum_minimum_nights IS NULL THEN 1 ELSE 0 END) AS null_minimum_minimum_nights,\n",
    "  SUM(CASE WHEN maximum_minimum_nights IS NULL THEN 1 ELSE 0 END) AS null_maximum_minimum_nights,\n",
    "  SUM(CASE WHEN minimum_maximum_nights IS NULL THEN 1 ELSE 0 END) AS null_minimum_maximum_nights,\n",
    "  SUM(CASE WHEN maximum_maximum_nights IS NULL THEN 1 ELSE 0 END) AS null_maximum_maximum_nights,\n",
    "  SUM(CASE WHEN minimum_nights_avg_ntm IS NULL THEN 1 ELSE 0 END) AS null_minimum_nights_avg_ntm,\n",
    "  SUM(CASE WHEN maximum_nights_avg_ntm IS NULL THEN 1 ELSE 0 END) AS null_maximum_nights_avg_ntm,\n",
    "  SUM(CASE WHEN calendar_updated IS NULL THEN 1 ELSE 0 END) AS null_calendar_updated,\n",
    "  SUM(CASE WHEN has_availability IS NULL THEN 1 ELSE 0 END) AS null_has_availability,\n",
    "  SUM(CASE WHEN availability_30 IS NULL THEN 1 ELSE 0 END) AS null_availability_30,\n",
    "  SUM(CASE WHEN availability_60 IS NULL THEN 1 ELSE 0 END) AS null_availability_60,\n",
    "  SUM(CASE WHEN availability_90 IS NULL THEN 1 ELSE 0 END) AS null_availability_90,\n",
    "  SUM(CASE WHEN availability_365 IS NULL THEN 1 ELSE 0 END) AS null_availability_365,\n",
    "  SUM(CASE WHEN calendar_last_scraped IS NULL THEN 1 ELSE 0 END) AS null_calendar_last_scraped,\n",
    "  SUM(CASE WHEN number_of_reviews IS NULL THEN 1 ELSE 0 END) AS null_number_of_reviews,\n",
    "  SUM(CASE WHEN number_of_reviews_ltm IS NULL THEN 1 ELSE 0 END) AS null_number_of_reviews_ltm,\n",
    "  SUM(CASE WHEN number_of_reviews_l30d IS NULL THEN 1 ELSE 0 END) AS null_number_of_reviews_l30d,\n",
    "  SUM(CASE WHEN first_review IS NULL THEN 1 ELSE 0 END) AS null_first_review,\n",
    "  SUM(CASE WHEN last_review IS NULL THEN 1 ELSE 0 END) AS null_last_review,\n",
    "  SUM(CASE WHEN review_scores_rating IS NULL THEN 1 ELSE 0 END) AS null_review_scores_rating,\n",
    "  SUM(CASE WHEN review_scores_accuracy IS NULL THEN 1 ELSE 0 END) AS null_review_scores_accuracy,\n",
    "  SUM(CASE WHEN review_scores_cleanliness IS NULL THEN 1 ELSE 0 END) AS null_review_scores_cleanliness,\n",
    "  SUM(CASE WHEN review_scores_checkin IS NULL THEN 1 ELSE 0 END) AS null_review_scores_checkin,\n",
    "  SUM(CASE WHEN review_scores_communication IS NULL THEN 1 ELSE 0 END) AS null_review_scores_communication,\n",
    "  SUM(CASE WHEN review_scores_location IS NULL THEN 1 ELSE 0 END) AS null_review_scores_location,\n",
    "  SUM(CASE WHEN review_scores_value IS NULL THEN 1 ELSE 0 END) AS null_review_scores_value,\n",
    "  SUM(CASE WHEN license IS NULL THEN 1 ELSE 0 END) AS null_license,\n",
    "  SUM(CASE WHEN instant_bookable IS NULL THEN 1 ELSE 0 END) AS null_instant_bookable,\n",
    "  SUM(CASE WHEN calculated_host_listings_count IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count,\n",
    "  SUM(CASE WHEN calculated_host_listings_count_entire_homes IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count_entire_homes,\n",
    "  SUM(CASE WHEN calculated_host_listings_count_private_rooms IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count_private_rooms,\n",
    "  SUM(CASE WHEN calculated_host_listings_count_shared_rooms IS NULL THEN 1 ELSE 0 END) AS null_calculated_host_listings_count_shared_rooms,\n",
    "  SUM(CASE WHEN reviews_per_month IS NULL THEN 1 ELSE 0 END) AS null_reviews_per_month\n",
    "FROM listings;\n",
    "```\n",
    "Die Berechnung der Anzahl sowie des prozentualen Anteils fehlender Werte pro Spalte bietet eine klare Übersicht darüber, welche Merkmale besonders betroffen sind. \n",
    "Auf dieser Basis können fundierte Entscheidungen hinsichtlich Imputation, Löschung oder anderer Strategien zur Behandlung fehlender Daten getroffen werden.\n",
    "\n",
    "### 2. Kategorisierung der Spalten nach Analyse-Relevanz für `listings`\n",
    "Ein zentraler Schritt bei der Behandlung fehlender Werte besteht darin, die betroffenen Spalten hinsichtlich ihrer Bedeutung für die Analyse zu kategorisieren.\n",
    "Diese Einordnung ermöglicht eine systematische Ableitung geeigneter Massnahmen im Umgang mit fehlenden Daten.\n",
    "Im Folgenden wird eine beispielhafte Kategorisierung vorgenommen:\n",
    "\n",
    "| Kategorie                                               | Beispielhafte Spalten                                                           | Empfohlener Umgang mit fehlenden Werten               |\n",
    "| ------------------------------------------------------- | -------------------------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "| 🟥 **Kritisch (essenzielle Kerninformationen)**          | `id`, `price`, `latitude`, `longitude`, `room_type`, `accommodates`             | Zeilen mit fehlenden Werten sollten entfernt werden.  |\n",
    "| 🟧 **Relevant für Analysen (wünschenswert vollständig)** | `beds`, `bedrooms`, `review_scores_*`, `availability_365`, `reviews_per_month`  | Fehlende Werte sollten durch Imputation oder Flags behandelt werden. |\n",
    "| 🟨 **Optional / rein informativ / technische Informationen**                        | `host_about`, `description`, `host_thumbnail_url`                               | Fehlende Werte können in der Regel ignoriert werden.  |\n",
    "\n",
    "Die Zuordnung erfolgt kontextabhängig, basierend auf der Zielsetzung der Analyse. \n",
    "Kritische Spalten sind für grundlegende Berechnungen unerlässlich und dürfen keine Lücken enthalten, während bei optionalen oder technischen Feldern eine höhere Toleranz gegenüber fehlenden Werten besteht.\n",
    "\n",
    "### 3. Zentrale Leitfragen zur Bewertung fehlender Werte für `listings`\n",
    "Bei der Bewertung fehlender Werte sollten bestimmte Leitfragen berücksichtigt werden, um fundierte Entscheidungen über den weiteren Umgang mit den Daten treffen zu können. Diese Fragen helfen, zwischen tolerierbaren und problematischen Ausprägungen zu unterscheiden:\n",
    "\n",
    "- **Wie viele Einträge sind betroffen?**\n",
    "  Ein hoher Anteil fehlender Werte (z. B. mehr als 30 %) kann die Aussagekraft einer Spalte erheblich beeinträchtigen und sollte als kritisch bewertet werden.\n",
    "- **Wird die Spalte später für Berechnungen oder Modellierung verwendet?**\n",
    "  Fehlt ein Wert in einem für mathematische Operationen relevanten Feld, kann dies zu Verzerrungen oder Fehlern führen.\n",
    "- **Kann der fehlende Wert sinnvoll ersetzt werden?**\n",
    "  In manchen Fällen ist eine Imputation möglich, z. B. durch Verwendung des Mittelwerts, Medians oder eines Platzhalterwertes wie \"unknown\".\n",
    "- **Trägt das Fehlen des Wertes eine eigene Information?**\n",
    "  Ein `NULL`-Wert kann unter Umständen auch eine inhaltliche Bedeutung haben, z. B. dass ein Gast keine Bewertung abgegeben hat. In solchen Fällen kann es sinnvoll sein, den fehlenden Wert explizit als \"nicht vorhanden\" zu interpretieren.\n",
    "\n",
    "Diese Überlegungen unterstützen eine datengetriebene und analytisch begründete Entscheidungsfindung im Umgang mit fehlenden Werten.\n",
    "\n",
    "### 4. Kategorisierung aller Spalten nach Relevanz für `listings`\n",
    "Zur systematischen Behandlung fehlender Werte und zur Priorisierung von Datenbereinigungsschritten wurden alle Spalten des Datensatzes in drei Kategorien eingeteilt. Die Einordnung basiert auf ihrer analytischen Relevanz, insbesondere im Hinblick auf Zielgrössen wie die Berechnung der Rentabilität (ROI), räumliche Analysen (z. B. Heatmaps) sowie die Bewertung von Angebotsqualität und Nutzerverhalten.\n",
    "\n",
    "| Kategorie                             | Spaltennamen                                                                                                          | Begründung |\n",
    "|--------------------------------------|-----------------------------------------------------------------------------------------------------------------------|------------|\n",
    "| 🟥 **High Impact (essentiell)**       | `id`, `latitude`, `longitude`, `price`, `room_type`, `accommodates`, `neighbourhood_cleansed`, `availability_365`, `number_of_reviews`, `reviews_per_month`, `review_scores_rating` | Diese Spalten sind zentral für Kernanalysen wie ROI-Berechnung, geografische Visualisierungen (z. B. Heatmaps) und zur Beurteilung der Angebotsqualität. Fehlende Werte führen zu erheblichen Einschränkungen der Aussagekraft. |\n",
    "| 🟧 **Medium Impact (nützlich, aber nicht kritisch)** | `bathrooms`, `bedrooms`, `beds`, `host_id`, `host_listings_count`, `host_total_listings_count`, `property_type`, `review_scores_*`, `first_review`, `last_review`, `instant_bookable`, `calculated_host_listings_count_*`, `number_of_reviews_ltm`, `number_of_reviews_l30d`, `has_availability`, `minimum_nights`, `maximum_nights`, `amenities` | Diese Merkmale ergänzen die Analysen sinnvoll und tragen zur Erklärung von Erfolgsfaktoren bei (z. B. welche Eigenschaften machen ein Listing attraktiv oder profitabel). Fehlende Werte sind tolerierbar, sollten aber möglichst behandelt werden. |\n",
    "| 🟨 **Low Impact (optional oder informativ)** | `listing_url`, `scrape_id`, `last_scraped`, `source`, `name`, `description`, `neighborhood_overview`, `picture_url`, `host_url`, `host_name`, `host_since`, `host_location`, `host_about`, `host_response_time`, `host_response_rate`, `host_acceptance_rate`, `host_is_superhost`, `host_thumbnail_url`, `host_picture_url`, `host_neighbourhood`, `host_verifications`, `host_has_profile_pic`, `host_identity_verified`, `neighbourhood`, `neighbourhood_group_cleansed`, `bathrooms_text`, `calendar_updated`, `calendar_last_scraped`, `license`, `minimum_minimum_nights`, `maximum_minimum_nights`, `minimum_maximum_nights`, `maximum_maximum_nights`, `minimum_nights_avg_ntm`, `maximum_nights_avg_ntm` | Diese Spalten enthalten vorwiegend Metadaten, beschreibende Texte, Bilder oder technische Informationen. Sie sind für Business-Intelligence-Analysen oder geografische Auswertungen nur bedingt relevant, können aber im Rahmen von UI-Design, Vollständigkeitsprüfungen oder NLP-Analysen von Interesse sein. |\n",
    "\n",
    "Die vorliegende Klassifizierung stellt eine arbeitsorientierte Grundlage für alle weiteren Entscheidungen zur Datenvorverarbeitung dar.\n",
    "\n",
    "### 5. Bereinigung kritischer Felder und Markierung unvollständiger Einträge (Flagging) für `listings`\n",
    "Im Rahmen der Datenbereinigung wurde eine zweistufige Strategie verfolgt, um mit fehlenden Werten umzugehen. Zunächst wurden alle Datensätze entfernt, die in den als *High Impact* klassifizierten Spalten fehlende Werte aufwiesen. Diese Spalten sind für zentrale Analysen wie Rentabilitätsberechnungen, geografische Auswertungen und die allgemeine Bewertung der Angebotsqualität unerlässlich. Fehlende Werte in diesen Feldern würden die Aussagekraft der Analysen massiv beeinträchtigen.\n",
    "\n",
    "Im Gegensatz dazu wurde bei den als *Medium Impact* eingestuften Spalten auf das Löschen von Zeilen verzichtet. Stattdessen wurde ein **Flagging-Mechanismus** eingeführt: Für jede Zeile wurde ein boolesches Flag (`missing_data_flag`) gesetzt, das anzeigt, ob in mindestens einem dieser mittleren Felder ein Wert fehlt. Dieses Vorgehen ermöglicht es, die Informationen zu fehlenden Werten zu einem späteren Zeitpunkt gezielt wiederzuverwenden – etwa zur Modellbewertung, Filterung oder bei der Entwicklung von Imputationsstrategien.\n",
    "\n",
    "Die folgende SQL-Abfrage implementiert beide Schritte:\n",
    "```sql\n",
    "CREATE TABLE cleaned_listings AS\n",
    "SELECT *,\n",
    "  -- Setze Flag für Medium Impact Spalten mit fehlenden Werten\n",
    "  CASE\n",
    "    WHEN\n",
    "      bathrooms IS NULL OR\n",
    "      bedrooms IS NULL OR\n",
    "      beds IS NULL OR\n",
    "      host_id IS NULL OR\n",
    "      host_listings_count IS NULL OR\n",
    "      host_total_listings_count IS NULL OR\n",
    "      property_type IS NULL OR\n",
    "      review_scores_accuracy IS NULL OR\n",
    "      review_scores_cleanliness IS NULL OR\n",
    "      review_scores_checkin IS NULL OR\n",
    "      review_scores_communication IS NULL OR\n",
    "      review_scores_location IS NULL OR\n",
    "      review_scores_value IS NULL OR\n",
    "      first_review IS NULL OR\n",
    "      last_review IS NULL OR\n",
    "      instant_bookable IS NULL OR\n",
    "      calculated_host_listings_count IS NULL OR\n",
    "      calculated_host_listings_count_entire_homes IS NULL OR\n",
    "      calculated_host_listings_count_private_rooms IS NULL OR\n",
    "      calculated_host_listings_count_shared_rooms IS NULL OR\n",
    "      number_of_reviews_ltm IS NULL OR\n",
    "      number_of_reviews_l30d IS NULL OR\n",
    "      has_availability IS NULL OR\n",
    "      minimum_nights IS NULL OR\n",
    "      maximum_nights IS NULL OR\n",
    "      amenities IS NULL\n",
    "    THEN TRUE\n",
    "    ELSE FALSE\n",
    "  END AS missing_data_flag\n",
    "\n",
    "FROM listings\n",
    "-- High Impact: Zeilen löschen, wenn diese Spalten NULL sind\n",
    "WHERE \n",
    "  id IS NOT NULL AND\n",
    "  latitude IS NOT NULL AND\n",
    "  longitude IS NOT NULL AND\n",
    "  price IS NOT NULL AND\n",
    "  room_type IS NOT NULL AND\n",
    "  accommodates IS NOT NULL AND\n",
    "  neighbourhood_cleansed IS NOT NULL AND\n",
    "  availability_365 IS NOT NULL AND\n",
    "  number_of_reviews IS NOT NULL AND\n",
    "  reviews_per_month IS NOT NULL AND\n",
    "  review_scores_rating IS NOT NULL;\n",
    "```\n",
    "Mit dieser Vorgehensweise ist sichergestellt, dass alle für die Kernanalysen relevanten Spalten vollständig vorliegen, während gleichzeitig potenziell informative Lücken in weniger zentralen Spalten nicht verloren gehen, sondern gezielt gekennzeichnet werden.\n",
    "\n",
    "### 6. Auswertung des `missing_data_flag` udn Analyse der unvollständigen Datensätze für `listings`\n",
    "Nach der Bereinigung der *High Impact*-Spalten wurde ein Flag (`missing_data_flag`) eingeführt, das anzeigt, ob ein Datensatz in einer oder mehreren *Medium Impact*-Spalten fehlende Werte enthält. Um den Umfang des verbleibenden Datenqualitätsproblems besser einschätzen zu können, wurde eine erste Auswertung dieses Flags vorgenommen.\n",
    "\n",
    "**Die Auswertung beantwortet unter anderem folgende Fragen:**\n",
    "- Wie viele Datensätze enthalten noch fehlende Werte in *Medium Impact*-Feldern?\n",
    "- Wie gross ist ihr Anteil am Gesamtbestand?\n",
    "- Welche strategischen Optionen ergeben sich daraus (z. B. Imputation, gezielter Ausschluss)?\n",
    "\n",
    "**In SQL:**\n",
    "```sql\n",
    "-- Zähle, wie viele Zeilen fehlende Werte in Medium Impact Feldern haben\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  SUM(CASE WHEN missing_data_flag = TRUE THEN 1 ELSE 0 END) AS rows_with_missing,\n",
    "  ROUND(100.0 * SUM(CASE WHEN missing_data_flag = TRUE THEN 1 ELSE 0 END) / COUNT(*), 2) AS percent_with_missing\n",
    "FROM cleaned_listings;\n",
    "```\n",
    "Diese Kennzahlen bieten eine Grundlage für datenbasierte Entscheidungen im weiteren Verlauf der Analyse. Beispielsweise kann entschieden werden, ob die betroffenen Zeilen durch geeignete Verfahren ergänzt (Imputation) oder selektiv ausgeschlossen werden sollen.\n",
    "\n",
    "### 7. Finalisierung und Typisierung der Tabelle `cleaned_listings`\n",
    "Nach der ersten Bereinigung des Datensatzes und dem Setzen eines Flags für unvollständige *Medium Impact*-Spalten wurde die Tabelle `cleaned_listings` final strukturiert. Ziel war es, eine konsolidierte und konsistente Datenbasis zu schaffen, mit der im weiteren Analyseprozess effizient und ohne zusätzliche Nachbearbeitung gearbeitet werden kann.\n",
    "\n",
    "**Vorgehen:**\n",
    "1. Zunächst wurde eine Sicherungskopie der bereinigten Tabelle erstellt.\n",
    "2. Anschliessend wurde die ursprüngliche Version entfernt.\n",
    "3. Eine neue, typisierte Tabelle `cleaned_listings` wurde auf Basis des bisherigen Inhalts erstellt.\n",
    "\n",
    "Besonderes Augenmerk lag dabei auf der **Daten-Typisierung**, um typische Inkonsistenzen – wie zum Beispiel Prozentangaben im Textformat (\"95%\") – direkt im SQL-Prozess zu bereinigen. Dadurch konnte eine nachgelagerte Datenreinigung in Python vermieden werden.\n",
    "\n",
    "Zudem wurden gezielte **inhaltliche Korrekturen** vorgenommen, etwa das Auffüllen fehlender Werte im Feld `neighbourhood` mit dem Standardwert \"Zürich\". \n",
    "\n",
    "Die finale Struktur der Tabelle ist in folgender SQL-Definition abgebildet:\n",
    "```sql\n",
    "CREATE TABLE cleaned_listings (\n",
    "  id NUMERIC,\n",
    "  listing_url TEXT,\n",
    "  scrape_id NUMERIC,\n",
    "  last_scraped DATE,\n",
    "  source TEXT,\n",
    "  name TEXT,\n",
    "  description TEXT,\n",
    "  neighborhood_overview TEXT,\n",
    "  picture_url TEXT,\n",
    "  host_id INT,\n",
    "  host_url TEXT,\n",
    "  host_name TEXT,\n",
    "  host_since DATE,\n",
    "  host_location TEXT,\n",
    "  host_about TEXT,\n",
    "  host_response_time TEXT,\n",
    "  host_response_rate TEXT,\n",
    "  host_acceptance_rate INT,\n",
    "  host_is_superhost BOOLEAN,\n",
    "  host_thumbnail_url TEXT,\n",
    "  host_picture_url TEXT,\n",
    "  host_listings_count INT,\n",
    "  host_total_listings_count INT,\n",
    "  host_verifications TEXT,\n",
    "  host_has_profile_pic BOOLEAN,\n",
    "  host_identity_verified BOOLEAN,\n",
    "  neighbourhood TEXT,\n",
    "  neighbourhood_cleansed TEXT,\n",
    "  neighbourhood_group_cleansed TEXT,\n",
    "  latitude FLOAT,\n",
    "  longitude FLOAT,\n",
    "  property_type TEXT,\n",
    "  room_type TEXT,\n",
    "  accommodates INT,\n",
    "  bathrooms FLOAT,\n",
    "  bedrooms FLOAT,\n",
    "  beds FLOAT,\n",
    "  amenities JSONB,\n",
    "  price FLOAT,\n",
    "  minimum_nights INT,\n",
    "  maximum_nights INT,\n",
    "  minimum_minimum_nights INT,\n",
    "  maximum_minimum_nights INT,\n",
    "  minimum_maximum_nights INT,\n",
    "  maximum_maximum_nights INT,\n",
    "  minimum_nights_avg_ntm FLOAT,\n",
    "  maximum_nights_avg_ntm FLOAT,\n",
    "  has_availability BOOLEAN,\n",
    "  availability_30 INT,\n",
    "  availability_60 INT,\n",
    "  availability_90 INT,\n",
    "  availability_365 INT,\n",
    "  calendar_last_scraped DATE,\n",
    "  number_of_reviews INT,\n",
    "  number_of_reviews_ltm INT,\n",
    "  number_of_reviews_l30d INT,\n",
    "  first_review DATE,\n",
    "  last_review DATE,\n",
    "  review_scores_rating FLOAT,\n",
    "  review_scores_accuracy FLOAT,\n",
    "  review_scores_cleanliness FLOAT,\n",
    "  review_scores_checkin FLOAT,\n",
    "  review_scores_communication FLOAT,\n",
    "  review_scores_location FLOAT,\n",
    "  review_scores_value FLOAT,\n",
    "  instant_bookable BOOLEAN,\n",
    "  calculated_host_listings_count INT,\n",
    "  calculated_host_listings_count_entire_homes INT,\n",
    "  calculated_host_listings_count_private_rooms INT,\n",
    "  reviews_per_month FLOAT,\n",
    "  missing_data_flag BOOLEAN\n",
    ");\n",
    "```\n",
    "Mit dieser finalen Struktur stehen nun bereinigte, konsistent typisierte und vollständig analysierbare Daten zur Verfügung für alle nachfolgenden Analysen und Modellierungen.\n",
    "\n",
    "### 8. Finaler Datenimport, Typkonvertierung und strukturierte Bereinigung in `cleaned_listings`\n",
    "Nach mehreren Wochen aktiver Analyse durch die Gruppenmitglieder konnten die tatsächliche Relevanz und der Nutzungszweck vieler *Medium* und *Low Impact*-Felder deutlich besser eingeschätzt werden. Auf dieser Grundlage wurde beschlossen, die bestehende `cleaned_listings`-Tabelle final zu überarbeiten und dabei eine umfassende Typkonvertierung sowie gezielte Bereinigungen durchzuführen.\n",
    "\n",
    "Ziel dieses Schritts war es, die noch enthaltenen inkonsistenten oder fehleranfälligen Werteformate (z. B. `\"N/A\"`, Prozentzeichen, Währungszeichen) systematisch zu bereinigen und in ein robustes Datenmodell zu überführen, das für analytische und statistische Auswertungen direkt einsetzbar ist – ohne zusätzliche Nachbearbeitung in Python oder anderen Tools.\n",
    "\n",
    "**Beispiele für durchgeführte Konvertierungen:**\n",
    "- Textuelle Platzhalter wie `\"N/A\"` wurden in `NULL` umgewandelt.\n",
    "- Prozentwerte wie `\"95%\"` wurden bereinigt und als numerische Werte `95` gespeichert.\n",
    "- Währungsangaben wie `\"$123.00\"` wurden durch Entfernen von Sonderzeichen in numerische Gleitkommazahlen `FLOAT` überführt.\n",
    "- Wahrheitswerte wie `\"t\"` / `\"f\"` wurden als `BOOLEAN` gespeichert.\n",
    "- JSON-Textfelder `amenities` wurden korrekt in das Datentypformat `JSONB` überführt.\n",
    "\n",
    "**Das folgende SQL-Statement zeigt die konkrete Umsetzung:**\n",
    "```sql\n",
    "INSERT INTO cleaned_listings (\n",
    "  id, listing_url, scrape_id, last_scraped, source, name, description,\n",
    "  neighborhood_overview, picture_url, host_id, host_url, host_name, host_since,\n",
    "  host_location, host_about, host_response_time, host_response_rate,\n",
    "  host_acceptance_rate, host_is_superhost, host_thumbnail_url, host_picture_url,\n",
    "  host_listings_count, host_total_listings_count, host_verifications,\n",
    "  host_has_profile_pic, host_identity_verified, neighbourhood, \n",
    "  neighbourhood_cleansed, neighbourhood_group_cleansed, latitude, longitude,\n",
    "  property_type, room_type, accommodates, bathrooms, bedrooms, beds, amenities,\n",
    "  price, minimum_nights, maximum_nights, minimum_minimum_nights,\n",
    "  maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights,\n",
    "  minimum_nights_avg_ntm, maximum_nights_avg_ntm, has_availability,\n",
    "  availability_30, availability_60, availability_90, availability_365,\n",
    "  calendar_last_scraped, number_of_reviews, number_of_reviews_ltm,\n",
    "  number_of_reviews_l30d, first_review, last_review, review_scores_rating,\n",
    "  review_scores_accuracy, review_scores_cleanliness, review_scores_checkin,\n",
    "  review_scores_communication, review_scores_location, review_scores_value,\n",
    "  instant_bookable, calculated_host_listings_count,\n",
    "  calculated_host_listings_count_entire_homes,\n",
    "  calculated_host_listings_count_private_rooms, reviews_per_month,\n",
    "  missing_data_flag\n",
    ")\n",
    "SELECT\n",
    "  NULLIF(id::TEXT, 'N/A')::NUMERIC,\n",
    "  listing_url,\n",
    "  NULLIF(scrape_id::TEXT, 'N/A')::NUMERIC,\n",
    "  NULLIF(last_scraped::TEXT, 'N/A')::DATE,\n",
    "  source,\n",
    "  name,\n",
    "  description,\n",
    "  neighborhood_overview,\n",
    "  picture_url,\n",
    "  NULLIF(host_id::TEXT, 'N/A')::NUMERIC,\n",
    "  host_url,\n",
    "  host_name,\n",
    "  NULLIF(host_since::TEXT, 'N/A')::DATE,\n",
    "  host_location,\n",
    "  host_about,\n",
    "  host_response_time,\n",
    "  host_response_rate,\n",
    "  NULLIF(REPLACE(host_acceptance_rate::TEXT, '%', ''), 'N/A')::BIGINT,\n",
    "  host_is_superhost = 't',\n",
    "  host_thumbnail_url,\n",
    "  host_picture_url,\n",
    "  NULLIF(host_listings_count::TEXT, 'N/A')::NUMERIC,\n",
    "  NULLIF(host_total_listings_count::TEXT, 'N/A')::NUMERIC,\n",
    "  host_verifications,\n",
    "  host_has_profile_pic = 't',\n",
    "  host_identity_verified = 't',\n",
    "  neighbourhood,\n",
    "  neighbourhood_cleansed,\n",
    "  neighbourhood_group_cleansed,\n",
    "  NULLIF(latitude::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(longitude::TEXT, 'N/A')::FLOAT,\n",
    "  property_type,\n",
    "  room_type,\n",
    "  NULLIF(accommodates::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(bathrooms::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(bedrooms::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(beds::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(amenities::TEXT, 'N/A')::JSONB,\n",
    "  NULLIF(REPLACE(REPLACE(\"price\", ',', ''), '$', '')::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(minimum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(maximum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(minimum_minimum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(maximum_minimum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(minimum_maximum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(maximum_maximum_nights::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(minimum_nights_avg_ntm::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(maximum_nights_avg_ntm::TEXT, 'N/A')::FLOAT,\n",
    "  has_availability = 't',\n",
    "  NULLIF(availability_30::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(availability_60::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(availability_90::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(availability_365::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(calendar_last_scraped::TEXT, 'N/A')::DATE,\n",
    "  NULLIF(number_of_reviews::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(number_of_reviews_ltm::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(number_of_reviews_l30d::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(first_review::TEXT, 'N/A')::DATE,\n",
    "  NULLIF(last_review::TEXT, 'N/A')::DATE,\n",
    "  NULLIF(review_scores_rating::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_accuracy::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_cleanliness::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_checkin::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_communication::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_location::TEXT, 'N/A')::FLOAT,\n",
    "  NULLIF(review_scores_value::TEXT, 'N/A')::FLOAT,\n",
    "  instant_bookable = 't',\n",
    "  NULLIF(calculated_host_listings_count::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(calculated_host_listings_count_entire_homes::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(calculated_host_listings_count_private_rooms::TEXT, 'N/A')::BIGINT,\n",
    "  NULLIF(reviews_per_month::TEXT, 'N/A')::FLOAT,\n",
    "  missing_data_flag\n",
    "FROM cleaned_listings_backup_14_05_2025;\n",
    "```\n",
    "Diese finale Version der Tabelle cleaned_listings bildet den Ausgangspunkt für alle weiterführenden Analysen und Modelle. \n",
    "Sie stellt sicher, dass sämtliche strukturellen Inkonsistenzen beseitigt wurden und bietet ein hohes Mass an Datenqualität, Nachvollziehbarkeit und Robustheit.\n",
    "\n",
    "\n",
    "## Datenquellen und -beschaffung via Supabase für `SellingPrices`\n",
    "\n",
    "Die Dataclass `SellingPrices` wurde als Ergänzung bei der Ausarbeitung der Objectives erstellt und mit Daten zu *Verkaufspreise (Median) pro Wohnung und pro Quadratmeter Wohnungsfläche im Stockwerkeigentum, nach Zimmerzahl und Quartier* der [Stadt Zürich Open Data](https://data.stadt-zuerich.ch/dataset/bau_hae_preis_stockwerkeigentum_zimmerzahl_stadtquartier_od5155) befüllt.\n",
    "\n",
    "Die Tabelle `selling_prices`ist nicht so reich an Attributen wie die `listings` Tabelle von Airbnb. Desweiteren benötigten wir fast nur die Preise, weshalb die meisten Attribute dieser Tabelle ignoriert werden konnten.\n",
    "\n",
    "In diesem Abschnitt wird Schritt für Schritt beschrieben, wie die `selling_prices` Tabelle für die Datenanalysen vorbereitet wurde.\n",
    "\n",
    "### 1. Typanpassung und Neuanlage für `cleaned_selling_prices`\n",
    "Analog zur Bearbeitung der `listings`-Tabelle wurde auch für die Wohnpreisdaten eine neue, typisierte Tabelle erstellt. Ziel war es, Datentypen so anzupassen, dass eine direkte Weiterverarbeitung der Werte möglich ist – insbesondere in Bezug auf numerische Analysen.\n",
    "\n",
    "Beim Import der CSV-Datei wurden alle Spalten zunächst als Text `STRING` interpretiert. Für die Preisinformationen war dies jedoch ungeeignet, da diese Felder in späteren Analysen arithmetisch verarbeitet werden sollen (z. B. Mittelwertberechnungen, Preisvergleiche, Visualisierungen). Deshalb wurden gezielt die drei preisbezogenen Attribute in den passenden numerischen Datentyp `INTEGER` überführt:\n",
    "- `HAPreisWohnflaeche`: Preis pro Quadratmeter\n",
    "- `HAMedianPreis`: Medianpreis\n",
    "- `HASumPreis`: Gesamtpreis\n",
    "\n",
    "```sql\n",
    "CREATE TABLE cleaned_ha_preise (\n",
    "  Stichtagdatjahr INTEGER,\n",
    "  DatenstandCd TEXT,\n",
    "  HAArtLevel1Sort INTEGER,\n",
    "  HAArtLevel1Cd INTEGER,\n",
    "  HAArtLevel1Lang TEXT,\n",
    "  HASTWESort INTEGER,\n",
    "  HASTWECd TEXT,\n",
    "  HASTWELang TEXT,\n",
    "  RaumSort TEXT,\n",
    "  RaumCd TEXT,\n",
    "  RaumLang TEXT,\n",
    "  AnzZimmerLevel2Sort_noDM INTEGER,\n",
    "  AnzZimmerLevel2Cd_noDM INTEGER,\n",
    "  AnzZimmerLevel2Lang_noDM TEXT,\n",
    "  AnzHA TEXT,\n",
    "  HAPreisWohnflaeche INTEGER,\n",
    "  HAMedianPreis INTEGER,\n",
    "  HASumPreis INTEGER\n",
    ");\n",
    "```\n",
    "\n",
    "### 2. Filtern und Übertragen gültiger Preisdaten für `cleaned_selling_prices`\n",
    "\n",
    "Um sicherzustellen, dass ausschliesslich qualitativ hochwertige und verarbeitbare Daten in die finale Analyse gelangen, wurden aus der Zwischen- bzw. Staging-Tabelle `stage_selling_prices` nur jene Datensätze in die endgültige Tabelle `cleaned_selling_prices` übernommen, bei denen **alle drei preisbezogenen Attribute gültige numerische Werte enthalten**.\n",
    "\n",
    "Insbesondere sollten folgende Fehlerquellen ausgeschlossen werden:\n",
    "- Leere Strings (`''`)\n",
    "- Nicht-numerische Einträge (z. B. `'K'` bei `HASumPreis`)\n",
    "- Formatierungsfehler (z. B. nicht ganzzahlig)\n",
    "- `NULL`-Werte\n",
    "\n",
    "Durch die Kombination von `IS NOT NULL`, expliziten Ausschlüssen und einem regulären Ausdruck `~ '^\\d+$'` wurde sichergestellt, dass nur **reine Ganzzahlen** verarbeitet werden, die für Aggregationen, Vergleiche und Visualisierungen ohne vorherige Umwandlung nutzbar sind.\n",
    "\n",
    "```sql\n",
    "INSERT INTO cleaned_selling_prices( \n",
    "  Stichtagdatjahr, DatenstandCd, HAArtLevel1Sort, HAArtLevel1Cd, HAArtLevel1Lang,\n",
    "  HASTWESort, HASTWECd, HASTWELang, RaumSort, RaumCd, RaumLang,\n",
    "  AnzZimmerLevel2Sort_noDM, AnzZimmerLevel2Cd_noDM, AnzZimmerLevel2Lang_noDM,\n",
    "  AnzHA, HAPreisWohnflaeche, HAMedianPreis, HASumPreis\n",
    ")\n",
    "SELECT\n",
    "  Stichtagdatjahr,\n",
    "  DatenstandCd,\n",
    "  HAArtLevel1Sort,\n",
    "  HAArtLevel1Cd,\n",
    "  HAArtLevel1Lang,\n",
    "  HASTWESort,\n",
    "  HASTWECd,\n",
    "  HASTWELang,\n",
    "  RaumSort,\n",
    "  RaumCd,\n",
    "  RaumLang,\n",
    "  AnzZimmerLevel2Sort_noDM,\n",
    "  AnzZimmerLevel2Cd_noDM,\n",
    "  AnzZimmerLevel2Lang_noDM,\n",
    "  AnzHA,\n",
    "  NULLIF(HAPreisWohnflaeche, '')::INTEGER,\n",
    "  NULLIF(HAMedianPreis, '')::INTEGER,\n",
    "  NULLIF(HASumPreis, '')::INTEGER\n",
    "FROM stage_selling_prices\n",
    "WHERE\n",
    "  HAPreisWohnflaeche IS NOT NULL AND HAPreisWohnflaeche <> '' AND HAPreisWohnflaeche ~ '^\\d+$' AND\n",
    "  HAMedianPreis IS NOT NULL AND HAMedianPreis <> '' AND HAMedianPreis ~ '^\\d+$' AND\n",
    "  HASumPreis IS NOT NULL AND HASumPreis <> '' AND HASumPreis <> 'K' AND HASumPreis ~ '^\\d+$';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04732f87",
   "metadata": {},
   "source": "## Datenaufbereitung für Analyse"
  },
  {
   "cell_type": "code",
   "id": "f467e925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:58:53.792233Z",
     "start_time": "2025-06-02T13:58:47.108870Z"
    }
   },
   "source": [
    "# === Bibliotheken importieren ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import nltk\n",
    "import dataclasses\n",
    "\n",
    "# NLTK Ressourcen (Downloads)\n",
    "nltk_resources = ['wordnet', 'stopwords', 'punkt', 'omw-1.4']\n",
    "for resource in nltk_resources:\n",
    "    try:\n",
    "        resource_path_part = f'corpora/{resource}.zip' if resource in ['wordnet', 'stopwords', 'omw-1.4'] else f'tokenizers/{resource}.zip'\n",
    "        nltk.data.find(resource_path_part)\n",
    "        print(f\"NLTK Ressource '{resource}' bereits vorhanden.\")\n",
    "    except LookupError: # Korrektes Abfangen von LookupError\n",
    "        print(f\"NLTK Ressource '{resource}' nicht gefunden. Versuche Download...\")\n",
    "        try:\n",
    "            nltk.download(resource, quiet=False)\n",
    "            print(f\"NLTK Ressource '{resource}' erfolgreich heruntergeladen.\")\n",
    "        except Exception as e: # Allgemeiner Fehler beim Download\n",
    "            print(f\"Fehler beim Herunterladen von '{resource}': {e}. Bitte manuell prüfen mit nltk.download('{resource}').\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (mean_squared_error, r2_score)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Importiere den Service und die Modelle\n",
    "# Stelle sicher, dass airbnb_analysis_service.py und bina_models.py im selben Verzeichnis oder im Python-Pfad sind.\n",
    "try:\n",
    "    from airbnb_analysis_service import AirbnbAnalysisService\n",
    "    from bina_models import Listing, SellingPrices\n",
    "except ImportError as e:\n",
    "    print(f\"Fehler beim Importieren des Services oder der Modelle: {e}\")\n",
    "    AirbnbAnalysisService = None; Listing = None; SellingPrices = None\n",
    "\n",
    "# Plotting-Einstellungen\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "# %matplotlib inline # Zeile für Jupyter Notebooks, um Plots inline anzuzeigen (kann hier auskommentiert bleiben)\n",
    "\n",
    "# === Daten laden via Service ===\n",
    "listings_df = pd.DataFrame() # Wird direkt mit den Daten aus dem Service befüllt\n",
    "selling_prices_df = pd.DataFrame()\n",
    "\n",
    "if AirbnbAnalysisService:\n",
    "    try:\n",
    "        service = AirbnbAnalysisService()\n",
    "        print(\"Lade Airbnb Listings via Service (aus Supabase `cleaned_listings`)...\")\n",
    "        listings_objects = service.get_listings()\n",
    "\n",
    "        if listings_objects and isinstance(listings_objects, list) and len(listings_objects) > 0:\n",
    "            if hasattr(listings_objects[0], 'model_dump'): listings_data = [l.model_dump(exclude_none=True) for l in listings_objects]\n",
    "            elif hasattr(listings_objects[0], 'dict'): listings_data = [l.dict(exclude_none=True) for l in listings_objects]\n",
    "            elif dataclasses.is_dataclass(listings_objects[0]): listings_data = [dataclasses.asdict(l) for l in listings_objects]\n",
    "            else: listings_data = [l.__dict__ for l in listings_objects]\n",
    "            listings_df = pd.DataFrame(listings_data) # Direkte Zuweisung zu listings_df\n",
    "            print(f\"Airbnb Listings erfolgreich geladen. Shape: {listings_df.shape}\")\n",
    "        else:\n",
    "            print(\"Keine Listings-Daten vom Service erhalten oder Liste ist leer.\")\n",
    "\n",
    "        print(\"\\nLade Immobilien-Verkaufspreise via Service (aus Supabase `cleaned_selling_prices`)...\")\n",
    "        selling_prices_objects = service.get_selling_prices()\n",
    "        if selling_prices_objects and isinstance(selling_prices_objects, list) and len(selling_prices_objects) > 0:\n",
    "            if hasattr(selling_prices_objects[0], 'model_dump'): selling_prices_data = [sp.model_dump(exclude_none=True) for sp in selling_prices_objects]\n",
    "            elif hasattr(selling_prices_objects[0], 'dict'): selling_prices_data = [sp.dict(exclude_none=True) for sp in selling_prices_objects]\n",
    "            elif dataclasses.is_dataclass(selling_prices_objects[0]): selling_prices_data = [dataclasses.asdict(sp) for sp in selling_prices_objects]\n",
    "            else: selling_prices_data = [sp.__dict__ for sp in selling_prices_objects]\n",
    "            selling_prices_df = pd.DataFrame(selling_prices_data) # Direkte Zuweisung zu selling_prices_df\n",
    "            print(f\"Immobilien-Verkaufspreise erfolgreich geladen. Shape: {selling_prices_df.shape}\")\n",
    "        else:\n",
    "            print(\"Keine Verkaufspreis-Daten vom Service erhalten oder Liste ist leer.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden der Daten via Service: {e}\")\n",
    "else:\n",
    "    print(\"AirbnbAnalysisService konnte nicht importiert werden. Daten können nicht geladen werden.\")\n",
    "\n",
    "# === Erste Inspektion der (aus Supabase geladenen) Daten ===\n",
    "if not listings_df.empty:\n",
    "    print(\"\\n--- Listings DataFrame (aus Supabase): Erste 5 Zeilen ---\"); print(listings_df.head())\n",
    "    print(f\"\\n--- Listings DataFrame (aus Supabase): Dimensionen --- \\nShape: {listings_df.shape}\")\n",
    "    print(\"\\n--- Listings DataFrame (aus Supabase): Info ---\"); listings_df.info()\n",
    "    print(\"\\n--- Listings DataFrame (aus Supabase): Fehlende Werte (Top 10) ---\"); print(listings_df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print(\"Listings DataFrame ist leer oder konnte nicht geladen werden.\")\n",
    "\n",
    "if not selling_prices_df.empty:\n",
    "    print(\"\\n\\n--- Selling Prices DataFrame (aus Supabase): Erste 5 Zeilen ---\"); print(selling_prices_df.head())\n",
    "    print(\"\\n--- Selling Prices DataFrame (aus Supabase): Info ---\"); selling_prices_df.info()\n",
    "else:\n",
    "    print(\"\\nSelling Prices DataFrame ist leer oder konnte nicht geladen werden.\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mseaborn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msns\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mast\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "ec1095bc",
   "metadata": {},
   "source": [
    "## Finale Datenanpassungen und DataFrame Engineering für Analyse\n",
    "\n",
    "Obwohl die Daten in Supabase grundlegend bereinigt wurden, führen wir hier finale Anpassungen durch, die spezifisch für die Analysen und Modellierungen in diesem Notebook notwendig sind. Wir erstellen eine Arbeitskopie `df_analysis` von listings_df`."
   ]
  },
  {
   "cell_type": "code",
   "id": "84d2fa25",
   "metadata": {},
   "source": [
    "df_analysis = pd.DataFrame() # Initialisiere df_analysis als leeren DataFrame\n",
    "\n",
    "if not listings_df.empty:\n",
    "    df_analysis = listings_df.copy() # Arbeitskopie erstellen\n",
    "\n",
    "    # 1. Preisspalte ('price') - finale Prüfung und Filterung\n",
    "    # Annahme: 'price' ist bereits float aus Supabase (gemäss bina_models.Listing.price: Optional[float])\n",
    "    if 'price' in df_analysis.columns:\n",
    "        df_analysis['price'] = pd.to_numeric(df_analysis['price'], errors='coerce')\n",
    "        df_analysis.dropna(subset=['price'], inplace=True)\n",
    "        if not df_analysis.empty and df_analysis['price'].nunique() > 1 :\n",
    "            price_q_low_notebook = df_analysis['price'].quantile(0.005)\n",
    "            price_q_high_notebook = df_analysis['price'].quantile(0.995)\n",
    "            if pd.notna(price_q_low_notebook) and pd.notna(price_q_high_notebook):\n",
    "                 df_analysis = df_analysis[df_analysis['price'].between(price_q_low_notebook, price_q_high_notebook, inclusive='both')]\n",
    "    else:\n",
    "        print(f\"KRITISCH: Preisspalte 'price' fehlt.\"); df_analysis['price'] = np.nan\n",
    "\n",
    "    # 2. Numerische Spalten: Finale Imputation für Modellierung\n",
    "    # 'bathrooms' ist Optional[float]\n",
    "    # 'beds' ist Optional[float]\n",
    "    numeric_cols_to_impute_final = [\n",
    "        'bedrooms', 'bathrooms', 'accommodates', 'beds',\n",
    "        'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "        'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "        'review_scores_value', 'reviews_per_month', 'number_of_reviews', 'availability_365',\n",
    "        'host_listings_count', 'host_total_listings_count'\n",
    "    ]\n",
    "    for col in numeric_cols_to_impute_final:\n",
    "        if col in df_analysis.columns:\n",
    "            df_analysis[col] = pd.to_numeric(df_analysis[col], errors='coerce')\n",
    "            if df_analysis[col].isnull().sum() > 0:\n",
    "                if not df_analysis[col].isnull().all():\n",
    "                    df_analysis[col] = df_analysis[col].fillna(df_analysis[col].median())\n",
    "                else:\n",
    "                     df_analysis[col] = df_analysis[col].fillna(0)\n",
    "        else:\n",
    "            print(f\"Info: Numerische Spalte '{col}' für finale Imputation fehlt.\"); df_analysis[col] = np.nan\n",
    "\n",
    "    # 3. Prozentuale Host-Metriken\n",
    "    # 'host_response_rate': Optional[str] (z.B. \"90%\")\n",
    "    if 'host_response_rate' in df_analysis.columns:\n",
    "        df_analysis['host_response_rate'] = df_analysis['host_response_rate'].replace(['N/A', None, ''], np.nan)\n",
    "        # Da es als String von Supabase kommen kann (gem. bina_models)\n",
    "        if df_analysis['host_response_rate'].dropna().apply(lambda x: isinstance(x, str)).any():\n",
    "             df_analysis['host_response_rate'] = df_analysis['host_response_rate'].str.rstrip('%').astype(float) / 100.0\n",
    "        else:\n",
    "            df_analysis['host_response_rate'] = pd.to_numeric(df_analysis['host_response_rate'], errors='coerce')\n",
    "            mask_hrr_analysis = (df_analysis['host_response_rate'] > 1.0) & (df_analysis['host_response_rate'] <= 100.0)\n",
    "            df_analysis.loc[mask_hrr_analysis, 'host_response_rate'] = df_analysis.loc[mask_hrr_analysis, 'host_response_rate'] / 100.0\n",
    "\n",
    "        if not df_analysis['host_response_rate'].isnull().all(): df_analysis['host_response_rate'] = df_analysis['host_response_rate'].fillna(df_analysis['host_response_rate'].median())\n",
    "        else: df_analysis['host_response_rate'] = df_analysis['host_response_rate'].fillna(0.5)\n",
    "    else:\n",
    "        print(f\"Info: Spalte 'host_response_rate' fehlt.\"); df_analysis['host_response_rate'] = np.nan\n",
    "\n",
    "    # 'host_acceptance_rate_percent': Optional[int] (z.B. 90 für 90%)\n",
    "    if 'host_acceptance_rate_percent' in df_analysis.columns:\n",
    "        df_analysis['host_acceptance_rate_percent'] = pd.to_numeric(df_analysis['host_acceptance_rate_percent'], errors='coerce') / 100.0\n",
    "        if not df_analysis['host_acceptance_rate_percent'].isnull().all(): df_analysis['host_acceptance_rate_percent'] = df_analysis['host_acceptance_rate_percent'].fillna(df_analysis['host_acceptance_rate_percent'].median())\n",
    "        else: df_analysis['host_acceptance_rate_percent'] = df_analysis['host_acceptance_rate_percent'].fillna(0.5)\n",
    "    else:\n",
    "        print(f\"Info: Spalte 'host_acceptance_rate_percent' fehlt.\"); df_analysis['host_acceptance_rate_percent'] = np.nan\n",
    "\n",
    "    for rate_col in ['host_response_rate', 'host_acceptance_rate_percent']:\n",
    "        if rate_col in df_analysis.columns: df_analysis[rate_col] = np.clip(df_analysis[rate_col], 0, 1)\n",
    "\n",
    "    # 4. Amenities ('amenities' ist Optional[list[str]] in bina_models)\n",
    "    if 'amenities' in df_analysis.columns:\n",
    "        def count_amenities_from_model_list(amenity_input): # Bereits angepasst für Listen\n",
    "            if isinstance(amenity_input, list): return len(amenity_input)\n",
    "            if pd.isna(amenity_input): return 0\n",
    "            if isinstance(amenity_input, str): # Seltener Fallback für Strings\n",
    "                 if amenity_input in ['[]', '{}', ''] or not amenity_input.strip(): return 0\n",
    "                 try:\n",
    "                     parsed_list = ast.literal_eval(amenity_input)\n",
    "                     return len(parsed_list) if isinstance(parsed_list, list) else 0\n",
    "                 except: return 0\n",
    "            return 0\n",
    "        df_analysis['num_amenities'] = df_analysis['amenities'].apply(count_amenities_from_model_list)\n",
    "    else:\n",
    "        df_analysis['num_amenities'] = 0; print(f\"Warnung: Spalte 'amenities' nicht gefunden.\")\n",
    "\n",
    "    # 5. Superhost Status ('host_is_superhost' ist Optional[bool])\n",
    "    if 'host_is_superhost' in df_analysis.columns:\n",
    "        df_analysis['host_is_superhost'] = df_analysis['host_is_superhost'].map({True: 1, False: 0}).fillna(0).astype(int)\n",
    "    else:\n",
    "        df_analysis['host_is_superhost'] = 0; print(f\"Info: Spalte 'host_is_superhost' fehlt, wird mit 0 initialisiert.\")\n",
    "\n",
    "    # 6. Host Response Time ('host_response_time' ist Optional[str])\n",
    "    if 'host_response_time' in df_analysis.columns:\n",
    "        df_analysis['host_response_time'] = df_analysis['host_response_time'].fillna('N/A').astype('category')\n",
    "    else:\n",
    "        df_analysis['host_response_time'] = 'N/A'; df_analysis['host_response_time'] = df_analysis['host_response_time'].astype('category')\n",
    "\n",
    "    # 7. Host Identity Verified ('host_identity_verified' ist Optional[bool])\n",
    "    if 'host_identity_verified' in df_analysis.columns:\n",
    "        df_analysis['host_identity_verified'] = df_analysis['host_identity_verified'].map({True: 1, False: 0}).fillna(0).astype(int)\n",
    "    else:\n",
    "        df_analysis['host_identity_verified'] = 0\n",
    "\n",
    "    # 8. Standortspalte (`loc_col_for_analysis_notebook`) - Auswahl und Sicherstellung des Typs\n",
    "    # Definiere eine lokale Variable für die Standortspalte, die in diesem Notebook verwendet wird\n",
    "    loc_col_for_analysis_notebook = None\n",
    "    if 'neighbourhood_group_cleansed' in df_analysis.columns and df_analysis['neighbourhood_group_cleansed'].nunique() >= 1:\n",
    "        loc_col_for_analysis_notebook = 'neighbourhood_group_cleansed'\n",
    "    elif 'neighbourhood_cleansed' in df_analysis.columns and df_analysis['neighbourhood_cleansed'].nunique() >= 1:\n",
    "        loc_col_for_analysis_notebook = 'neighbourhood_cleansed'\n",
    "    elif 'neighbourhood' in df_analysis.columns and df_analysis['neighbourhood'].nunique() >=1:\n",
    "        loc_col_for_analysis_notebook = 'neighbourhood'\n",
    "\n",
    "    if loc_col_for_analysis_notebook:\n",
    "        print(f\"Verwende '{loc_col_for_analysis_notebook}' als primäre Standortspalte für Analysen in diesem Notebook.\")\n",
    "        df_analysis[loc_col_for_analysis_notebook] = df_analysis[loc_col_for_analysis_notebook].fillna('Unknown').astype(str)\n",
    "    else:\n",
    "        print(f\"KRITISCH: Keine valide Standortspalte gefunden. Erstelle 'location_fallback'.\");\n",
    "        df_analysis['location_fallback'] = 'Unknown'; loc_col_for_analysis_notebook = 'location_fallback'\n",
    "    # Stelle sicher, dass die verwendete Spalte existiert, auch wenn es der Fallback ist\n",
    "    if loc_col_for_analysis_notebook not in df_analysis.columns: df_analysis[loc_col_for_analysis_notebook] = 'Unknown'\n",
    "    df_analysis[loc_col_for_analysis_notebook] = df_analysis[loc_col_for_analysis_notebook].astype(str)\n",
    "\n",
    "\n",
    "    # 9. Room Type ('room_type' ist Optional[str])\n",
    "    if 'room_type' in df_analysis.columns: df_analysis['room_type'] = df_analysis['room_type'].fillna('Unknown').astype('category')\n",
    "    else: print(f\"KRITISCH: Spalte 'room_type' fehlt.\"); df_analysis['room_type'] = 'Unknown'; df_analysis['room_type'] = df_analysis['room_type'].astype('category')\n",
    "\n",
    "    # 10. Textspalten für NLP (UC4)\n",
    "    text_cols_nlp_list = ['description', 'name', 'neighborhood_overview', 'host_about']\n",
    "    for col in text_cols_nlp_list:\n",
    "        if col in df_analysis.columns: df_analysis[col] = df_analysis[col].fillna('').astype(str)\n",
    "        else: print(f\"Info: Textspalte '{col}' für NLP fehlt.\"); df_analysis[col] = ''\n",
    "\n",
    "    # Log-Transformation des Preises für Regression (UC2) und ggf. andere Analysen\n",
    "    if 'price' in df_analysis.columns and df_analysis['price'].nunique() > 1 and pd.api.types.is_numeric_dtype(df_analysis['price']):\n",
    "        df_analysis['price_log'] = np.log1p(df_analysis['price'])\n",
    "    else:\n",
    "        df_analysis['price_log'] = np.nan\n",
    "\n",
    "    # Finale Bereinigung von Zeilen, falls Preis nach allem immer noch NaN ist\n",
    "    if 'price' in df_analysis.columns: df_analysis.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "    print(f\"\\nFinale Datenanpassungen im Notebook abgeschlossen. Shape des DataFrames `df_analysis`: {df_analysis.shape}\")\n",
    "    if df_analysis.empty: print(\"WARNUNG: DataFrame `df_analysis` ist nach finalen Anpassungen leer!\")\n",
    "    else:\n",
    "        print(\"\\nÜberprüfung der wichtigsten Spalten nach finaler Anpassung (erste 5 Zeilen von `df_analysis`):\")\n",
    "        cols_to_show_final = ['price', loc_col_for_analysis_notebook, 'room_type', 'accommodates', 'bedrooms',\n",
    "                              'bathrooms', 'num_amenities', 'host_is_superhost',\n",
    "                              'review_scores_rating', 'host_response_time',\n",
    "                              'host_response_rate', 'host_acceptance_rate_percent', 'price_log']\n",
    "        existing_cols_to_show_final = [col for col in cols_to_show_final if col in df_analysis.columns]\n",
    "        if existing_cols_to_show_final:\n",
    "          print(df_analysis[existing_cols_to_show_final].head())\n",
    "else:\n",
    "    print(\"Ursprünglicher Listings DataFrame (`listings_df`) ist leer. Datenaufbereitung übersprungen.\")\n",
    "    df_analysis = pd.DataFrame()\n",
    "    loc_col_for_analysis_notebook = 'location_fallback' # Fallback für loc_col_for_analysis_notebook"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d089dc0",
   "metadata": {},
   "source": [
    "from airbnb_analysis_service import AirbnbAnalysisService\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # create service class\n",
    "    airbnbAnalysis = AirbnbAnalysisService()\n",
    "\n",
    "    # get all tables in form of a list\n",
    "    listings = airbnbAnalysis.get_listings()\n",
    "\n",
    "    print(f\"listings {listings[0]}\")\n",
    "\n",
    "    # Schritt 1: Umwandeln in DataFrames\n",
    "    listings_df = pd.DataFrame([l.__dict__ for l in listings])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8fb0d95",
   "metadata": {},
   "source": [
    "# Step 3: Analyzing Data\n",
    "\n",
    "## Objective 1 – Marktpotenzial und Standortanalyse\n",
    "Im Rahmen dieses ersten Untersuchungsziels soll eine fundierte Analyse des Marktpotenzials sowie eine differenzierte Standortbewertung für Kurzzeitvermietung über Airbnb in der stadt Zürich erfolgen. Ziel ist es, für die InvestZurich AG belastbare Entscheidungsgrundlagen zu schaffen, um vielversprechende Investitionsgebiete zu identifizieren und zu priorisieren.\n",
    "\n",
    "Zürich ist als internationale Wirtschaftsmetropole, Bildungsstandort und Tourismusziel von konstant hoher Nachfrage geprägt. Besonders im Bereich temporärer Unterkünfte - wie sie Airbnb bietet - ergeben sich daraus regelmässig neue Marktchance, aber auch dynamische Herausforderungen. Für eine Immobilien-Investmentstrategie in diesem Segment sind sowohl mikrogeografische Unterschiede zwischen Quartieren als auch spezifische Angebots- und Nachfragestrukturen zentral.\n",
    "\n",
    "Daher verfolgt dieses Kapitel die Frage, wo innerhalb Zürich das grösste Potenzial für Airbnb-Investitionen liegt - unter Berücksichtigung von Preisniveau, Nachfrageintensität und Angebotsstrktur je Kreis. Zusätzlich wird untersucht, welche Wohnungstypen (z.B. Anzahl Zimmer, Wohnungsgrösse) besonders gefragt oder unterversorgt sind, um daraus konkrete Handlungsempfehlungen für die künftige Immobilienauswahl ableiten zu können.\n",
    "\n",
    "Zur Beantwortung dieser fragestellungen werden verschiedene Datenquellen herangezogen, explorative Visualisierungen erstellt und relevante statistische Kennzahlen berechnet.\n",
    "\n",
    "### Anzahl Listings pro Kreis\n",
    "Ein zentraler Ausgangspunkt zur Analyse des Marktpotenzials im Zürcher Airbnb-Markt ist die Betrachtung der derzeitigen Angebotsverteilung über die verschiedenen Stadtkreise hinweg. Die folgende Visualisierung zeigt die absolute Anzahl an Airbnb-Angeboten (\"Listings\") pro Kreis. Dadurch lassen sich erste Aussagen über die Marktaktivität und mögliche Sättigung oder Unterversorgung einzelner Stadtteile treffen.\n",
    "\n",
    "Die nachfolgende Darstellung zeigt die Anzahl Listing pro Kreis:"
   ]
  },
  {
   "cell_type": "code",
   "id": "eaca0cb3",
   "metadata": {},
   "source": [
    "# Gruppierung – Anzahl Listings pro Stadtteilgruppe\n",
    "kreis_counts = listings_df[\"neighbourhood_group_cleansed\"].value_counts().reset_index()\n",
    "kreis_counts.columns = [\"neighbourhood_group_cleansed\", \"count\"]\n",
    "kreis_counts_sorted = kreis_counts.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Plot in fig1 speichern\n",
    "fig1, ax = plt.subplots(figsize=(12,6))\n",
    "bar_color = \"#5DADE2\"\n",
    "barplot = sns.barplot(\n",
    "    data=kreis_counts_sorted,\n",
    "    x=\"neighbourhood_group_cleansed\",\n",
    "    y=\"count\",\n",
    "    ax=ax,\n",
    "    color=bar_color\n",
    ")\n",
    "\n",
    "# Zahlen über den Balken anzeigen\n",
    "for bar in barplot.patches:\n",
    "    height = bar.get_height()\n",
    "    barplot.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{int(height)}',\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "# Achsentitel und Design\n",
    "ax.set_title(\"Anzahl Airbnb-Listings pro Kreis in Zürich\", fontsize=14)\n",
    "ax.set_xlabel(\"Kreis\")\n",
    "ax.set_ylabel(\"Anzahl Listings\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig1.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9cfa85ce",
   "metadata": {},
   "source": [
    "Wie aus der Visualisierung deutlich hervorgeht, konzentriert sich das Angebot derzeit stark auf bestimmte Stadtteile. Besonders Kreis 11 sticht mit 72 aktiven Listings hervor, gefolgt von Kreis 4 und Kreis 8 (jeweils 63) sowie Kreis 7 (60). Diese Kreise zeichnen sich offenbar durch eine bereits hohe Marktdurchdringung im Bereich Kurzzeitvermietung aus.\n",
    "\n",
    "Demgegenüber zeigen Kreis 10 (25 Listings), Kreis 5 (22 Listings) und insbesondere Kreis 12 (nur 3 Listings) eine deutlich geringere Präsenz auf Airbnb. Diese niedrigeren Zahlen können verschieden interpretiert werden: Einerseits könnten sie auf geringere Nachfrage oder restriktivere Regulierungen hindeuten. Andererseits besteht hier möglicherweise ein bislang unerschlossenes Marktpotenzial, das gezielt erschlossen werden könnte – etwa durch gezielte Investitionen in passende Wohnungstypen und differenzierte Angebotsstrategien.\n",
    "\n",
    "- Hohe Listings-Zahlen (z.B. Kreise 4, 8, 11): Diese Quartiere sind vermutlich stark frequentiert und bieten bereits funktionierende Geschäftsmodelle. Für Investoren könnten diese Bezirke trotz möglicher Konkurrenz weiterhin attraktiv sein – sofern Nachfrage, Auslastung und Preisniveau entsprechend hoch sind.\n",
    "\n",
    "- Niedrige Listings-Zahlen (z.B. Kreise 5, 10, 12): Diese Bereiche könnten neue Chancen eröffnen, insbesondere wenn dort eine latente Nachfrage besteht, die bislang nicht durch Airbnb-Angebote gedeckt wurde. Eine tiefere Analyse von Besucherströmen, Infrastruktur und lokalen Gegebenheiten ist hier entscheidend.\n",
    "\n",
    "### Durchschnittlicher Preis pro Nacht und Kreis\n",
    "Im zweiten Schritt der Standortanalyse richtet sich der Fokus auf die durchschnittlichen Übernachtungspreise pro Airbnb-Listing, differenziert nach Keisen in Zürich. Diese Kennzahl ist von zentraler Bedeutung für die Bewertung der potenziellen Ertragskraft eines Investments: Je höher der durchschnittliche Preis pro Nacht, desto grösser ist – bei vergleichbarer Auslastung – das Umsatzpotenzial einer Unterkunft.\n",
    "\n",
    "Die nachfolgende Visualisierung zeigt die durchschnittlichen Preise pro Nacht (in CHF) für jedes Zürcher Stadtquartier:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdff7bc6",
   "metadata": {},
   "source": [
    "# Daten filtern\n",
    "listings_df = listings_df[\n",
    "    (listings_df['price'] > 0) &\n",
    "    (listings_df['availability_365'] > 0) &\n",
    "    (listings_df['neighbourhood'].notnull())\n",
    "]\n",
    "\n",
    "# Gruppieren nach neighbourhood_group_cleansed\n",
    "group_stats = listings_df.groupby(\"neighbourhood_group_cleansed\").agg({\n",
    "    \"price\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Sortieren nach Preis\n",
    "group_stats_sorted = group_stats.sort_values(by=\"price\", ascending=False)\n",
    "\n",
    "# Plot in fig2 speichern\n",
    "fig2, ax = plt.subplots(figsize=(12,6))\n",
    "sns.barplot(data=group_stats_sorted, x=\"neighbourhood_group_cleansed\", y=\"price\", ax=ax)\n",
    "ax.set_title(\"Durchschnittlicher Preis pro Kreis / Nacht\")\n",
    "ax.set_ylabel(\"Durchschnittlicher Preis (CHF)\")\n",
    "ax.set_xlabel(\"Kreis\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Durchschnittspreise oberhalb der Balken anzeigen\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{height:.0f}',\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "fig2.tight_layout()\n",
    "\n",
    "durchschnittspreis = listings_df[\"price\"].mean()\n",
    "print(f\"Durchschnittlicher Preis aller Airbnb-Angebote: {durchschnittspreis:.2f} CHF\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e1e244d",
   "metadata": {},
   "source": [
    "Der auffälligste Ausreisser ist klar Kreis 2, mit einem durchschnittlichen Preis von 487 CHF pro Nacht. Dieser Wert liegt deutlich über dem Marktdurchschnitt von 195 CHF und hebt sich stark von allen anderen Kreisen ab. Kreis 2 liegt direkt am Zürichsee und umfasst prestigeträchtige Wohnlagen wie Enge und Wollishofen – Stadtteile, die bei Touristen durch Seelage, Ruhe und Exklusivität besonders gefragt sind. Für Investoren bietet dieser Kreis somit ein überdurchschnittlich hohes Preisniveau, das allerdings mit entsprechend hohen Immobilienpreisen und regulatorischen Hürden einhergehen dürfte.\n",
    "\n",
    "Es folgen Kreis 1 (246 CHF) – das historische und touristische Zentrum der Stadt – sowie Kreis 5 (213 CHF), das trendige ehemalige Industriequartier mit hoher kultureller Dichte und urbanem Flair. Auch Kreis 8 und 4 (je 206 CHF) zeigen attraktive durchschnittliche Übernachtungspreise.\n",
    "\n",
    "Der Grossteil der übrigen Kreise bewegt sich im Bereich zwischen 130 und 170 CHF pro Nacht. Den niedrigsten Durchschnittspreis verzeichnet Kreis 12 mit 98 CHF, was auf eine geringere touristische Attraktivität oder geringere Zahlungsbereitschaft hinweist.\n",
    "\n",
    "**Fazit und strategische Überlegungen:**\n",
    "- Premium-Strategie: Investitionen in Kreise mit hohen durchschnittlichen Preisen (v.a. 2, 1, 5, 4, 8) versprechen potenziell hohe Umsätze pro Nacht. Diese Strategie setzt jedoch meist höhere Einstiegskosten, intensivere Konkurrenz und gegebenenfalls strengere Auflagen voraus.\n",
    "- Wachstumsstrategie: In Kreisen mit bislang niedrigem Angebot und moderaten Preisen (z.B. 10, 12) könnten gezielte Investitionen lohnenswert sein – insbesondere, wenn dort Nachfragepotenziale bestehen, die bislang nicht durch Airbnb-Angebote gedeckt sind.\n",
    "- Mischstrategie: Eine Kombination aus hochpreisigen Lagen mit etabliertem Marktumfeld und aufstrebenden, preisgünstigen Quartieren könnte für InvestZurich AG ein ausgewogenes Risiko-Ertrags-Profil darstellen.\n",
    "\n",
    "In Kombination mit der zuvor analysierten Angebotsdichte ergibt sich ein differenziertes Bild: Ein hoher Preis bedeutet nicht zwangsläufig geringe Konkurrenz, ebenso ist ein niedriges Preisniveau nicht automatisch ein Ausschlusskriterium für Investitionen.\n",
    "\n",
    "### Durchschnittliche Verfügbarkeit der Airbnb-Listings\n",
    "Nach der Analyse von Angebotsdichte und durchschnittlichem Übernachtungspreis liefert ein weiterer wichtiger Indikator zusätzliche Einblicke in die Marktdynamik: die Verfügbarkeit von Airbnb-Angeboten pro Jahr und pro Stadtkreis.\n",
    "\n",
    "Im dritten Analyseschritt betrachten wir die durchschnittliche Verfügbarkeit von Airbnb-Angeboten in den einzelnen Zürcher Stadtkreisen – gemessen an der Variable availability_365. Diese beschreibt, an wie vielen Tagen im Jahr ein Airbnb theoretisch verfügbar ist. Eine niedrige Verfügbarkeit kann darauf hinweisen, dass ein Objekt häufig gebucht und damit stark nachgefragt ist – also eine hohe Auslastung aufweist. Die nachfolgende Abbildung zeigt, an wie vielen Tagen die Airbnb's durchschnittlich pro Kreis innerhalb der nächsten 365 Tagen noch buchbar sind."
   ]
  },
  {
   "cell_type": "code",
   "id": "36e1f1a9",
   "metadata": {},
   "source": [
    "# Daten bereinigen und aggregieren\n",
    "availability_stats = listings_df.groupby(\"neighbourhood_group_cleansed\").agg({\n",
    "    \"availability_365\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Sortieren nach Verfügbarkeit\n",
    "availability_stats_sorted = availability_stats.sort_values(by=\"availability_365\", ascending=False)\n",
    "\n",
    "# Plot in fig3 speichern\n",
    "fig3, ax = plt.subplots(figsize=(12,6))\n",
    "bar_color = \"#5DADE2\"\n",
    "sns.barplot(\n",
    "    data=availability_stats_sorted,\n",
    "    x=\"neighbourhood_group_cleansed\",\n",
    "    y=\"availability_365\",\n",
    "    color=bar_color,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Werte über den Balken anzeigen\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{height:.0f}',  # ganze Tage ohne Nachkommastellen\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "# Titel, Achsen und Layout\n",
    "ax.set_title(\"Durchschnittliche Verfügbarkeit (Tage/Jahr) von Airbnbs pro Kreis\", fontsize=14)\n",
    "ax.set_xlabel(\"Kreis\")\n",
    "ax.set_ylabel(\"Ø Verfügbarkeit pro Jahr (Tage)\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig3.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99e9cc83",
   "metadata": {},
   "source": [
    "**Interpretation der Verfügbarkeiten:**\n",
    "\n",
    "Die geringsten durchschnittlichen Verfügbarkeiten zeigen sich in...\n",
    "- Kreis 10 (138 Tage)\n",
    "- Kreis 5 (151 Tage)\n",
    "- Kreis 2 (157 Tage)\n",
    "\n",
    "Diese Zahlen legen nahe, dass die dort gelisteten Unterkünfte besonders häufig gebucht sind – ein klares Zeichen für eine hohe Marktnachfrage und attraktive Standorte für Investitionen. Solche Kreise sind aus Investorensicht spannend, da sie auf eine gute Auslastung und stabile Einnahmen hindeuten.\n",
    "\n",
    "Umgekehrt haben Kreise mit hoher Verfügbarkeit wie:\n",
    "- Kreis 1 (227 Tage)\n",
    "- Kreis 9 (224 Tage)\n",
    "- Kreis 3 (213 Tage)\n",
    "eher ein Überangebot oder eine geringere Buchungsfrequenz. Hier könnten Unterkünfte teilweise leer stehen oder noch nicht optimal ausgelastet sein – potenziell ein Zeichen für ein schwächeres Nachfrageprofil.\n",
    "-\n",
    "Es ist allerdings zu beachten, dass niedrige Verfügbarkeiten auch durch Kalendersperrungen durch Gastgeber oder gesetzliche Einschränkungen verursacht werden können. Dennoch: In der Regel gilt eine niedrige Verfügbarkeit als positives Marktzeichen, sofern sie auf eine tatsächliche Gästebuchung zurückzuführen ist.\n",
    "\n",
    "**Verbindung zu bisherigen Erkenntnissen:**\n",
    "- Kreis 2 ist besonders interessant: Er kombiniert sehr hohe Preise (487 CHF/Nacht) mit vergleichsweise geringer Verfügbarkeit – ein Indiz für lukrative, stark nachgefragte Premium-Listings.\n",
    "- Kreis 10, obwohl mit moderaten Preisen und geringer Angebotsdichte, weist die geringste Verfügbarkeit auf. Dies könnte auf eine hohe Nachfrage bei gleichzeitig geringem Wettbewerb hinweisen – ein vielversprechender Nischenmarkt.\n",
    "\n",
    "### Einfluss des Unterkunftstyps auf die Verfügbarkeit\n",
    "Nachdem wir die Angebotsdichte, Preisstruktur und durchschnittliche Verfügbarkeit pro Stadtkreis betrachtet haben, widmet sich dieser Abschnitt der Frage, ob auch der Unterkunftstyp einen Einfluss auf die Beliebtheit und Auslastung eines Airbnb-Angebots hat. Dafür wurde erneut die Variable availability_365 verwendet und mittels Boxplot-Visualisierung nach Unterkunftstyp aufgeschlüsselt. Die nachfolgende Visualisierung zeigt die Verteilungsstruktur der jährlichen Verfügbarkeit für die drei  Unterkunftsarten, Private Room, Entire Home/Apt und Hotel Room auf Airbnb in Zürich."
   ]
  },
  {
   "cell_type": "code",
   "id": "ae22afe3",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "df = listings_df[\n",
    "    (listings_df[\"availability_365\"].notnull()) &\n",
    "    (listings_df[\"room_type\"].notnull())\n",
    "]\n",
    "\n",
    "# Extreme Verfügbarkeiten beschränken (nur bis 365 Tage erlaubt)\n",
    "df = df[df[\"availability_365\"] <= 365]\n",
    "\n",
    "# Plot in fig4 speichern\n",
    "fig4, ax = plt.subplots(figsize=(12,6))\n",
    "box_color = \"#5DADE2\"\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"room_type\",\n",
    "    y=\"availability_365\",\n",
    "    color=box_color,\n",
    "    showfliers=True,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Layout\n",
    "ax.set_title(\"Verfügbarkeitsverteilung je Unterkunftstyp\", fontsize=14)\n",
    "ax.set_xlabel(\"Unterkunftstyp\")\n",
    "ax.set_ylabel(\"Verfügbarkeit im Jahr (Tage)\")\n",
    "ax.tick_params(axis='x', rotation=0)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig4.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40fbe6df",
   "metadata": {},
   "source": [
    "**Einige zentrale Beobachtungen:**\n",
    "- Private Rooms zeigen eine sehr breite Streuung, mit Verfügbarkeiten zwischen nahezu 0 und 365 Tagen. Der Median liegt jedoch relativ tief, was darauf hindeutet, dass diese Objekte häufig gebucht oder blockiert sind – ein möglicher Hinweis auf hohe Nachfrage.\n",
    "- Entire Homes/Apartments weisen ebenfalls eine grosse Spannbreite auf, mit einem Median leicht oberhalb der Private Rooms. Dies lässt vermuten, dass sie etwas seltener gebucht oder bewusster dosiert verfügbar gemacht werden – etwa durch Gastgeber, die sie auch selbst nutzen.\n",
    "- Hotel Rooms zeigen eine deutlich engere Verteilung mit einem höheren Median und vergleichsweise hoher konstanter Verfügbarkeit (oft über 250 Tage). Dies spiegelt die professionell betriebene Natur dieser Angebote wider, welche meist permanent buchbar und weniger von privaten Nutzungszyklen abhängig sind. Gleichzeitig kann die hohe Verfügbarkeit aber auch auf niedrigere Auslastung hindeuten, wenn der Markt gesättigt ist oder Nachfrage fehlt.\n",
    "\n",
    "In dieser Darstellung ist der Unterkunftstyp \"Private Room\" tendenziell am wenigsten verfügbar, was als Indikator für hohe Nachfrage interpretiert werden kann – entweder durch eine Vielzahl an Buchungen oder durch punktuell aktivierte Verfügbarkeit. Investitionen in dieses Segment könnten sich für Anbieter mit begrenzten Immobilienressourcen (z.B. einzelne Zimmer in bewohnten Wohnungen) lohnen.\n",
    "\n",
    "### Verfügbarkeit in Abhängigkeit von der Unterkunftskapazität\n",
    "Ein weiterer entscheidender Faktor bei der Bewertung des Marktpotenzials von Airbnb-Angeboten ist die Grösse bzw. Gästekapazität der Unterkunft – gemessen an der maximalen Anzahl von Personen, die eine Unterkunft gleichzeitig beherbergen kann (accommodates). Das folgende Balkendiagramm untersucht, wie sich die durchschnittliche jährliche Verfügbarkeit in Abhängigkeit dieser Kapazität verändert."
   ]
  },
  {
   "cell_type": "code",
   "id": "b9685a38",
   "metadata": {},
   "source": [
    "# Daten vorbereiten\n",
    "df = listings_df[\n",
    "    (listings_df[\"accommodates\"].notnull()) &\n",
    "    (listings_df[\"availability_365\"].notnull()) &\n",
    "    (listings_df[\"accommodates\"] > 0)\n",
    "]\n",
    "\n",
    "# Aggregation und Sortierung nach Verfügbarkeit (absteigend)\n",
    "availability_stats = df.groupby(\"accommodates\")[\"availability_365\"].mean().reset_index()\n",
    "availability_stats_sorted = availability_stats.sort_values(by=\"availability_365\", ascending=False)\n",
    "\n",
    "# Plot in fig5 speichern\n",
    "fig5, ax = plt.subplots(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    data=availability_stats_sorted,\n",
    "    x=\"accommodates\",\n",
    "    y=\"availability_365\",\n",
    "    color=\"#5DADE2\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Balkenbeschriftung\n",
    "for index, row in availability_stats_sorted.iterrows():\n",
    "    ax.text(\n",
    "        x=index,\n",
    "        y=row[\"availability_365\"] + 5,\n",
    "        s=f\"{row['availability_365']:.0f} Tage\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=9,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# Layout\n",
    "ax.set_title(\"Durchschnittliche Verfügbarkeit nach Unterkunftskapazität\", fontsize=14)\n",
    "ax.set_xlabel(\"Maximale Gästeanzahl (accommodates)\")\n",
    "ax.set_ylabel(\"Ø Verfügbarkeit (Tage/Jahr)\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "fig5.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff6c11fd",
   "metadata": {},
   "source": [
    "**Interpretation der Visualisierung:**\n",
    "\n",
    "Die Balkengrafik zeigt auf den ersten Blick ein nicht-lineares Muster\n",
    "- Listings mit einer Kapazität von 8 Personen (115 Tage) und 6 Personen (134 Tage) sind im Durchschnitt am wenigsten verfügbar – was auf eine sehr hohe Nachfrage und häufige Buchungen schliessen lässt.\n",
    "- Ebenfalls vergleichsweise niedrige Verfügbarkeiten zeigen sich bei Unterkünften für 1–2 Gäste (ca. 187–188 Tage), was auf konstant gute Auslastung bei kleinen Einheiten hindeutet.\n",
    "- Deutlich höhere Verfügbarkeiten zeigen sich hingegen bei Kapazitäten von 7 Gästen (254 Tage) und vor allem bei sehr grossen Unterkünften mit 14 Gästen (289 Tage) – hier scheint die Nachfrage (relativ zur Angebotskapazität) geringer oder die Zielgruppe eingeschränkt zu sein.\n",
    "- Mittelgrosse Kapazitäten (z.B. 3–5 Gäste) weisen eine ausgeglichene Verfügbarkeit im Bereich von 200–217 Tagen auf – ein Zeichen für solide, aber nicht überdurchschnittliche Nachfrage.\n",
    "\n",
    "Die Daten deuten darauf hin, dass vor allem Unterkünfte mit mittlerer bis hoher Kapazität (6–8 Gäste) besonders stark nachgefragt werden – wie anhand ihrer niedrigen durchschnittlichen Verfügbarkeit ersichtlich ist. Dies könnte daran liegen, dass diese Objekte ideal für Familien, kleine Gruppen oder Geschäftsreiseteams sind – also Zielgruppen mit überdurchschnittlicher Buchungshäufigkeit\n",
    "\n",
    "Für die InvestZurich AG ergeben sich aus der Analyse der Unterkunftskapazitäten konkrete strategische Implikationen. Besonders attraktiv erscheinen Investitionen in Immobilien mit einer Kapazität für 6 bis 8 Personen, da diese Einheiten im Durchschnitt am häufigsten gebucht werden und somit eine besonders hohe Auslastung aufweisen. Auch kleinere Objekte für 1 bis 2 Gäste bleiben relevant, da sie eine solide Nachfrage zeigen und im Markt weit verbreitet sind – sie bieten insbesondere für Alleinreisende oder Paare eine geeignete Unterkunftsform. Mit Vorsicht zu bewerten sind hingegen sehr grosse Unterkünfte, etwa mit einer Kapazität für 14 Personen. Obwohl diese Angebote am Markt verfügbar sind, deutet ihre vergleichsweise hohe Verfügbarkeit darauf hin, dass sie seltener gebucht werden und somit ein erhöhtes Auslastungsrisiko bergen.\n",
    "\n",
    "### Klassifikation von Top Performern mittels Random Forest\n",
    "Um potenziell erfolgreiche Airbnb-Angebote systematisch identifizieren zu können, wurde ein Klassifikationsmodell auf Basis eines Random Forest Algorithmus entwickelt. Ziel war es, sogenannte Top Performer zu erkennen – also Angebote, die sowohl hinsichtlich ihres Preises als auch ihrer Anzahl an Bewertungen über dem Median liegen. Diese Kombination wurde als Indikator für wirtschaftlich erfolgreiche und gleichzeitig nachgefragte Angebote interpretiert.\n",
    "\n",
    "Die Modellierung erfolgte in mehreren Schritten. Zunächst wurde das zugrunde liegende Datenset bereinigt und nur solche Einträge berücksichtigt, die vollständige Informationen zu Preis, Raumanzahl, Badezimmern, Unterkunftskapazität, Unterkunftstyp und Lage enthielten. Anschliessend wurde die Zielvariable top_performer binär kodiert: Ein Listing erhielt den Wert 1, wenn sowohl Preis als auch Anzahl der Bewertungen über dem jeweiligen Median lagen; andernfalls wurde es mit 0 klassifiziert.\n",
    "\n",
    "Als erklärende Merkmale wurden fünf Variablen ausgewählt: accommodates, bedrooms, bathrooms, room_type sowie neighbourhood_group_cleansed. Kategorische Variablen wurden mittels Label-Encoding numerisch transformiert, bevor das Modell mit einem RandomForestClassifier (100 Bäume) trainiert wurde. Die Daten wurden im Verhältnis 70% zu 30% in Trainings- und Testdaten aufgeteilt.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8c094945",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Daten vorbereiten\n",
    "df = listings_df.copy()\n",
    "\n",
    "# Filter und Bereinigung\n",
    "df = df[\n",
    "    (df[\"price\"] > 0) & (df[\"price\"] < 1000) &\n",
    "    (df[\"number_of_reviews\"].notnull()) &\n",
    "    (df[\"bedrooms\"].notnull()) &\n",
    "    (df[\"bathrooms\"].notnull()) &\n",
    "    (df[\"accommodates\"].notnull()) &\n",
    "    (df[\"room_type\"].notnull()) &\n",
    "    (df[\"neighbourhood_group_cleansed\"].notnull())\n",
    "]\n",
    "\n",
    "# Zielvariable konstruieren (Top Performer = Preis und Reviews über Median)\n",
    "df[\"top_performer\"] = (\n",
    "    (df[\"price\"] > df[\"price\"].median()) &\n",
    "    (df[\"number_of_reviews\"] > df[\"number_of_reviews\"].median())).astype(int)\n",
    "\n",
    "# Feature-Auswahl\n",
    "features = [\n",
    "    \"accommodates\", \"bedrooms\", \"bathrooms\",\n",
    "    \"room_type\", \"neighbourhood_group_cleansed\"\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[\"top_performer\"]\n",
    "\n",
    "# Kategorische Variablen encodieren\n",
    "le_room = LabelEncoder()\n",
    "le_neigh = LabelEncoder()\n",
    "X[\"room_type\"] = le_room.fit_transform(X[\"room_type\"])\n",
    "X[\"neighbourhood_group_cleansed\"] = le_neigh.fit_transform(X[\"neighbourhood_group_cleansed\"])\n",
    "\n",
    "# Train/Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance visualisieren\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "fig6, ax = plt.subplots(figsize=(10,6))\n",
    "sns.barplot(\n",
    "    x=importances.values,\n",
    "    y=importances.index,\n",
    "    color=\"#5DADE2\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(\"Feature Importance\")\n",
    "ax.set_ylabel(\"Merkmale\")\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "fig6.tight_layout()\n",
    "\n",
    "# Confusion Matrix\n",
    "fig7, ax = plt.subplots(figsize=(6,6))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=14)\n",
    "ax.grid(False)\n",
    "fig7.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0df91d63",
   "metadata": {},
   "source": [
    "Das Modell erzielte auf dem Testdatensatz eine Gesamtgenauigkeit von 85%. Der F1-Score für die Klasse der Top Performer (1) lag bei 0.59, während die Klasse der Nicht-Performer (0) einen deutlich höheren F1-Score von 0.91 erreichte. Diese Differenz verdeutlicht, dass das Modell besonders gut darin ist, weniger erfolgreiche Angebote zu erkennen, während die Identifikation von Top Performern anspruchsvoller bleibt. Die Confusion Matrix zeigt, dass 17 der 30 tatsächlichen Top Performer korrekt vorhergesagt wurden, während 13 nicht erkannt wurden. Gleichzeitig wurden 11 Objekte fälschlicherweise als Top Performer klassifiziert.\n",
    "\n",
    "Besonders aufschlussreich ist die Analyse der Merkmalswichtigkeit im Modell: Das wichtigste Kriterium für die Klassifikation war die Unterkunftskapazität (accommodates), gefolgt von der Lage (neighbourhood_group_cleansed) und der Anzahl der Schlafzimmer. Geringere Bedeutung hatten dagegen die Anzahl der Badezimmer sowie der Unterkunftstyp.\n",
    "\n",
    "Diese Ergebnisse bestätigen die vorherigen Analysen der Nachfrageverteilung: Erfolgreiche Airbnb-Angebote sind häufig in der Lage, mehrere Gäste zu beherbergen und befinden sich in bestimmten, gefragten Stadtteilen. Das Random Forest Modell bietet somit eine fundierte Grundlage, um Investitionsentscheidungen datenbasiert zu unterstützen. Es kann als ergänzendes Werkzeug dienen, um Immobilienangebote frühzeitig auf ihr Potenzial zur erfolgreichen Kurzzeitvermietung hin zu prüfen. Weiteres Optimierungspotenzial besteht durch die Integration zusätzlicher Einflussfaktoren wie z.B. Ausstattung, Bewertungsscores oder saisonale Schwankungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93893b",
   "metadata": {},
   "source": [
    "## Objective 2 – Preisstrategie & Ertragsprognose\n",
    "\n",
    "Analyse der Preistreiber und Erstellung eines Regressionsmodells zur Quantifizierung des Einflusses verschiedener Merkmale auf den Preis `price`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Aufbereitung der Immobilienverkaufsdaten aus `SellingPrices`\n",
    "`selling_prices_df` wurde bereits in \"Step 2\" geladen und inspiziert. Wir führen nun die Aggregation durch."
   ],
   "id": "39c0fb4c62aa435d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'selling_prices_df' in locals() or 'selling_prices_df' in globals():\n",
    "    if not selling_prices_df.empty:\n",
    "        # Stelle sicher, dass die relevanten Spalten vorhanden sind\n",
    "        required_columns_sp = ['raumlang', 'hapreiswohnflaeche']\n",
    "        if all(col in selling_prices_df.columns for col in required_columns_sp):\n",
    "\n",
    "            # Kopie erstellen, um SettingWithCopyWarning zu vermeiden\n",
    "            processed_selling_prices_df = selling_prices_df.copy()\n",
    "\n",
    "            # Konvertiere 'hapreiswohnflaeche' in einen numerischen Typ, Fehler werden zu NaN\n",
    "            processed_selling_prices_df['hapreiswohnflaeche'] = pd.to_numeric(processed_selling_prices_df['hapreiswohnflaeche'], errors='coerce')\n",
    "\n",
    "            # Entferne Zeilen, bei denen 'raumlang' (Quartier) oder 'hapreiswohnflaeche' (Preis pro m²) NaN ist\n",
    "            # oder 'raumlang' leer ist.\n",
    "            processed_selling_prices_df.dropna(subset=['raumlang', 'hapreiswohnflaeche'], inplace=True)\n",
    "            # Entferne Zeilen, wo 'raumlang' nur aus Leerzeichen besteht oder leer ist\n",
    "            processed_selling_prices_df = processed_selling_prices_df[processed_selling_prices_df['raumlang'].str.strip() != '']\n",
    "\n",
    "\n",
    "            # Gruppiere nach 'raumlang' (Quartier) und berechne den Median von 'hapreiswohnflaeche'\n",
    "            selling_prices_agg_df = processed_selling_prices_df.groupby('raumlang')['hapreiswohnflaeche'].median().reset_index()\n",
    "\n",
    "            # Umbenennen der Spalten für bessere Lesbarkeit und Konsistenz\n",
    "            selling_prices_agg_df.rename(columns={\n",
    "                'raumlang': 'Quartier', # Dies ist der Name des Quartiers aus den Verkaufsdaten\n",
    "                'hapreiswohnflaeche': 'Median_Preis_pro_m2_Quartier'\n",
    "            }, inplace=True)\n",
    "\n",
    "            print(\"Aggregierte Immobilienpreise pro Quartier (Median Preis pro m²)\")\n",
    "            print(selling_prices_agg_df.head())\n",
    "\n",
    "            # Überprüfen auf fehlende Werte im aggregierten DataFrame\n",
    "            print(\"\\nFehlende Werte in selling_prices_agg_df:\")\n",
    "            print(selling_prices_agg_df.isnull().sum())\n",
    "        else:\n",
    "            print(f\"Fehler: Die erforderlichen Spalten ({', '.join(required_columns_sp)}) wurden nicht im DataFrame 'selling_prices_df' gefunden.\")\n",
    "            print(\"Vorhandene Spaltennamen in selling_prices_df:\", selling_prices_df.columns)\n",
    "else:\n",
    "    print(\"Der DataFrame 'selling_prices_df' aus Step 2 ist leer.\")"
   ],
   "id": "c657947af287218",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Aufbereitung der Airbnb aus `Listings` für die Ertragsanalyse\n",
    "Jetzt kümmern wir uns um die Ertragsseite. Wir verwenden deinen bereits in \"Step 2\" aufbereiteten DataFrame `df_analysis` (die Arbeitskopie von `listings_df`). Ziel ist es, die potenziellen jährlichen Einnahmen pro Airbnb-Angebot zu schätzen und diese dann pro Quartier zu aggregieren.\n",
    "\n",
    "**Die relevanten Spalten in `df_analysis` sind:**\n",
    "- Die definierte Standortspalte (gespeichert in der Variable `loc_col_for_analysis_notebook`)\n",
    "- `price` (Preis pro Nacht)\n",
    "- `availability_365` (Verfügbarkeit über 365 Tage), woraus wir eine Schätzung für die Belegung ableiten können"
   ],
   "id": "8633fd1fbe5770bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df_analysis wurde bereits in deinem \"Step 2\" des Notebooks umfassend vorbereitet.\n",
    "# loc_col_for_analysis_notebook wurde in deinem \"Step 2\" definiert und enthält den Namen der relevanten Standortspalte.\n",
    "\n",
    "if 'df_analysis' in locals() or 'df_analysis' in globals():\n",
    "    if not df_analysis.empty:\n",
    "        # Stelle sicher, dass die relevante Standortspalte und Preisspalte existieren\n",
    "        # loc_col_for_analysis_notebook sollte aus deinem vorherigen Code-Teil verfügbar sein.\n",
    "        # Falls nicht, musst du sie hier erneut definieren oder sicherstellen, dass sie global ist.\n",
    "        # Beispiel: loc_col_for_analysis_notebook = 'neighbourhood_cleansed' # oder was auch immer es war\n",
    "\n",
    "        # Überprüfe, ob die Variable loc_col_for_analysis_notebook existiert\n",
    "        if 'loc_col_for_analysis_notebook' not in locals() and 'loc_col_for_analysis_notebook' not in globals():\n",
    "            print(\"Fehler: Variable 'loc_col_for_analysis_notebook' ist nicht definiert. Bitte stelle sicher, dass sie aus Step 2 übernommen wurde.\")\n",
    "            # Definiere einen Fallback oder brich ab, je nach Anforderung\n",
    "            # loc_col_for_analysis_notebook = 'neighbourhood_cleansed' # Beispiel-Fallback\n",
    "\n",
    "        required_cols_airbnb = [loc_col_for_analysis_notebook, 'price', 'availability_365']\n",
    "        if all(col in df_analysis.columns for col in required_cols_airbnb):\n",
    "\n",
    "            airbnb_revenue_df = df_analysis.copy()\n",
    "\n",
    "            # Bereinigung und Konvertierung für die Berechnung\n",
    "            airbnb_revenue_df['price'] = pd.to_numeric(airbnb_revenue_df['price'], errors='coerce')\n",
    "            airbnb_revenue_df['availability_365'] = pd.to_numeric(airbnb_revenue_df['availability_365'], errors='coerce')\n",
    "\n",
    "            # Entferne Einträge, wo Preis oder Verfügbarkeit NaN sind oder Standort leer ist\n",
    "            airbnb_revenue_df.dropna(subset=[loc_col_for_analysis_notebook, 'price', 'availability_365'], inplace=True)\n",
    "            airbnb_revenue_df = airbnb_revenue_df[airbnb_revenue_df[loc_col_for_analysis_notebook].astype(str).str.strip() != '']\n",
    "\n",
    "            # Berechnung der geschätzten jährlichen Einnahmen pro Listing\n",
    "            # Annahme: Tage, an denen das Listing NICHT verfügbar ist (availability_365), sind gebuchte Tage.\n",
    "            # Dies ist eine Vereinfachung, da Tage auch geblockt sein könnten.\n",
    "            # Eine konservativere Annahme für die Belegung wäre z.B. 50% der verfügbaren Tage oder (365-availability_365)\n",
    "            # Hier verwenden wir (365 - availability_365) als Schätzung für gebuchte Tage.\n",
    "            # Wir stellen sicher, dass gebuchte Tage nicht negativ werden, falls availability_365 > 365 (sollte nicht sein)\n",
    "            airbnb_revenue_df['estimated_booked_days_yearly'] = (365 - airbnb_revenue_df['availability_365']).clip(lower=0)\n",
    "            airbnb_revenue_df['estimated_yearly_revenue'] = airbnb_revenue_df['price'] * airbnb_revenue_df['estimated_booked_days_yearly']\n",
    "\n",
    "            # Einige Listings könnten einen Preis von 0 haben oder 0 gebuchte Tage, was zu 0 Einnahmen führt.\n",
    "            # Überprüfe, ob estimated_yearly_revenue valide Werte hat (nicht negativ)\n",
    "            airbnb_revenue_df = airbnb_revenue_df[airbnb_revenue_df['estimated_yearly_revenue'] >= 0]\n",
    "\n",
    "            # Aggregation der geschätzten jährlichen Einnahmen pro Quartier (Median)\n",
    "            # Wir verwenden hier den Median, um Ausreissern weniger Gewicht zu geben.\n",
    "            airbnb_revenue_agg_df = airbnb_revenue_df.groupby(loc_col_for_analysis_notebook)['estimated_yearly_revenue'].median().reset_index()\n",
    "\n",
    "            airbnb_revenue_agg_df.rename(columns={\n",
    "                loc_col_for_analysis_notebook: 'Quartier', # Umbenennung für Konsistenz beim Mergen\n",
    "                'estimated_yearly_revenue': 'Median_Estimated_Yearly_Revenue_Airbnb'\n",
    "            }, inplace=True)\n",
    "\n",
    "            print(\"\\nAggregierte geschätzte jährliche Airbnb-Einnahmen pro Quartier (Median)\")\n",
    "            print(airbnb_revenue_agg_df.head())\n",
    "\n",
    "            print(f\"\\nAnzahl der Quartiere im Airbnb-Ertrags-DataFrame: {airbnb_revenue_agg_df.shape[0]}\")\n",
    "\n",
    "            print(\"\\nFehlende Werte in airbnb_revenue_agg_df:\")\n",
    "            print(airbnb_revenue_agg_df.isnull().sum())\n",
    "else:\n",
    "    print(\"Der DataFrame 'df_analysis' wurde in Step 2 nicht definiert oder ist nicht zugänglich.\")"
   ],
   "id": "2ef1ce51179204f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zusammenführen der Datensätze\n",
    "In diesem Schritt werden wir `selling_prices_agg_df` und `airbnb_revenue_agg_df` über die gemeinsame Spalte `Quartier` zusammenführen."
   ],
   "id": "c9a4e26097bb3442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# selling_prices_agg_df und airbnb_revenue_agg_df sollten nun existieren.\n",
    "if ('selling_prices_agg_df' in locals() or 'selling_prices_agg_df' in globals()) and \\\n",
    "   ('airbnb_revenue_agg_df' in locals() or 'airbnb_revenue_agg_df' in globals()):\n",
    "\n",
    "    if not selling_prices_agg_df.empty and not airbnb_revenue_agg_df.empty:\n",
    "\n",
    "        # Zusammenführen der beiden DataFrames über die Spalte 'Quartier'\n",
    "        # Wir verwenden einen 'inner' Merge, um nur Quartiere zu behalten, für die wir beide Arten von Daten haben.\n",
    "        # Alternativ könnte man 'outer' verwenden und die fehlenden Werte später behandeln.\n",
    "        combined_analysis_df = pd.merge(selling_prices_agg_df, airbnb_revenue_agg_df, on='Quartier', how='inner')\n",
    "\n",
    "        print(\"Kombinierter DataFrame aus Immobilienpreisen und Airbnb-Erträgen\")\n",
    "        print(combined_analysis_df.head())\n",
    "\n",
    "        print(f\"\\nShape des kombinierten DataFrames: {combined_analysis_df.shape}\")\n",
    "        print(f\"Dies bedeutet, wir haben für {combined_analysis_df.shape[0]} Quartiere sowohl Preis- als auch Ertragsdaten.\")\n",
    "\n",
    "        print(\"\\nFehlende Werte im combined_analysis_df:\")\n",
    "        print(combined_analysis_df.isnull().sum())\n",
    "\n",
    "        # Kurze Überprüfung der Datentypen, um sicherzustellen, dass die numerischen Spalten korrekt sind\n",
    "        print(\"\\nDatentypen im combined_analysis_df:\")\n",
    "        print(combined_analysis_df.dtypes)\n",
    "\n",
    "    else:\n",
    "        print(\"Einer der DataFrames (selling_prices_agg_df oder airbnb_revenue_agg_df) ist leer.\")\n",
    "else:\n",
    "    print(\"selling_prices_agg_df oder airbnb_revenue_agg_df wurde nicht gefunden.\")"
   ],
   "id": "45e0f4a25dc0f994",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rentabilitätsanalyse\n",
    "\n",
    "In diesem Schritt werden wir anhand des zusammengeführten DataFrame `combined_analysis_df` eine **Rentabilitätskennzahl** berechnen, um die Quartiere direkter vergleichen zu können. Wir nennen sie `Revenue_Yield_Proxy`. Sie wird als das Verhältnis der medianen jährlichen Airbnb-Einnahmen zum medianen Quadratmeterpreis der Immobilie berechnet. Ein höherer Wert dieser Kennzahl deutet auf eine potenziell bessere Rentabilität hin (höhere Einnahmen im Verhältnis zum Preis pro m²)."
   ],
   "id": "3693198a3f251044"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combined_analysis_df sollte nun existieren.\n",
    "# Wir benötigen auch matplotlib und seaborn für die Visualisierungen.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # Für den Fall, dass wir Inf-Werte behandeln müssen\n",
    "\n",
    "if 'combined_analysis_df' in locals() or 'combined_analysis_df' in globals():\n",
    "    if not combined_analysis_df.empty:\n",
    "\n",
    "        # Berechnung der Rentabilitätskennzahl (Revenue Yield Proxy)\n",
    "        # Dieser Proxy gibt an, wie viel des Quadratmeterpreises potenziell durch jährliche Airbnb-Einnahmen \"gedeckt\" wird.\n",
    "        # Wir müssen sicherstellen, dass Median_Preis_pro_m2_Quartier nicht Null ist, um DivisionByZeroError zu vermeiden.\n",
    "        if (combined_analysis_df['Median_Preis_pro_m2_Quartier'] == 0).any():\n",
    "            print(\"Warnung: Einige Quartiere haben einen Median_Preis_pro_m2_Quartier von 0. Diese werden NaN/Inf in der Renditekennzahl ergeben.\")\n",
    "\n",
    "        # Ersetze 0 im Nenner temporär durch NaN, um Inf zu vermeiden, und fülle dann ggf. mit 0 oder behandle es.\n",
    "        # In diesem Fall ist es unwahrscheinlich, dass der Preis 0 ist, aber eine gute Praxis.\n",
    "        combined_analysis_df['Revenue_Yield_Proxy'] = combined_analysis_df['Median_Estimated_Yearly_Revenue_Airbnb'] / combined_analysis_df['Median_Preis_pro_m2_Quartier'].replace(0, np.nan)\n",
    "\n",
    "        # Falls durch die obige Ersetzung NaNs entstanden sind (weil Preis 0 war), könnten wir sie mit 0 füllen.\n",
    "        # combined_analysis_df['Revenue_Yield_Proxy'].fillna(0, inplace=True)\n",
    "\n",
    "        # --- Visualisierung ---\n",
    "\n",
    "        # a) Balkendiagramm für den Revenue_Yield_Proxy pro Quartier\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Revenue_Yield_Proxy', y='Quartier', data=combined_analysis_sorted_df, palette='viridis')\n",
    "        plt.title('Potenzielle Rentabilität (Revenue Yield Proxy) nach Quartier')\n",
    "        plt.xlabel('Revenue Yield Proxy (Median Jährl. Airbnb-Ertrag / Median Preis pro m²)')\n",
    "        plt.ylabel('Quartier')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"DataFrame mit Rentabilitätskennzahl (Revenue_Yield_Proxy)\")\n",
    "        # Sortieren nach der neuen Kennzahl, um die \"Top\"-Quartiere zu sehen\n",
    "        combined_analysis_sorted_df = combined_analysis_df.sort_values(by='Revenue_Yield_Proxy', ascending=False)\n",
    "        print(combined_analysis_sorted_df)\n",
    "\n",
    "    else:\n",
    "        print(\"Der DataFrame 'combined_analysis_df' ist leer.\")\n",
    "else:\n",
    "    print(\"Der DataFrame 'combined_analysis_df' wurde nicht gefunden.\")"
   ],
   "id": "1d633da10a3a219c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Das Balkendiagramm `Potenzielle Rentabilität (Revenue Yield Proxy) nach Quartier` visualisiert das Ranking aus dem sortierten DataFrame. Kreis 12 ist klar als Quartier mit dem höchsten Revenue_Yield_Proxy zu erkennen, gefolgt von Kreis 4 und Kreis 6. Die Grafik macht die Unterschiede in der potenziellen Rentabilität zwischen den Quartieren sehr deutlich und ist ideal, um die attraktivsten Standorte schnell zu identifizieren.\n",
    "\n",
    "Der DataFrame `combined_analysis_sorted_df` zeigt die 12 Quartiere, für die wir vollständige Daten haben, sortiert nach dem `Revenue_Yield_Proxy` in absteigender Reihenfolge. Diese Kennzahl stellt das Verhältnis der medianen geschätzten jährlichen Airbnb-Einnahmen zum medianen Quadratmeterpreis der Immobilien dar. Ein höherer Wert ist hier potenziell besser.\n",
    "\n",
    "**Spitzenreiter:** `Kreis 12` weist mit einem `Revenue_Yield_Proxy` von ca. 3.78 den höchsten Wert auf. Das bedeutet, dass hier die geschätzten jährlichen Airbnb-Einnahmen im Verhältnis zum Quadratmeterpreis am höchsten sind. Dies könnte auf relativ moderate Immobilienpreise bei gleichzeitig guten Einnahmemöglichkeiten hindeuten.\n",
    "\n",
    "**Weitere attraktive Quartiere:** `Kreis 4` (ca. 2.66) und `Kreis 6` (ca. 2.58) folgen dahinter und zeigen ebenfalls ein überdurchschnittlich gutes Verhältnis von Einnahmen zu Immobilienpreisen.\n",
    "\n",
    "**Mittelfeld:** Quartiere wie `Kreis 2`, `Kreis 10` und `Kreis 3` bewegen sich im Mittelfeld mit Werten zwischen ca. 2.31 und 2.35.\n",
    "\n",
    "**Unteres Ende:** `Kreis 1` hat mit ca. 1.60 den niedrigsten `Revenue_Yield_Proxy`. Dies ist nicht überraschend, da `Kreis 1` bekanntermassen sehr hohe Immobilienpreise hat (Altstadt), die durch die Airbnb-Einnahmen (obwohl absolut gesehen auch hoch) verhältnismässig weniger stark \"aufgefangen\" werden. Auch `Kreis 9` und `Kreis 7` zeigen hier vergleichsweise niedrigere Werte."
   ],
   "id": "569a87a66d0637e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Korrelationsanalyse Immobilienpreis vs. Airbnb-Einnahmen\n",
    "\n",
    "In diesem weiterführenden Schritt werden wir die Korrelation zwischen den Immobilienpreisen und den Airbnb-Einnahmen untersuchen."
   ],
   "id": "7a5bfba30a2e2670"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "        # Korrelationsanalyse\n",
    "        correlation_matrix = combined_analysis_df[['Median_Preis_pro_m2_Quartier', 'Median_Estimated_Yearly_Revenue_Airbnb', 'Revenue_Yield_Proxy']].corr()\n",
    "        print(\"\\nKorrelationsmatrix:\")\n",
    "        print(correlation_matrix)\n",
    "\n",
    "        # --- Visualisierungen ---\n",
    "\n",
    "        # b) Streudiagramm: Immobilienpreise vs. Airbnb-Einnahmen\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.scatterplot(x='Median_Preis_pro_m2_Quartier', y='Median_Estimated_Yearly_Revenue_Airbnb', hue='Quartier', size='Revenue_Yield_Proxy', sizes=(50,500), data=combined_analysis_df, legend='brief', palette='muted')\n",
    "        plt.title('Immobilienpreise pro m² vs. Geschätzte jährliche Airbnb-Einnahmen')\n",
    "        plt.xlabel('Median Preis pro m² (CHF)') # Annahme Euro, anpassen falls andere Währung\n",
    "        plt.ylabel('Median geschätzte jährl. Airbnb-Einnahmen (CHF)')\n",
    "        plt.grid(True)\n",
    "        # Legende ausserhalb des Plots platzieren, um Überlappung zu vermeiden\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout(rect=[0,0,0.85,1]) # Platz für Legende schaffen\n",
    "        plt.show()"
   ],
   "id": "490c8cda5f460af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Immobilienpreis vs. Airbnb-Einnahmen:**\n",
    "- `Median_Preis_pro_m2_Quartier` und `Median_Estimated_Yearly_Revenue_Airbnb` weisen eine Korrelation von ca. 0.30 auf.\n",
    "- Es besteht eine schwache positive Korrelation. Das heisst, es gibt eine leichte Tendenz, dass in Quartieren mit höheren Immobilienpreisen auch tendenziell höhere Airbnb-Einnahmen erzielt werden. Der Zusammenhang ist jedoch nicht stark ausgeprägt, was darauf hindeutet, dass hohe Immobilienpreise nicht automatisch die höchsten Airbnb-Erträge garantieren.\n",
    "\n",
    "Das Streudiagramm `Immobilienpreise pro m² vs. Geschätzte jährliche Airbnb-Einnahmen` positioniert die Quartiere im Preis-Ertrags-Raum.\n",
    "- `Kreis 1` befindet sich oben rechts: höchste Preise und hohe (aber nicht die höchsten) Einnahmen.\n",
    "- `Kreis 12` sticht heraus: Es hat nicht die niedrigsten Immobilienpreise, aber die höchsten medianen Airbnb-Einnahmen im Datensatz, was zu seiner führenden Position beim `Revenue_Yield_Proxy` führt.\n",
    "- Die Punktgrösse, die den `Revenue_Yield_Proxy` darstellt, unterstreicht visuell, welche Quartiere relativ zu ihrem Preisniveau hohe Einnahmen generieren (grössere Blasen sind hier besser). `Kreis 12` sollte hier die grösste Blase haben.\n",
    "Man kann Cluster oder Ausreisser erkennen und die allgemeine Verteilung besser verstehen.\n",
    "\n",
    "**Immobilienpreis vs. Rentabilitätskennzahl:**\n",
    "- `Median_Preis_pro_m2_Quartier` und `Revenue_Yield_Proxy` weisen eine Korrelation von ca. -0.48 auf.\n",
    "- Hier zeigt sich eine moderate negative Korrelation. Dies bedeutet, dass mit steigenden Quadratmeterpreisen der `Revenue_Yield_Proxy tendenziell sinkt. Sehr teure Quartiere haben es also schwerer, einen hohen relativen \"Ertrag\" im Sinne unserer Kennzahl zu erzielen, da die hohen Preise die Einnahmen stark relativieren.\n",
    "\n",
    "**Airbnb-Einnahmen vs. Rentabilitätskennzahl:**\n",
    "- `Median_Estimated_Yearly_Revenue_Airbnb` und `Revenue_Yield_Proxy` weisen eine Korrelation von ca. 0.67 auf.\n",
    "`Diese moderate bis starke positive Korrelation ist logisch. Höhere absolute Airbnb-Einnahmen führen ceteris paribus (bei gleichbleibenden Preisen) zu einem besseren (höheren) Revenue_Yield_Proxy. Dies unterstreicht, dass hohe Einnahmen ein wichtiger Treiber für die Rentabilität sind, aber immer im Kontext der Immobilienpreise gesehen werden müssen."
   ],
   "id": "9de48b70afb2ae3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "        # c) Heatmap der Korrelationsmatrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "        plt.title('Korrelationsmatrix der Schlüsselmetriken')\n",
    "        plt.show()"
   ],
   "id": "70197236312d793c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Die Headmap `Korrelationsmatrix der Schlüsselmetriken` ist die grafische Darstellung der zuvor diskutierten Korrelationsmatrix.\n",
    "\n",
    "*Rottöne zeigen positive Korrelationen, Blautöne negative. Die Intensität der Farbe spiegelt die Stärke der Korrelation wider.*\n",
    "\n",
    "**Die Heatmap bestätigt visuell:**\n",
    "- Die moderate negative Korrelation (bläulich) zwischen `Median_Preis_pro_m2_Quartier` und `Revenue_Yield_Proxy`.\n",
    "- Die moderate bis starke positive Korrelation (rötlich) zwischen `Median_Estimated_Yearly_Revenue_Airbnb` und `Revenue_Yield_Proxy`.\n",
    "- Die schwach positive Korrelation (leicht rötlich) zwischen `Median_Preis_pro_m2_Quartier` und `Median_Estimated_Yearly_Revenue_Airbnb`.\n",
    "- Die Heatmap macht es einfach, die wichtigsten Zusammenhänge auf einen Blick zu erfassen, ohne die Zahlen direkt lesen zu müssen."
   ],
   "id": "9c976a736b048cb0"
  },
  {
   "cell_type": "markdown",
   "id": "7507721d",
   "metadata": {},
   "source": [
    "## Objective 3 – Performance Optimierung & Benchmarking\n",
    "\n",
    "Ziel dieses Untersuchungsabschnitts ist es, die zentralen Erfolgsfaktoren für den Superhost-Status auf Airbnb datenbasiert zu identifizieren. Im Fokus steht die Frage, welche quantifizierbaren Merkmale Top-Performer (Superhosts) von anderen Gastgebern im Raum Zürich unterscheiden – und wie die InvestZurich AG diese Erkenntnisse gezielt zur Optimierung ihrer eigenen Objekte nutzen kann.\n",
    "\n",
    "Der Superhost-Status ist ein Qualitätssiegel innerhalb des Airbnb-Ökosystems, das mit höherer Sichtbarkeit, gesteigerter Buchungswahrscheinlichkeit und verbessertem Gästevertrauen einhergeht. Für professionelle Anbieter wie die InvestZurich AG stellt dieser Status daher einen strategisch bedeutsamen Wettbewerbsvorteil dar.\n",
    "\n",
    "In einem ersten Schritt wird untersucht, welche Eigenschaften (z.B. Antwortzeit, Buchungsannahmequote, Bewertungsniveau oder Gastgeberaktivität) statistisch signifikant mit dem Superhost-Status korrelieren. Anschliessend werden mittels Klassifikationsmodellen – wie etwa Entscheidbäumen oder Random Forests – die einflussreichsten Prädiktoren herausgearbeitet.\n",
    "\n",
    "Das Ziel besteht darin, auf Grundlage dieser Daten konkrete Handlungspfade für die InvestZurich AG abzuleiten, etwa zur Verbesserung von Gastgebermetriken oder zur internen Qualitätssicherung. Der Fokus liegt dabei nicht nur auf reiner Leistungsdiagnostik, sondern auf einer operationalisierbaren Optimierungsstrategie.\n",
    "?\n",
    "\n",
    "Die nachfolgende Analyse visualisiert zentrale Merkmale, die signifikant mit dem Superhost-Status zusammenhängen – und bildet damit die Grundlage für gezielte Massnahmen zur Performance-Steigerung.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c96e6aeb",
   "metadata": {},
   "source": [
    "from airbnb_analysis_service import AirbnbAnalysisService\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # create service class\n",
    "    airbnbAnalysis = AirbnbAnalysisService()\n",
    "\n",
    "    # get all tables in form of a list\n",
    "    listings = airbnbAnalysis.get_listings()\n",
    "\n",
    "    print(f\"listings {listings[0]}\")\n",
    "\n",
    "    # Schritt 1: Umwandeln in DataFrames\n",
    "    listings_df = pd.DataFrame([l.__dict__ for l in listings])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7da8f2eb",
   "metadata": {},
   "source": [
    "### Datenaufbereitung\n",
    "\n",
    "Im Rahmen der Datenaufbereitung wurden zunächst 22 relevante Merkmale ausgewählt, die potenziell Einfluss auf den Superhost-Status haben. Dazu zählen hostbezogene Informationen (z. B. Antwortzeit, Annahmequote, Verifizierung), Objektmerkmale (wie Zimmeranzahl, Preis, Mindestaufenthalt) sowie Bewertungskennzahlen und Aktivitätsindikatoren (z. B. Anzahl Bewertungen pro Monat, durchschnittliche Bewertung).\n",
    "\n",
    "Prozentangaben wie die Antwort- und Annahmequote wurden in dezimale Werte umgewandelt, um sie numerisch auswerten zu können. Anschliessend wurden alle Datensätze mit fehlendem Superhost-Status entfernt, um eine saubere Klassifikationsbasis zu schaffen. Der Zielwert wurde anschliessend in eine binäre Variable überführt (1 = Superhost, 0 = Nicht-Superhost).\n",
    "\n",
    "Fehlende numerische Werte wurden mit dem Median der jeweiligen Spalte ersetzt, um Ausreisserverzerrungen zu vermeiden. Schliesslich wurden ausgewählte kategoriale Merkmale, darunter etwa die Zimmerart oder Buchbarkeit, mittels Label Encoding in numerische Kategorien umgewandelt, sodass sie für maschinelles Lernen geeignet sind."
   ]
  },
  {
   "cell_type": "code",
   "id": "c1a894be",
   "metadata": {},
   "source": [
    "cols = [\n",
    "    'host_is_superhost', 'host_response_time', 'host_response_rate',\n",
    "    'host_acceptance_rate_percent', 'host_total_listings_count', 'host_has_profile_pic',\n",
    "    'host_identity_verified', 'room_type', 'accommodates', 'bathrooms',\n",
    "    'bedrooms', 'beds', 'price', 'minimum_nights', 'number_of_reviews',\n",
    "    'review_scores_rating', 'review_scores_cleanliness', 'review_scores_communication',\n",
    "    'review_scores_value', 'instant_bookable', 'availability_365', 'reviews_per_month'\n",
    "]\n",
    "listings_df = listings_df[cols].copy()\n",
    "def convert_percent(x):\n",
    "    try:\n",
    "        if isinstance(x, str) and '%' in x:\n",
    "            return float(x.strip('%')) / 100\n",
    "        return float(x) / 100\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "listings_df['host_response_rate'] = listings_df['host_response_rate'].apply(convert_percent)\n",
    "\n",
    "listings_df['host_acceptance_rate_percent'] = listings_df['host_acceptance_rate_percent'].apply(convert_percent)\n",
    "\n",
    "listings_df = listings_df[listings_df['host_is_superhost'].notna()]\n",
    "\n",
    "listings_df['host_is_superhost'] = listings_df['host_is_superhost'].astype(str).str.lower().map({'true': 1, 'false': 0, 't': 1, 'f': 0})\n",
    "\n",
    "listings_df.fillna(listings_df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "for col in ['host_response_time', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable', 'room_type']:\n",
    "    listings_df[col] = LabelEncoder().fit_transform(listings_df[col].astype(str))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afcb6de4",
   "metadata": {},
   "source": [
    "### Überblick über die Verteilung des Superhost-Status\n",
    "\n",
    "Zur ersten quantitativen Einschätzung wurde analysiert, wie viele Anbieter im Datensatz den Superhost-Status tragen und wie hoch deren Anteil im Vergleich zu regulären Hosts ist. Dazu wurden sowohl die absoluten Häufigkeiten als auch die prozentuale Verteilung berechnet.\n",
    "\n",
    "Anschliessend wurde die Verteilung visuell mittels Balkendiagramm dargestellt. Die zweiseitige Darstellung zeigt deutlich, wie stark (oder schwach) Superhosts im Verhältnis zur Gesamtmenge vertreten sind. Diese Basisanalyse ist wichtig, um potenzielle Klassenungleichgewichte zu erkennen, die bei der späteren Modellierung berücksichtigt werden müssen."
   ]
  },
  {
   "cell_type": "code",
   "id": "ce1554ed",
   "metadata": {},
   "source": [
    "print(\"Anzahl Superhosts vs. Nicht-Superhosts:\")\n",
    "print(listings_df['host_is_superhost'].value_counts())\n",
    "print(\"\\nProzentuale Verteilung:\")\n",
    "print(listings_df['host_is_superhost'].value_counts(normalize=True) * 100)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='host_is_superhost', data=listings_df)\n",
    "plt.title(\"Verteilung Superhost vs. andere\")\n",
    "plt.xticks([0,1], ['Nicht Superhost', 'Superhost'])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8b919f15",
   "metadata": {},
   "source": [
    "Im betrachteten Datensatz sind rund 34 % der Anbieter Superhosts, während etwa 66 % keine Superhosts sind. Dies zeigt, dass der Superhost-Status zwar kein Standard, aber auch nicht selten ist – es handelt sich um eine bedeutende Teilgruppe.\n",
    "\n",
    "Diese Verteilung weist auf eine gewisse Klassenungleichheit hin, was bei der Modellierung beachtet werden sollte (z. B. durch Balancing-Strategien). Gleichzeitig zeigt die relativ hohe Quote von Superhosts, dass der Status erreichbar ist – sofern bestimmte Merkmale oder Verhaltensweisen erfüllt werden.\n",
    "\n",
    "Für InvestZurich AG bedeutet das: Der Superhost-Status stellt ein realistisches Ziel dar, das auf Grundlage datenbasierter Erkenntnisse gezielt angestrebt werden kann.\n",
    "\n",
    "### Merkmalsvergleich zwischen Superhosts und Nicht-Superhosts\n",
    "\n",
    "In diesem Abschnitt wird untersucht, wie sich die numerischen Merkmale zwischen Superhosts und Nicht-Superhosts unterscheiden. Dazu werden zunächst die Mittelwerte aller numerischen Variablen separat für beide Gruppen berechnet und gegenübergestellt.\n",
    "\n",
    "Anschliessend wird für jedes Merkmal die prozentuale Differenz berechnet – also wie stark sich der Mittelwert bei Superhosts im Vergleich zu Nicht-Superhosts unterscheidet. Diese Analyse zeigt, welche Faktoren bei Superhosts überdurchschnittlich stark ausgeprägt sind und somit potenziell entscheidende Erfolgsfaktoren darstellen.\n",
    "\n",
    "Die 15 Merkmale mit dem grössten relativen Unterschied werden in einem Balkendiagramm visualisiert. Dadurch wird sichtbar, welche quantitativen Eigenschaften besonders stark mit dem Superhost-Status assoziiert sind – z. B. häufige Bewertungen, hohe Sauberkeit oder hohe Buchungsaktivität. Diese Erkenntnisse bilden eine fundierte Grundlage für die Ableitung konkreter Optimierungsmassnahmen."
   ]
  },
  {
   "cell_type": "code",
   "id": "04108937",
   "metadata": {},
   "source": [
    "grouped_stats = listings_df.groupby('host_is_superhost').mean(numeric_only=True).T\n",
    "diff = (grouped_stats[1] - grouped_stats[0]) / grouped_stats[0] * 100\n",
    "print(\"\\nMittelwerte der Merkmale nach Superhost-Status:\")\n",
    "print(grouped_stats.sort_values(by=1, ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "diff.sort_values(ascending=False).head(15).plot(kind='bar')\n",
    "plt.title(\"Top 15 Merkmale mit grösstem Unterschied (Superhost vs. Nicht-Superhost)\")\n",
    "plt.ylabel(\"Differenz in %\")\n",
    "plt.xlabel(\"Merkmal\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d84a54c4",
   "metadata": {},
   "source": [
    "Die Auswertung zeigt deutliche Unterschiede zwischen Superhosts und Nicht-Superhosts in mehreren zentralen Merkmalen. Am stärksten unterscheiden sich die Gruppen bei folgenden Aspekten:\n",
    "\n",
    "- Anzahl Bewertungen (number_of_reviews): Superhosts erhalten im Durchschnitt mehr als doppelt so viele Bewertungen wie Nicht-Superhosts (+108 %). Dies deutet auf eine höhere Buchungsaktivität und Erfahrung hin.\n",
    "- Sofortbuchbarkeit (instant_bookable): Superhosts bieten deutlich häufiger die Möglichkeit zur Sofortbuchung an (+67 %), was die Buchungshürde für Gäste senkt und Vertrauen signalisiert.\n",
    "- Anzahl gelisteter Objekte (host_total_listings_count): Superhosts verwalten im Schnitt mehr Objekte (+40 %), was darauf hinweist, dass viele von ihnen Airbnb professionell nutzen.\n",
    "- Monatliche Bewertungsfrequenz (reviews_per_month): Auch hier zeigen sich höhere Werte bei Superhosts (+35 %), ein weiterer Hinweis auf kontinuierliche Auslastung und Gästekontakt.\n",
    "- Antwortzeit (host_response_time): Superhosts reagieren schneller (höherer numerischer Wert entspricht z. B. \"innerhalb weniger Stunden\") – ein Plus von 28 % im Vergleich zur Kontrollgruppe.\n",
    "\n",
    "Auch bei Bewertungsdimensionen wie Sauberkeit, Kommunikation und Wertigkeit zeigen sich tendenziell bessere Werte bei Superhosts, wenn auch mit geringerem absoluten Unterschied.\n",
    "\n",
    "Zusätzlich fällt auf, dass Superhosts kürzere Mindestaufenthalte zulassen, was die Buchungshäufigkeit erhöhen kann. Auch die Antwort- und Annahmequote ist bei ihnen deutlich höher, was auf Verlässlichkeit und aktives Hosting hinweist.\n",
    "\n",
    "Die Mittelwertanalyse zeigt, dass Superhosts in mehreren operativen Bereichen systematisch besser abschneiden als andere Hosts. Besonders stark unterscheiden sie sich bei der Anzahl an Bewertungen, der Sofortbuchbarkeit, der Gastgeberaktivität und dem Antwortverhalten. Diese Muster deuten auf professionell geführte, effizient organisierte Unterkünfte hin.\n",
    "\n",
    "**Für InvestZurich AG ergeben sich daraus folgende strategische Ansätze:**\n",
    "- Mehr Bewertungen generieren, z. B. durch aktives Bewertungsmanagement.\n",
    "- Sofortbuchung aktivieren, um die Buchungsquote zu erhöhen.\n",
    "- Reaktionszeiten verbessern, idealerweise durch automatisierte Antworten.\n",
    "- Mindestaufenthalte reduzieren, um spontane Buchungen zu ermöglichen.\n",
    "- Gastgeberprozesse professionalisieren, vor allem bei wachsender Objektanzahl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c895b",
   "metadata": {},
   "source": [
    "### Verteilungsanalyse\n",
    "\n",
    "Im Anschluss an die Mittelwertanalyse bietet eine detaillierte Betrachtung der Verteilungen zentraler Merkmale zusätzliche Einblicke in die Unterschiede zwischen Superhosts und Nicht-Superhosts. Während Durchschnittswerte erste Hinweise auf potenziell relevante Einflussfaktoren liefern, zeigen Boxplots auf, wie sich diese Merkmale innerhalb der Gruppen tatsächlich verteilen.\n",
    "\n",
    "Für neun besonders relevante Variablen – darunter Antwortverhalten, Bewertungsqualität, Buchungsaktivität und Verfügbarkeit – wird die Verteilung jeweils getrennt nach Superhost-Status visualisiert. So lassen sich Muster erkennen, die nicht nur im Mittelwert, sondern auch in der Streuung und Konsistenz deutlich voneinander abweichen."
   ]
  },
  {
   "cell_type": "code",
   "id": "b8683143",
   "metadata": {},
   "source": [
    "features = [\n",
    "    'host_response_time', 'host_response_rate', 'host_acceptance_rate_percent',\n",
    "    'review_scores_rating', 'review_scores_cleanliness', 'review_scores_communication',\n",
    "    'review_scores_value', 'availability_365', 'reviews_per_month'\n",
    "]\n",
    "\n",
    "# Plot-Layout automatisch berechnen\n",
    "n_cols = 3\n",
    "n_rows = -(-len(features) // n_cols)  # Aufrunden\n",
    "\n",
    "plt.figure(figsize=(5 * n_cols, 4 * n_rows))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    sns.boxplot(\n",
    "    x='host_is_superhost',\n",
    "    y=feature,\n",
    "    data=listings_df,\n",
    "    hue='host_is_superhost',\n",
    "    palette='pastel',\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "    plt.title(feature.replace('_', ' ').capitalize())\n",
    "    plt.xlabel(\"Superhost\")\n",
    "    plt.ylabel(\"\")  # optional für kompaktere Darstellung\n",
    "    plt.xticks([0, 1], ['Nein', 'Ja'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig90, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.boxplot(x='host_is_superhost', y='host_response_rate', data=listings_df,\n",
    "            hue='host_is_superhost', palette='pastel', ax=axes[0])\n",
    "axes[0].set_title(\"Antwortrate nach Superhost-Status\")\n",
    "axes[0].set_xlabel(\"Superhost\")\n",
    "axes[0].set_ylabel(\"Antwortrate\")\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Nein', 'Ja'])\n",
    "axes[0].get_legend().remove()\n",
    "\n",
    "sns.boxplot(x='host_is_superhost', y='host_acceptance_rate_percent', data=listings_df,\n",
    "            hue='host_is_superhost', palette='pastel', ax=axes[1])\n",
    "axes[1].set_title(\"Annahmequote nach Superhost-Status\")\n",
    "axes[1].set_xlabel(\"Superhost\")\n",
    "axes[1].set_ylabel(\"Annahmequote\")\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['Nein', 'Ja'])\n",
    "axes[1].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig91, ax91 = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "reviews = listings_df.groupby('host_is_superhost')['number_of_reviews'].mean()\n",
    "ax91.bar(['Nicht-Superhost', 'Superhost'], reviews, color='slateblue')\n",
    "ax91.set_title(\"Durchschnittliche Anzahl Bewertungen\")\n",
    "ax91.set_ylabel(\"Anzahl Bewertungen\")\n",
    "ax91.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "features = ['review_scores_cleanliness', 'review_scores_communication', 'review_scores_rating']\n",
    "fig92, axes3 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='host_is_superhost', y=feature, data=listings_df,\n",
    "                hue='host_is_superhost', palette='pastel', ax=axes3[i])\n",
    "    axes3[i].set_title(feature.replace('_', ' ').capitalize())\n",
    "    axes3[i].set_xlabel(\"Superhost\")\n",
    "    axes3[i].set_ylabel(\"\")\n",
    "    axes3[i].set_xticks([0, 1])\n",
    "    axes3[i].set_xticklabels(['Nein', 'Ja'])\n",
    "    axes3[i].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c3995c5",
   "metadata": {},
   "source": [
    "Superhosts unterscheiden sich in mehreren zentralen operativen Kennzahlen systematisch von regulären Gastgeber:innen.\n",
    "\n",
    "Ein besonders markanter Unterschied besteht bei der Antwortrate: Superhosts erreichen Werte nahe der maximalen Schwelle (ca. 1.0), während die Werte bei Nicht-Superhosts deutlich stärker streuen. Auch die Annahmequote ist bei Superhosts im Schnitt deutlich höher – ein Hinweis auf professionell geführte Buchungsprozesse und verlässliche Kalenderpflege.\n",
    "\n",
    "Die durchschnittliche Anzahl an Bewertungen ist bei Superhosts fast doppelt so hoch. Zwar ist dies nicht als Ursache des Superhost-Status zu interpretieren, es spricht aber für eine höhere Buchungsfrequenz und grössere Gästeerfahrung. Damit wird die Bewertungshäufigkeit zu einem indirekten Indikator für operative Aktivität und Präsenz** auf der Plattform.\n",
    "\n",
    "Auch bei den **Bewertungsdimensionen** – insbesondere Sauberkeit, Kommunikation und Gesamtbewertung – schneiden Superhosts signifikant besser ab. Die Boxplots zeigen nicht nur höhere Mittelwerte, sondern auch geringere Streuung, was auf ein stabiles und standardisiertes Qualitätsniveau hinweist.\n",
    "### Klassifikationsmodell zur Vorhersage des Superhost-Status\n",
    "\n",
    "Im folgenden Abschnitt wird ein Klassifikationsmodell aufgebaut, das vorhersagen soll, ob ein Gastgeber den Superhost-Status erreicht. Dafür wird ein Random Forest Classifier verwendet.\n",
    "\n",
    "Zunächst werden die Daten in Trainings- und Testmengen unterteilt, um die Modellleistung realistisch evaluieren zu können. Nach dem Training des Modells erfolgt eine Klassifikation auf Basis der Testdaten. Die Modellgüte wird anhand klassischer Metriken wie Precision, Recall und F1-Score ausgewertet.\n",
    "\n",
    "Darüber hinaus liefert das Modell Einblick in die Feature Importance – also die relative Bedeutung einzelner Merkmale für die Entscheidungsfindung des Modells. Diese Information ist besonders wertvoll, um zu verstehen, welche Variablen am stärksten zur Unterscheidung von Superhosts und Nicht-Superhosts beitragen. Die wichtigsten Merkmale werden abschliessend in einem Balkendiagramm visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "id": "92eb1637",
   "metadata": {},
   "source": [
    "X = listings_df.drop('host_is_superhost', axis=1)\n",
    "y = listings_df['host_is_superhost']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "fig93, ax4 = plt.subplots(figsize=(12, 6))\n",
    "indices = np.argsort(model.feature_importances_)[::-1]\n",
    "sns.barplot(x=np.array(X.columns)[indices], y=model.feature_importances_[indices], ax=ax4, color='C0')\n",
    "ax4.set_title(\"Feature Importance im Random Forest Modell\")\n",
    "ax4.set_xticks(range(len(X.columns)))\n",
    "ax4.set_xticklabels(np.array(X.columns)[indices], rotation=90)\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f66be7ac",
   "metadata": {},
   "source": [
    "**Bedeutende Einflussfaktoren:**\n",
    "\n",
    "1. **`host_total_listings_count`:**\n",
    "      Hosts mit mehreren Objekten weisen häufiger den Superhost-Status auf. Dies ist weniger ein Hinweis darauf, dass die Anzahl der vermieteten Wohnungen selbst entscheidend ist, sondern vielmehr darauf, dass diese Hosts Airbnb gewerblich oder zumindest professioneller betreiben. Dadurch sind sie tendenziell besser organisiert und schneiden in anderen relevanten Faktoren wie Reaktionszeit, Buchungsannahme und Gästekommunikation besser ab. Die Korrelation könnte zudem dadurch beeinflusst sein, dass erfahrene Gastgeber sich proaktiver um den Superhost-Status bemühen oder besser mit den Anforderungen der Plattform vertraut sind.\n",
    "\n",
    "2. **`host_response_time`:** und **`host_acceptance_rate_percent`**\n",
    "   Eine schnelle Reaktion auf Anfragen und eine hohe Annahmequote gelten als zentrale Anforderungen, da sie Verlässlichkeit signalisieren.\n",
    "\n",
    "3. **`reviews_per_month`** und **`review_scores_cleanliness`:**\n",
    "   Regelmässige und qualitativ hochwertige Bewertungen, insbesondere im Bereich Sauberkeit, sprechen für ein hohes Serviceniveau.\n",
    "\n",
    "**Kritische Einordnung:**\n",
    "\n",
    "- Merkmale wie `host_identity_verified` oder `host_has_profile_pic` tragen im Modell kaum zur Vorhersagekraft bei. Dies kann durch geringe Varianz in diesen Spalten erklärt werden oder darauf hinweisen, dass sie für Gäste keine ausschlaggebende Rolle spielen.\n",
    "\n",
    "- Die Ausstattung der Unterkunft (z. B. **`beds`**, **`bathrooms`**, **`room_type`**) ist im Zusammenhang mit dem Superhost-Status weniger relevant, was plausibel erscheint – dieser Status bewertet vorrangig das Verhalten des Hosts.\n",
    "\n",
    "- Der Einfluss von **`price`** ist ebenfalls gering. Daraus lässt sich schliessen, dass Preisgestaltung allein nicht entscheidend ist – wichtiger ist das gebotene Preis-Leistungs-Verhältnis.\n",
    "\n",
    "### Modellvergleich für Random Forest vs. Logistische Regression\n",
    "\n",
    "Zur Validierung der Modellgüte und zur Einordnung der Ergebnisse wird das Random-Forest-Modell mit einer Logistischen Regression verglichen – einem einfacheren, gut interpretierbaren Klassifikator. Beide Modelle werden mittels 5-facher Cross-Validation bewertet, zusätzlich erfolgt ein Vergleich der ROC-Kurven. Dies ermöglicht eine differenzierte Beurteilung der Trennschärfe und Stabilität beider Modelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d6cdef4",
   "metadata": {},
   "source": [
    "log_model = LogisticRegression(max_iter=1000000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "print(\"Logistische Regression - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "rf_cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Random Forest - durchschnittliche CV-Accuracy:\", rf_cv_scores.mean())\n",
    "\n",
    "log_cv_scores = cross_val_score(log_model, X, y, cv=5)\n",
    "print(\"Logistische Regression - durchschnittliche CV-Accuracy:\", log_cv_scores.mean())\n",
    "\n",
    "\n",
    "probs_rf = model.predict_proba(X_test)[:, 1]\n",
    "probs_log = log_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, probs_rf)\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, probs_log)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = {:.2f})'.format(roc_auc_score(y_test, probs_rf)))\n",
    "plt.plot(fpr_log, tpr_log, label='Logistische Regression (AUC = {:.2f})'.format(roc_auc_score(y_test, probs_log)))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-Kurve Vergleich')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f3951cd",
   "metadata": {},
   "source": [
    "### Modellvergleich und Auswahl\n",
    "\n",
    "Die Gegenüberstellung der beiden Klassifikatoren zeigt einen deutlichen Leistungsunterschied: Der Random Forest erzielt eine AUC von 0.94, während die Logistische Regression bei 0.77 liegt. Auch in der ROC-Kurve wird dieser Unterschied visuell deutlich – der Random Forest verläuft näher an der idealen oberen linken Ecke und weist somit eine höhere Trennschärfe auf.\n",
    "\n",
    "Die Cross-Validation-Ergebnisse bestätigen dieses Bild: Der Random Forest erreicht im Mittel eine höhere Genauigkeit, zeigt sich gleichzeitig stabil und robust gegenüber unterschiedlichen Trainings-/Test-Splits. Die Logistische Regression liefert akzeptable, aber deutlich schwächere Ergebnisse.\n",
    "\n",
    "Der Random Forest ist dem linearen Modell sowohl bei der Gesamtgüte (AUC) als auch bei der generalisierbaren Genauigkeit (CV-Score) klar überlegen.\n",
    "\n",
    "Aufgrund seiner nichtlinearen Struktur kann der Random Forest auch komplexe Zusammenhänge zwischen den Merkmalen besser abbilden – was bei einem vielseitigen Merkmalssatz wie in diesem Fall entscheidend ist.\n",
    "\n",
    "Für die finale Modellierung und die Ableitung strategischer Empfehlungen wird daher auf den Random Forest als Hauptmodell gesetzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc752475",
   "metadata": {},
   "source": [
    "## Objective 4 – Listing-Optimierung durch Textanalyse\n",
    "\n",
    "Ziel dieses Untersuchungsabschnitts ist es, den Einfluss von sprachlichen und inhaltlichen Eigenschaften in Listing-Beschreibungen auf die Performance von Airbnb-Angeboten im Raum Zürich systematisch zu analysieren. Im Fokus steht die Frage, ob sich durch gezielte Optimierung von Beschreibungstexten messbare Effekte auf Buchungserfolg, Bewertung oder Preissetzung erzielen lassen – und wie die InvestZurich AG diese Erkenntnisse nutzen kann, um ihre Listings gezielt zu verbessern.\n",
    "\n",
    "Im Zentrum der Analyse steht die strukturelle und inhaltliche Auswertung der Textspalte 'description' mithilfe von Methoden der natürlichen Sprachverarbeitung (Natural Language Processing, NLP). Dabei werden zunächst syntaktische Merkmale wie Textlänge, Stimmung (Sentiment) und Subjektivität untersucht, um ein Gefühl für den sprachlichen Charakter der Texte zu bekommen. In einem zweiten Schritt erfolgt eine Themenanalyse (Topic Modeling), um wiederkehrende inhaltliche Muster zu identifizieren.\n",
    "\n",
    "Ziel dieser Analyse ist es, datenbasiert herauszufinden, welche Textmerkmale besonders häufig in gut bewerteten oder hochpreisigen Listings vorkommen – oder ob bestimmte sprachliche Stile tendenziell mit besseren Resultaten einhergehen. Auf dieser Basis sollen für die InvestZurich AG konkrete Empfehlungen zur textbasierten Listing-Optimierung abgeleitet werden, etwa im Hinblick auf Keyword-Nutzung, Tonalität oder Zielgruppenansprache.\n",
    "\n",
    "Die nachfolgende Analyse liefert somit die Grundlage für eine inhaltlich fundierte und skalierbare Optimierungsstrategie, die über rein visuelle oder lagebezogene Aspekte hinausgeht – und gezielt das Potenzial textlicher Kommunikation als Erfolgsfaktor nutzt."
   ]
  },
  {
   "cell_type": "code",
   "id": "f33cefc5",
   "metadata": {},
   "source": [
    "# Stellt sicher, dass df_analysis und die relevante Textspalte (z.B. 'description') existieren.\n",
    "\n",
    "# Haupt-Textspalte für die detaillierte Analyse (gemäss bina_models.Listing)\n",
    "# Andere Textspalten wie 'name', 'neighborhood_overview', 'host_about' können analog analysiert werden.\n",
    "import sys\n",
    "#!{sys.executable} -m pip install supabase\n",
    "#!{sys.executable} -m pip install python-dotenv\n",
    "#!{sys.executable} -m pip install pandas\n",
    "#!{sys.executable} -m pip install nltk\n",
    "#!{sys.executable} -m pip install scikit-learn\n",
    "#!{sys.executable} -m pip install matplotlib seaborn textblob\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Ressourcen laden (nur 1x nötig)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from airbnb_analysis_service import AirbnbAnalysisService\n",
    "\n",
    "airbnbAnalysis = AirbnbAnalysisService()\n",
    "listings = airbnbAnalysis.get_listings()\n",
    "main_text_col_for_nlp = 'description'\n",
    "df_analysis = pd.DataFrame([l.__dict__ for l in listings])\n",
    "\n",
    "if not df_analysis.empty and main_text_col_for_nlp in df_analysis.columns and df_analysis[main_text_col_for_nlp].notna().sum() > 0 :\n",
    "    print(f\"\\n--- Analysen für Use Case 4 (NLP) basierend auf Spalte '{main_text_col_for_nlp}' ---\")\n",
    "\n",
    "    # Stichprobe für rechenintensive NLP-Tasks (Grösse anpassen falls nötig)\n",
    "    # Verwende nur Zeilen, in denen die Haupttextspalte nicht leer ist nach der Vorbereitung (fillna(''))\n",
    "    df_nlp_source = df_analysis[df_analysis[main_text_col_for_nlp].str.strip().astype(bool)]\n",
    "\n",
    "    sample_size_nlp_uc4 = min(1000, len(df_nlp_source))\n",
    "    if len(df_nlp_source) < sample_size_nlp_uc4 : sample_size_nlp_uc4 = len(df_nlp_source)\n",
    "\n",
    "    if sample_size_nlp_uc4 < 20 :\n",
    "         print(f\"Stichprobengrösse ({sample_size_nlp_uc4}) für '{main_text_col_for_nlp}' zu klein für NLP-Analyse. Überspringe.\")\n",
    "    else:\n",
    "        df_nlp = df_nlp_source.sample(n=sample_size_nlp_uc4, random_state=42).copy()\n",
    "        print(f\"NLP-Analyse wird auf einer Stichprobe von {len(df_nlp)} Listings für '{main_text_col_for_nlp}' durchgeführt.\")\n",
    "\n",
    "        # --- Textdaten-Vorbereitung für NLP ---\n",
    "        print(\"\\n--- Textdaten-Vorbereitung für NLP ---\")\n",
    "        stop_words_de_uc4 = stopwords.words('german')\n",
    "        stop_words_en_uc4 = stopwords.words('english')\n",
    "        custom_stopwords_uc4 = [\n",
    "            'br', 'href', 'www', 'https', 'http', 'com', 'zurich', 'zürich', 'apartment', 'wohnung',\n",
    "            'description', 'guest', 'guests', 'stay', 'place', 'room', 'rooms', 'city', 'haus', 'home',\n",
    "            'house', 'area', 'also', 'well', 'get', 'see', 'us', 'come', 'min', 'one', 'two', 'meter',\n",
    "            'bit', 'eur', 'chf', 'day', 'week', 'nbsp', 'amp', 'quot', 'lt', 'gt', 'apos', 'zurich',\n",
    "            'apartment', 'flat', 'studio', 'appartement' # Generische Airbnb Begriffe\n",
    "        ]\n",
    "        all_stopwords_uc4 = set(stop_words_de_uc4 + stop_words_en_uc4 + custom_stopwords_uc4)\n",
    "\n",
    "        lemmatizer_uc4 = WordNetLemmatizer()\n",
    "\n",
    "        def preprocess_text_nlp(text_series):\n",
    "            processed_texts = []\n",
    "            for text_doc in text_series:\n",
    "                doc = str(text_doc).lower()\n",
    "                doc = re.sub(r'<[^>]+>', ' ', doc) # HTML entfernen\n",
    "                doc = re.sub(r'[^a-zäöüss\\s]', ' ', doc) # Nur Buchstaben (inkl. Umlaute) und Leerzeichen\n",
    "                doc = re.sub(r'\\s+', ' ', doc).strip() # Überflüssige Leerzeichen entfernen\n",
    "\n",
    "                # Sprachabhängige Tokenisierung und Lemmatisierung (einfacher Ansatz)\n",
    "                # Für eine präzisere NLP bei gemischtsprachigen Texten wären fortgeschrittenere Methoden nötig\n",
    "                lang_to_tokenize = 'german' if any(c in 'äöüss' for c in doc) else 'english'\n",
    "\n",
    "                try:\n",
    "                    tokens = word_tokenize(doc, language=lang_to_tokenize)\n",
    "                except LookupError: # Fallback, falls spezifische Sprachdaten für punkt fehlen\n",
    "                    try: nltk.download('punkt', quiet=True); tokens = word_tokenize(doc, language=lang_to_tokenize)\n",
    "                    except: tokens = doc.split() # Einfaches Splitten als Notlösung\n",
    "\n",
    "                # Lemmatisierung - WordNetLemmatizer ist primär für Englisch.\n",
    "                # Für Deutsch wären andere Lemmatizer (z.B. GermaLemma, spaCy mit deutschem Modell) besser.\n",
    "                # Hier als Annäherung für beide Sprachen verwendet.\n",
    "                lemmatized_tokens = [lemmatizer_uc4.lemmatize(token) for token in tokens if token not in all_stopwords_uc4 and len(token) > 2]\n",
    "                processed_texts.append(\" \".join(lemmatized_tokens))\n",
    "            return processed_texts\n",
    "\n",
    "        print(\"Beginne mit der Textvorverarbeitung für NLP (kann etwas dauern)...\")\n",
    "        df_nlp.loc[:, 'description_cleaned_nlp'] = preprocess_text_nlp(df_nlp[main_text_col_for_nlp])\n",
    "        print(\"Textvorverarbeitung abgeschlossen.\")\n",
    "\n",
    "        if not df_nlp['description_cleaned_nlp'].empty:\n",
    "            example_cleaned_desc_uc4 = df_nlp['description_cleaned_nlp'].head(1)\n",
    "            print(f\"\\nBeispiel für bereinigte Beschreibung:\\n{example_cleaned_desc_uc4.iloc[0] if not example_cleaned_desc_uc4.empty else 'Keine Daten'}\")\n",
    "\n",
    "        # --- Sentiment Analyse ---\n",
    "        print(\"\\n--- Sentiment Analyse ---\")\n",
    "        def get_sentiment_textblob(text_to_analyze):\n",
    "            if not text_to_analyze or not isinstance(text_to_analyze, str) or not text_to_analyze.strip(): return 0.0, 0.0\n",
    "            try:\n",
    "                # TextBlob versucht, die Sprache zu erkennen. Für Deutsch ist die Genauigkeit manchmal limitiert.\n",
    "                blob = TextBlob(text_to_analyze)\n",
    "                return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "            except Exception as e_sent:\n",
    "                # print(f\"Fehler bei Sentiment Analyse für Text: '{text_to_analyze[:50]}...' - {e_sent}\")\n",
    "                return 0.0, 0.0\n",
    "\n",
    "        sentiments_nlp_uc4 = df_nlp['description_cleaned_nlp'].apply(get_sentiment_textblob)\n",
    "        df_nlp.loc[:, 'sentiment_polarity'] = sentiments_nlp_uc4.apply(lambda x: x[0])\n",
    "        df_nlp.loc[:, 'sentiment_subjectivity'] = sentiments_nlp_uc4.apply(lambda x: x[1])\n",
    "\n",
    "        print(\"\\nDeskriptive Statistiken für Sentiment-Scores:\")\n",
    "        print(df_nlp[['sentiment_polarity', 'sentiment_subjectivity']].describe())\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1); sns.histplot(df_nlp['sentiment_polarity'], kde=True, bins=20, color='purple'); plt.title('Verteilung Sentiment-Polarität (Description)')\n",
    "        plt.subplot(1, 2, 2); sns.histplot(df_nlp['sentiment_subjectivity'], kde=True, bins=20, color='orange'); plt.title('Verteilung Sentiment-Subjektivität (Description)')\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        # Korrelation Sentiment mit Performance-Metriken\n",
    "        # Stelle sicher, dass die Spalten für die Korrelation numerisch sind und existieren\n",
    "        cols_for_sentiment_corr_uc4 = [col for col in ['sentiment_polarity', 'sentiment_subjectivity', 'review_scores_rating', 'price']\n",
    "                                       if col in df_nlp.columns and pd.api.types.is_numeric_dtype(df_nlp[col])]\n",
    "        if len(cols_for_sentiment_corr_uc4) > 2 :\n",
    "            sentiment_corr_df_uc4 = df_nlp[cols_for_sentiment_corr_uc4].corr()\n",
    "            print(\"\\nKorrelation von Sentiment mit Performance-Metriken:\\n\", sentiment_corr_df_uc4)\n",
    "            plt.figure(figsize=(7,5)); sns.heatmap(sentiment_corr_df_uc4, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1); plt.title(\"Sentiment Korrelationen\"); plt.show()\n",
    "        else:\n",
    "            print(\"Nicht genügend Spalten für Sentiment-Korrelationsanalyse vorhanden.\")\n",
    "\n",
    "        # --- Topic Modeling (LDA) ---\n",
    "        print(\"\\n--- Topic Modeling (LDA) ---\")\n",
    "        # Nur Texte verwenden, die nach der Bereinigung nicht leer sind\n",
    "        documents_for_lda_uc4 = df_nlp['description_cleaned_nlp'][df_nlp['description_cleaned_nlp'].str.strip().astype(bool)]\n",
    "\n",
    "        if len(documents_for_lda_uc4) > 20: # Mindestanzahl Dokumente für LDA\n",
    "            try:\n",
    "                # max_features begrenzt das Vokabular für bessere Performance und klarere Topics\n",
    "                vectorizer_tfidf_uc4 = TfidfVectorizer(max_df=0.90, min_df=5, stop_words=list(all_stopwords_uc4), ngram_range=(1,1), max_features=1000)\n",
    "                tfidf_matrix_uc4 = vectorizer_tfidf_uc4.fit_transform(documents_for_lda_uc4)\n",
    "                feature_names_tfidf_uc4 = vectorizer_tfidf_uc4.get_feature_names_out()\n",
    "\n",
    "                num_topics_uc4 = 5 # ANPASSEN: Anzahl der zu entdeckenden Topics (typischerweise 5-15)\n",
    "                if tfidf_matrix_uc4.shape[1] >= num_topics_uc4: # Genügend Features für Topics\n",
    "                    lda_model_uc4 = LatentDirichletAllocation(n_components=num_topics_uc4, random_state=42, learning_method='online', n_jobs=-1, max_iter=15, evaluate_every=1)\n",
    "                    lda_model_uc4.fit(tfidf_matrix_uc4)\n",
    "\n",
    "                    print(f\"\\nTop Wörter für {num_topics_uc4} entdeckte Topics (LDA aus '{main_text_col_for_nlp}'):\")\n",
    "                    def display_topics_lda(model, feature_names, no_top_words):\n",
    "                        for topic_idx, topic_dist in enumerate(model.components_):\n",
    "                            top_words_indices = topic_dist.argsort()[:-no_top_words - 1:-1]\n",
    "                            top_words = [feature_names[i] for i in top_words_indices]\n",
    "                            print(f\"Thema #{topic_idx+1}: {' | '.join(top_words)}\")\n",
    "                    display_topics_lda(lda_model_uc4, feature_names_tfidf_uc4, 10) # Zeige Top 10 Wörter pro Topic\n",
    "                else:\n",
    "                    print(\"Nicht genügend einzigartige Features nach TF-IDF für LDA (Anzahl Topics vs. Features).\")\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler während Topic Modeling: {e}\")\n",
    "        else:\n",
    "            print(\"Nicht genügend Dokumente für Topic Modeling vorhanden nach Bereinigung/Filterung.\")\n",
    "else:\n",
    "    print(f\"Analysen für Use Case 4 (NLP) können nicht durchgeführt werden (DataFrame `df_analysis` leer oder Spalte '{main_text_col_for_nlp}' fehlt oder enthält keine Texte).\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3428e35",
   "metadata": {},
   "source": [
    "### Textvorbereitung\n",
    "Die Beschreibungen `'description'` wurden bereinigt, tokenisiert, von Stopwörtern befreit und lemmatisiert. Ein Beispiel für eine bereinigte Beschreibung aus der Stichprobe ist: `enjoy stylish experience centrally located`.\n",
    "\n",
    "### Sentiment Analyse\n",
    " - Die durchschnittliche Sentiment-Polarität der Objektbeschreibungen (basierend auf der Stichprobe `df_nlp`) liegt bei **0.253** (Werte reichen von -0.2 bis +0.925). Eine **leicht positive** Polarität überwiegt.\n",
    "- Die durchschnittliche Subjektivität liegt bei **0.486** (Werte von 0.0 bis 1.0). *Interpretation: Die Texte sind im Durchschnitt weder rein objektiv noch extrem subjektiv, sondern bewegen sich in einem mittleren, werblich-informativen Bereich.*\n",
    "- Korrelation mit Performance:** *(Basierend auf `sentiment_corr_df_uc4`)*\n",
    "    - Polarität vs. `'review_scores_rating'`: **-0.03**\n",
    "    - Polarität vs. `'price'`: **+0.03**\n",
    "\n",
    "**Interpretation:** Eine positivere Sprache in den Beschreibungen führt weder zu besseren Bewertungen noch zu höheren Preisen. Auch Subjektivität zeigt keine statistisch relevante Korrelation mit Performance-Metriken.*\n",
    "\n",
    "### Topic Modeling (LDA)\n",
    "Es wurden **5** Hauptthemen in den Objektbeschreibungen der Stichprobe identifiziert.\n",
    "\n",
    "**Thema 1:** Top Wörter: `minute | located | station | enjoy | tram | restaurant | train | walk | location | away`\n",
    "(Dieses Thema könnte sich auf **Lagevorteile und zentrale Erreichbarkeit** beziehen.)\n",
    "\n",
    "**Thema 2:** Top Wörter: `booking | ask | case | car | pay | discount | please | parking | need | accessible`\n",
    "(Dieses Thema behandelt **Buchungshinweise, Erreichbarkeit und mögliche Zusatzkosten**.)\n",
    "\n",
    "**Thema 3:** Top Wörter: `simple | life | centrally | peaceful | located | enjoy | quiet | keep | national | museum`\n",
    "(Hier geht es um **Atmosphäre und Lage – ruhige, kulturell attraktive Wohnlage**.)\n",
    "\n",
    "**Thema 4:** Top Wörter: `photo | paradeplatz | painting | bijou | luxuriously | digital | optic | europaallee | frame | fiber`\n",
    "(Dieses Thema beschreibt **Design, Kunst, Luxusausstattung und spezifische Stadtteile (Zürich)**.)\n",
    "\n",
    "**Thema 5:** Top Wörter: `bed | kitchen | bathroom | bedroom | equipped | living | balcony | fully | machine | shower`\n",
    "(Fokus liegt hier klar auf der **Innenausstattung und praktischen Einrichtung** der Unterkunft.)\n",
    "\n",
    "**Wie könnten diese Themen mit der Performance zusammenhängen?**\n",
    " Eine weiterführende Analyse könnte untersuchen, ob bestimmte Themen (z. B. Lage oder Luxusausstattung) häufiger mit höherer Bewertung oder höheren Preisen korrelieren. Dazu wäre es sinnvoll, jedem Listing das dominante Thema zuzuordnen und dann den Preis/Score innerhalb jeder Themengruppe zu vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22341b30",
   "metadata": {},
   "source": [
    "# Step 4: Presenting Information\n",
    "In diesem Kapitel werden die zentralen Erkenntnisse der vier analysierten Objectives zusammengefasst und übersichtlich dargestellt. Abschliessend wird eine übergreifende Schlussfolgerung gezogen, die alle Ergebnisse in einen gemeinsamen strategischen Kontext bringt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6325e",
   "metadata": {},
   "source": [
    "## Objective 1 – Marktpotenzial und Standortanalyse\n",
    "Im Rahmen von Objecitve 1 wurde eine Standort- und Potenzialanalyse für den Airbnb-Markt in der Stadt Zürich durchgeführt. Dabei wurden verschiedene Perspektiven berücksichtigt: die Verteilung und Anzahl der Angebote pro Stadtkreis, Preisniveaus, Auslastung bzw. Verfügbarkeit, Unterkunftstypen, Gästekapazitäten sowie die Klassifikation besonders erfolgreicher Inserate mittels eines Random-Forest-Modells.\n",
    "\n",
    "Die Ergebnisse zeigen deutlich, dass sich das Investitionspotenzial nicht pauschal auf einzelne Stadtteile oder Unterkunftstypen reduzieren lässt. Vielmehr entsteht ein differenziertes Bild, bei dem mehrere Faktoren zusammenwirken. Auf Basis der durchgeführten Analysen lassen sich für die InvestZurich AG folgende zentrale Handlungsempfehlungen ableiten:\n",
    "\n",
    "### Hohe Nachfrage für Standortwahl gezielt nutzen\n",
    "\n",
    "Kreise mit niedriger durchschnittlicher Verfügbarkeit, wie z.B. Kreis 10, Kreis 5 und Kreis 2, weisen auf eine hohe Buchungsauslastung hin. Besonders Kreis 2 fällt zudem durch ein sehr hohes Preisniveau auf, was auf ein überdurchschnittlich hohes Umsatzpotenzial hindeutet. Gleichzeitig ist hier das Angebot vergleichsweise gering, was auf eine attraktive Marktlücke hinweisen kann. Investitionen sollten gezielt auf Stadtteile ausgerichtet werden, die hohe Nachfrage mit überschaubarem Wettbewerb kombinieren."
   ]
  },
  {
   "cell_type": "code",
   "id": "1b5890ce",
   "metadata": {},
   "source": [
    "display(fig3)\n",
    "display(fig2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f46c1e15",
   "metadata": {},
   "source": [
    "### Unterkunftsgrösse und Kapazität strategisch wählen\n",
    "\n",
    "Die Analyse der Unterkunftskapazität zeigt, dass insbesondere Objekte mit Platz für 6 bis 8 Personen stark nachgefragt sind. Diese Einheiten weisen eine signifikant niedrigere Verfügbarkeit auf und lassen auf eine hohe Beliebtheit schliessen. Gleichzeitig ermöglichen sie durch höhere Preise pro Nacht ein attraktives Umsatzpotenzial. Auch kleinere Einheiten für 1 bis 2 Gäste bleiben relevant, da sie eine solide Auslastung erzielen und ein breites Zielpublikum ansprechen."
   ]
  },
  {
   "cell_type": "code",
   "id": "aca6b628",
   "metadata": {},
   "source": [
    "display(fig5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5040547e",
   "metadata": {},
   "source": [
    "### Geeignete Unterkunftstypen priorisieren\n",
    "\n",
    "Im Vergleich der Unterkunftstypen zeigt sich, dass \"Private Rooms\" und \"Entire Homes/Apartments\" häufiger gebucht werden als z.B. Hotelzimmer, was durch geringere durchschnittliche Verfügbarkeiten belegt wird. Für eine skalierbare Investmentstrategie bieten sich insbesondere ganze Wohnungen an, da sie mehr Flexibilität in Preisgestaltung, Ausstattung und Zielgruppenansprache ermöglichen."
   ]
  },
  {
   "cell_type": "code",
   "id": "0727ee8a",
   "metadata": {},
   "source": [
    "display(fig4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d886380",
   "metadata": {},
   "source": [
    "### Datenbasiertes Auswahlverfahren etablieren\n",
    "\n",
    "Das entwickelte Random-Forest-Modell zur Klassifikation von Top Performern ermöglicht eine erste Einschätzung, ob ein Angebot Potenzial für hohe Nachfrage und Ertrag aufweist. Die wichtigsten Einflussfaktoren im Modell waren dabei die Kapazität, Lage und Anzahl der Schlafzimmer. Dieses Modell kann als unterstützendes Tool genutzt werden, um neue Angebote im Markt vorab zu bewerten und Investitionsrisiken zu minimieren."
   ]
  },
  {
   "cell_type": "code",
   "id": "1277111a",
   "metadata": {},
   "source": [
    "display(fig6)\n",
    "display(fig7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93dd69fc",
   "metadata": {},
   "source": [
    "## Objective 2 – Preisstrategie und Ertragsprognose\n",
    "Basierend auf dieser detaillierten Analyse in **Step 3** können wir folgende Schlüsse für die \"InvestZurich AG\" ziehen:\n",
    "\n",
    "1. **Nicht nur auf absolute Einnahmen achten:** Obwohl Quartiere wie `Kreis 1` hohe absolute Airbnb-Einnahmen generieren können, sind die Immobilienpreise dort so exorbitant, dass die relative Rentabilität (gemessen am `Revenue_Yield_Proxy`) am niedrigsten ist.\n",
    "\n",
    "2. **Attraktive Quartiere identifiziert:**\n",
    "- `Kreis 12` sticht als das potenziell rentabelste Quartier hervor, basierend auf dem höchsten `Revenue_Yield_Proxy`.\n",
    "- `Kreis 4` und `Kreis 6` bieten ebenfalls sehr attraktive `Revenue_Yield_Proxy-Werte`.\n",
    "\n",
    "3. **Diversifikationspotenzial:** Das Mittelfeld (`Kreis 2`, `10`, `3`, `5`, `8`) bietet solide `Revenue_Yield_Proxy`-Werte und könnte für eine Diversifikationsstrategie interessant sein.\n",
    "\n",
    "4. **Vorsicht bei teuersten Lagen für reine Renditeobjekte:** Für Investitionen mit Fokus auf laufende Rendite im Verhältnis zum Kapitaleinsatz (pro m²) scheinen die teuersten Lagen (`Kreis 1`, `Kreis 7`, `Kreis 9`) weniger geeignet.\n",
    "\n",
    "**Wichtige Einschränkung:** Unser `Revenue_Yield_Proxy` ist eine Vereinfachung und berücksichtigt nicht die spezifische Grösse der Airbnb-Objekte im Verhältnis zum Quadratmeterpreis. Für detailliertere ROI-Betrachtungen wären weitere Daten (z.B. durchschnittliche Wohnungsgrössen) oder die Analyse spezifischer Objektkategorien notwendig. Dennoch bietet diese Kennzahl eine wertvolle erste Orientierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2bdd85",
   "metadata": {},
   "source": [
    "## Objective 3 – Marktpotenzial und Standortanalyse\n",
    "\n",
    "Im Rahmen von Objective 3 wurde analysiert, welche quantitativen und qualitativen Merkmale Superhosts auf Airbnb im Raum Zürich von anderen Gastgebern unterscheiden. Ziel war es, InvestZurich AG datenbasiert aufzuzeigen, wie der Superhost-Status gezielt erreicht werden kann. Zum Einsatz kamen Mittelwertvergleiche, Boxplot-Analysen, ein Random-Forest-Klassifikator sowie ein Modellvergleich mit logistischer Regression.\n",
    "\n",
    "Die Ergebnisse belegen klar, dass Superhosts durch ein konsistentes Gesamtprofil überzeugen – insbesondere in den Bereichen **Reaktionsverhalten, Buchungszuverlässigkeit, Gästefeedback** und **operative Präsenz**. Daraus ergeben sich folgende priorisierte Handlungsempfehlungen:\n",
    "\n",
    "### Gastgeberverhalten konsequent optimieren\n",
    "\n",
    "Die Analyse zeigt, dass Superhosts in mehreren operativen Dimensionen systematisch besser abschneiden als reguläre Gastgeber:innen. Eine der deutlichsten Abweichungen findet sich im Antwortverhalten: Superhosts reagieren nicht nur schneller, sondern auch konsequenter auf Buchungsanfragen. Die Antwortraten liegen nahezu durchgängig bei 100 %, während sie bei Nicht-Superhosts deutlich stärker streuen – teils sogar unter die von Airbnb geforderte Mindestgrenze von 90 %. Auch die Annahmequote ist bei Superhosts signifikant höher und konsistenter. Dieses verlässliche Buchungsverhalten ist eine zentrale Voraussetzung für Vertrauen auf Plattformen wie Airbnb.\n",
    "\n",
    "InvestZurich AG sollte automatisierte Antwortfunktionen und standardisierte Buchungsprozesse einführen, um eine Antwortrate von mindestens 90 % sicherzustellen. Zusätzlich sollten Kalendersysteme mit Echtzeit-Verfügbarkeit integriert werden, um Absagen zu vermeiden und die Annahmequote stabil hoch zu halten."
   ]
  },
  {
   "cell_type": "code",
   "id": "810b2c96",
   "metadata": {},
   "source": [
    "display(fig90)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "801f99ff",
   "metadata": {},
   "source": [
    "### Buchungserfahrung strategisch aufbauen\n",
    "\n",
    "Superhosts weisen im Mittel mehr als doppelt so viele Bewertungen auf wie Nicht-Superhosts. Dies lässt sich zwar nicht 1:1 in Buchungen übersetzen, deutet aber auf eine deutlich höhere Aktivität und Sichtbarkeit auf der Plattform hin. Bewertungen wirken wie ein soziales Vertrauenssignal und verbessern zugleich die algorithmische Platzierung bei Airbnb.\n",
    "\n",
    "InvestZurich AG sollte für neue Inserate gezielte Nachfrageanreize schaffen – etwa durch zeitlich befristete Einführungsangebote, niedrige Mindestaufenthalte oder erhöhte Verfügbarkeit. Ziel ist es, möglichst schnell die ersten 10–15 Bewertungen zu sammeln, um eine solide Buchungshistorie aufzubauen und Sichtbarkeit im Ranking zu erhöhen.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "61162f3d",
   "metadata": {},
   "source": [
    "display(fig91)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d39c4526",
   "metadata": {},
   "source": [
    "### Bewertungsqualität aktiv steuern\n",
    "\n",
    "Superhosts erzielen durchgängig bessere Bewertungen in den Bereichen Sauberkeit, Kommunikation und Gesamtbewertung – mit geringerer Streuung als Nicht-Superhosts. Diese Konstanz weist auf strukturierte Abläufe und kontrollierte Serviceprozesse hin. Schlechte Einzelbewertungen sind selten, was das Vertrauen künftiger Gäste stärkt und die Conversion-Rate erhöht.\n",
    "\n",
    "InvestZurich AG sollte standardisierte Checklisten für Reinigung, Check-in und Gästekommunikation einführen. Zudem sollten Bewertungen systematisch ausgewertet werden, um Schwachstellen zu identifizieren. Gäste sollten aktiv zur Bewertung eingeladen werden, z. B. über Follow-up-Nachrichten oder QR-Codes vor Ort."
   ]
  },
  {
   "cell_type": "code",
   "id": "309d3206",
   "metadata": {},
   "source": [
    "display(fig92)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "42fbdb95",
   "metadata": {},
   "source": [
    "### Datengetrieben entscheiden mit Modellunterstützung\n",
    "\n",
    "Das Machine-Learning-Modell zeigt, dass insbesondere Merkmale wie Anzahl Inserate, Annahmequote, Bewertungshäufigkeit und Servicequalität starke Prädiktoren für den Superhost-Status sind. Diese Erkenntnisse sind nicht nur erklärend, sondern bieten eine Grundlage zur operativen Steuerung und Priorisierung im Portfolio.\n",
    "\n",
    "InvestZurich AG sollte das ML-Modell zur laufenden Objektbewertung einsetzen. Ergänzend kann ein internes Dashboard entwickelt werden, das die wichtigsten KPI-Lücken visualisiert und datenbasiert Handlungsempfehlungen für jedes Objekt ableitet."
   ]
  },
  {
   "cell_type": "code",
   "id": "b60e7e67",
   "metadata": {},
   "source": [
    "display(fig93)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9f0950b",
   "metadata": {},
   "source": [
    "## Objective 4 – Listing-Optimierung durch Textanalyse\n",
    "\n",
    "Die nachfolgend abgeleiteten Empfehlungen basieren auf einer datengetriebenen Analyse von Listing-Beschreibungen mithilfe moderner NLP-Verfahren (Natural Language Processing). Im Zentrum standen linguistische Merkmale wie Stimmung (Sentiment), Subjektivität und thematische Inhalte. Ziel war es, herauszufinden, ob und wie sich Textgestaltung auf die Performance von Airbnb-Listings auswirkt – etwa in Bezug auf Bewertung, Preisniveau oder Sichtbarkeit.\n",
    "\n",
    "Auch wenn die Korrelationen mit Performance-Metriken nur schwach ausfielen, zeigen sich klare Muster hinsichtlich typischer Themen, Sprachstile und Wortwahl, die für die Optimierung von Listing-Texten genutzt werden können. Die folgenden Handlungsempfehlungen bieten InvestZurich AG eine pragmatische Grundlage für die strategische Weiterentwicklung ihrer textlichen Kommunikation auf Airbnb.\n",
    "\n",
    "1. **Positivität gezielt einsetzen:**  \n",
    "   Da eine insgesamt leicht **positive Sprachweise** in den Listings vorherrscht, die jedoch **nicht direkt mit besseren Bewertungen oder höheren Preisen korreliert**, sollte die Sprache zwar weiterhin einladend, aber gleichzeitig **faktenbasiert und informativ** bleiben. Eine **ausgewogene Mischung aus subjektiver und objektiver Sprache** scheint optimal zu sein.\n",
    "\n",
    "2. **Wichtige Themen gezielt hervorheben:**  \n",
    "   Die Topic-Modellierung zeigt, dass Themen wie **Lage, Ausstattung, Atmosphäre und Buchungsdetails** häufig vorkommen. Diese Inhalte sollten in zukünftigen Listings klar und strukturiert adressiert werden – insbesondere dann, wenn sie für die Zielgruppe relevant sind.\n",
    "\n",
    "3. **Keywords zur Sichtbarkeitssteigerung nutzen:**  \n",
    "   Die identifizierten Top-Wörter der Themen (z. B. \"kitchen\", \"station\", \"central\", \"luxurious\") können gezielt als **Keywords** in Titeln und in den ersten Sätzen der Beschreibungen verwendet werden, um die **Auffindbarkeit in der Airbnb-Suche** zu verbessern.\n",
    "\n",
    "4. **Zielgruppenspezifische Ansprache entwickeln:**  \n",
    "   Unterschiedliche Themen sprechen unterschiedliche Zielgruppen an (z. B. \"ruhige Lage\" für Familien, \"schnelles WLAN\" für Geschäftsreisende). Die Listings könnten daher **zielgruppenorientiert angepasst** werden, um verschiedene Gästesegmente gezielt anzusprechen und die Conversion-Rate zu steigern.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
